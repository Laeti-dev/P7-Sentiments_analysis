{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/laetitiataddei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/laetitiataddei/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/laetitiataddei/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "import nltk\n",
    "# Download necessary NLTK data to the specific directory\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies\n",
    "\n",
    "This notebook aims to test several basic models for binary classification. We will start by preprocessing tweets like we did during the EDA (URLs, mentions, hashtags,...), then tokens will be vectorized using either BoW or TF-IDF. Then, we will compare basic machine learning models using MLflow to mesure performances of each model and ease the comparison.\n",
    "\n",
    "**Models to test:**\n",
    "- Linear regression - Simple yet effective linear model for binary classification. Works great with bag-of-words or TF-IDF features. Outputs probabilities, which are useful for threshold tuning.\n",
    "- Random Forest Classifier - Can capture non-linear word interactions without manual feature engineering. Easy to interpret (at least for shallow trees).\n",
    "- SVM - Very fast and efficient for text (especially with sparse, high-dimensional data). Based on word occurrence probabilities, which often work surprisingly well in text classification. Robust even with relatively small datasets.\n",
    "- Naive bayes - Very fast and efficient for text (especially with sparse, high-dimensional data). Based on word occurrence probabilities, which often work surprisingly well in text classification. Robust even with relatively small datasets.\n",
    "\n",
    "**Metrics :**\n",
    "- Accuracy for an overall performance check\n",
    "- Precision (positive predicted values / true positives)\n",
    "- Recall \n",
    "- F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/5_6qtt550_3dxz3f8y6wwjww0000gn/T/ipykernel_91062/4236509596.py:3: FutureWarning: Parsed string \"Mon Apr 06 22:19:45 PDT 2009\" included an un-recognized timezone \"PDT\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
      "  data = pd.read_csv(path,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>2009-04-06 22:19:45</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>2009-04-06 22:19:49</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>2009-04-06 22:19:53</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                date             user  \\\n",
       "0       0  1467810369 2009-04-06 22:19:45  _TheSpecialOne_   \n",
       "1       0  1467810672 2009-04-06 22:19:49    scotthamilton   \n",
       "2       0  1467810917 2009-04-06 22:19:53         mattycus   \n",
       "3       0  1467811184 2009-04-06 22:19:57          ElleCTF   \n",
       "4       0  1467811193 2009-04-06 22:19:57           Karoli   \n",
       "\n",
       "                                                text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (1600000, 5)\n",
      "Number of unique target values: target\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n",
      "Number of unique target values after replacement: target\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/training.1600000.processed.noemoticon.csv\"\n",
    "# Load the data from the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(path,\n",
    "                header=None,\n",
    "                names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"],\n",
    "                usecols=[\"target\", \"ids\", \"date\", \"user\", \"text\"],  # remove flag column\n",
    "                parse_dates=[\"date\"],\n",
    "                encoding=\"utf-8\",\n",
    "                encoding_errors=\"replace\",)\n",
    "\n",
    "# Display the first few rows of the DataFrame and its info\n",
    "display(data.head())\n",
    "print(f'Shape of the DataFrame: {data.shape}')\n",
    "\n",
    "print(f\"Number of unique target values: {data['target'].value_counts()}\")\n",
    "# Change target value 4 to 1\n",
    "data['target'] = data['target'].replace(4, 1)\n",
    "print(f\"Number of unique target values after replacement: {data['target'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, lemmatize=False, stemming=False):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a single text string by replacing URLs, mentions, and hashtags,\n",
    "    converting to lowercase, removing special characters, and removing stopwords.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text string to process.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed text string.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Replace URLs with <URL>\n",
    "    processed = re.sub(r'https?://\\S+', '<URL>', text)\n",
    "    # Replace mentions with <MENTION>\n",
    "    processed = re.sub(r'@[A-Za-z0-9_]+', '<MENTION>', processed)\n",
    "    # Separate # from word and replace the word with <HASHTAG>\n",
    "    processed = re.sub(r'#([A-Za-z0-9_]+)', r'#<HASHTAG>', processed)\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    processed = processed.lower()\n",
    "\n",
    "    # Remove special characters and numbers, keeping !, ?, and ellipsis (...)\n",
    "    # Also keeps the placeholders <URL>, <MENTION>, <HASHTAG>\n",
    "    processed = re.sub(r'[^a-z0-9\\s.!?<>#]', '', processed)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(processed)\n",
    "\n",
    "    if stemming and lemmatize:\n",
    "        raise ValueError(\"Cannot use both stemming and lemmatization at the same time. Choose one.\")\n",
    "\n",
    "    # Initialize lemmatizer\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens] if lemmatize else tokens\n",
    "\n",
    "    # Initialize stemmer\n",
    "    if stemming:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens] if stemming else tokens\n",
    "\n",
    "\n",
    "    # Define negative words that should not be removed\n",
    "    negative_words = {\n",
    "        'no', 'not', 'nor', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\",\n",
    "        \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n",
    "        \"needn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\",\n",
    "        \"never\", \"none\", \"nobody\", \"nothing\", \"nowhere\", \"neither\"\n",
    "    }\n",
    "    # Create a set of stopwords to remove, excluding the negative words\n",
    "    stop_words_to_remove = set(stopwords.words('english')) - negative_words\n",
    "\n",
    "    # remove stopwords, and join back to string\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words_to_remove]\n",
    "\n",
    "    return ' '.join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/laetitiataddei/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text_lem</th>\n",
       "      <th>processed_text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>2185646565</td>\n",
       "      <td>2009-06-15 17:41:41</td>\n",
       "      <td>nazbear</td>\n",
       "      <td>@abcdude I'll bet your plane takes off to the ...</td>\n",
       "      <td>&lt; mention &gt; ill bet plane take tune quotill al...</td>\n",
       "      <td>&lt; mention &gt; ill bet plane take tune quotil alr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>1556812170</td>\n",
       "      <td>2009-04-19 00:28:02</td>\n",
       "      <td>digmyshine</td>\n",
       "      <td>Gaaah just got some good news about day 26!!!!</td>\n",
       "      <td>gaaah got good news day 26 ! ! ! !</td>\n",
       "      <td>gaaah got good news day 26 ! ! ! !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>1994848543</td>\n",
       "      <td>2009-06-01 12:33:13</td>\n",
       "      <td>TerezBaskin</td>\n",
       "      <td>Salad: chicken, craisins, carrots, mushrooms, ...</td>\n",
       "      <td>salad chicken craisins carrot mushroom cheese ...</td>\n",
       "      <td>salad chicken craisin carrot mushroom chees ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>2068458420</td>\n",
       "      <td>2009-06-07 14:06:50</td>\n",
       "      <td>TidalWaves7</td>\n",
       "      <td>Chillin on a raft in Devin's pool.</td>\n",
       "      <td>chillin raft devins pool .</td>\n",
       "      <td>chillin raft devin pool .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>2056840796</td>\n",
       "      <td>2009-06-06 11:53:42</td>\n",
       "      <td>krpearce</td>\n",
       "      <td>I think it's about time for a spontaneous trip...</td>\n",
       "      <td>think time spontaneous trip home visit amazing...</td>\n",
       "      <td>think time spontan trip home visit amaz famili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target         ids                date         user  \\\n",
       "49995       1  2185646565 2009-06-15 17:41:41      nazbear   \n",
       "49996       1  1556812170 2009-04-19 00:28:02   digmyshine   \n",
       "49997       1  1994848543 2009-06-01 12:33:13  TerezBaskin   \n",
       "49998       1  2068458420 2009-06-07 14:06:50  TidalWaves7   \n",
       "49999       1  2056840796 2009-06-06 11:53:42     krpearce   \n",
       "\n",
       "                                                    text  \\\n",
       "49995  @abcdude I'll bet your plane takes off to the ...   \n",
       "49996    Gaaah just got some good news about day 26!!!!    \n",
       "49997  Salad: chicken, craisins, carrots, mushrooms, ...   \n",
       "49998                Chillin on a raft in Devin's pool.    \n",
       "49999  I think it's about time for a spontaneous trip...   \n",
       "\n",
       "                                      processed_text_lem  \\\n",
       "49995  < mention > ill bet plane take tune quotill al...   \n",
       "49996                 gaaah got good news day 26 ! ! ! !   \n",
       "49997  salad chicken craisins carrot mushroom cheese ...   \n",
       "49998                         chillin raft devins pool .   \n",
       "49999  think time spontaneous trip home visit amazing...   \n",
       "\n",
       "                                     processed_text_stem  \n",
       "49995  < mention > ill bet plane take tune quotil alr...  \n",
       "49996                 gaaah got good news day 26 ! ! ! !  \n",
       "49997  salad chicken craisin carrot mushroom chees ba...  \n",
       "49998                          chillin raft devin pool .  \n",
       "49999  think time spontan trip home visit amaz famili...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the processed DataFrame: (50000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Sample dataframe for each target\n",
    "negative_sample = data[data['target'] == 0].sample(n=25000, random_state=42)\n",
    "positive_sample = data[data['target'] == 1].sample(n=25000, random_state=42)\n",
    "# Concatenate the two samples\n",
    "sample_df = pd.concat([negative_sample, positive_sample], ignore_index=True)\n",
    "# Apply the process_text function to the 'text' column\n",
    "nltk.download('punkt_tab')\n",
    "sample_df['processed_text_lem'] = sample_df['text'].apply(process_text, lemmatize=True)\n",
    "sample_df['processed_text_stem'] = sample_df['text'].apply(process_text, stemming=True)\n",
    "\n",
    "# Display the first few rows of the processed DataFrame\n",
    "display(sample_df.tail())\n",
    "print(f'Shape of the processed DataFrame: {sample_df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lem shape: (40000,)\n",
      "X_test_lem shape: (10000,)\n",
      "y_train_lem shape: (40000,)\n",
      "y_test_lem shape: (10000,)\n",
      "X_train_stem shape: (40000,)\n",
      "X_test_stem shape: (10000,)\n",
      "y_train_stem shape: (40000,)\n",
      "y_test_stem shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X_lem = sample_df['processed_text_lem']\n",
    "y_lem = sample_df['target']\n",
    "\n",
    "X_stem = sample_df['processed_text_stem']\n",
    "y_stem = sample_df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(\n",
    "    X_lem, y_lem,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_lem\n",
    ")\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train_lem shape: {X_train_lem.shape}\")\n",
    "print(f\"X_test_lem shape: {X_test_lem.shape}\")\n",
    "print(f\"y_train_lem shape: {y_train_lem.shape}\")\n",
    "print(f\"y_test_lem shape: {y_test_lem.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_stem, X_test_stem, y_train_stem, y_test_stem = train_test_split(\n",
    "    X_stem, y_stem,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_stem\n",
    ")\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train_stem shape: {X_train_stem.shape}\")\n",
    "print(f\"X_test_stem shape: {X_test_stem.shape}\")\n",
    "print(f\"y_train_stem shape: {y_train_stem.shape}\")\n",
    "print(f\"y_test_stem shape: {y_test_stem.shape}\")\n",
    "\n",
    "X_train_shape = X_train_lem.shape\n",
    "X_test_shape = X_test_lem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://127.0.0.1:8080\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix,fbeta_score, roc_curve, classification_report, make_scorer, matthews_corrcoef, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# For scikit-learn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Configuring MLflow\n",
    "load_dotenv()\n",
    "tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "print(f\"MLflow Tracking URI: {tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:02:15 INFO mlflow.tracking.fluent: Experiment with name 'P7-Sentiments_Analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/459239379042760612', creation_time=1756206135431, experiment_id='459239379042760612', last_update_time=1756206135431, lifecycle_stage='active', name='P7-Sentiments_Analysis', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"P7-Sentiments_Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name, vectorizer_name):\n",
    "    \"\"\"\n",
    "    Evaluates a machine learning model using various metrics and visualizations.\n",
    "    Args:\n",
    "        model: The trained machine learning model to evaluate.\n",
    "        X_test: The test features.\n",
    "        y_test: The true labels for the test set.\n",
    "        model_name: The name of the model being evaluated.\n",
    "        vectorizer_name: The name of the vectorizer used for feature extraction.\n",
    "    Returns:\n",
    "        accuracy, precision, recall, f1, f2, roc_auc: Evaluation metrics.\n",
    "        fig_cm: Figure of the confusion matrix.\n",
    "        fig_roc: Figure of the ROC curve.\n",
    "        y_pred: Predicted labels for the test set.\n",
    "    \"\"\"\n",
    "    # Predict the labels for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get the predicted probabilities or decision function scores\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_score = model.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = y_pred  # Fallback for models without probability estimates\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)\n",
    "    ax_cm.set_xlabel('Prediction')\n",
    "    ax_cm.set_ylabel('Real label')\n",
    "    ax_cm.set_title(f'Confusion matrix - {model_name} with {vectorizer_name}')\n",
    "\n",
    "    # Créer la courbe ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    fig_roc, ax_roc = plt.subplots(figsize=(8, 6))\n",
    "    ax_roc.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    ax_roc.plot([0, 1], [0, 1], 'k--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.set_title(f'ROC curve - {model_name} with {vectorizer_name}')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    ax_roc.grid(True)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    print(f\"\\nResults for {model_name} with {vectorizer_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")  # Ajout du F2-score\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassificatin report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, precision, recall, f1, f2, roc_auc, fig_cm, fig_roc, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizers\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "bow_vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "# Vectorize texts into TF-IDF vectors\n",
    "X_train_tfidf_lem = tfidf_vectorizer.fit_transform(X_train_lem)\n",
    "X_test_tfidf_lem = tfidf_vectorizer.transform(X_test_lem)\n",
    "X_train_tfidf_stem = tfidf_vectorizer.fit_transform(X_train_stem)\n",
    "X_test_tfidf_stem = tfidf_vectorizer.transform(X_test_stem)\n",
    "\n",
    "# Vectorize texts into Bag-of-Words vectors\n",
    "X_train_bow_lem = bow_vectorizer.fit_transform(X_train_lem)\n",
    "X_test_bow_lem = bow_vectorizer.transform(X_test_lem)\n",
    "X_train_bow_stem = bow_vectorizer.fit_transform(X_train_stem)\n",
    "X_test_bow_stem = bow_vectorizer.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the models\n",
    "base_models = {\n",
    "    \"Logistic_Regression\": LogisticRegression(random_state=42),\n",
    "    \"SVM_Lineaire\": LinearSVC(random_state=42),\n",
    "    \"Random_Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Naive_Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Defined hyperparameters\n",
    "param_grids = {\n",
    "    \"Logistic_Regression\": {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'max_iter': [1000],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \"SVM_Lineaire\": {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'max_iter': [1000],\n",
    "        'dual': [True, False]\n",
    "    },\n",
    "    \"Random_Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    \"Naive_Bayes\": {\n",
    "        'alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Vectorizers\n",
    "vectorizers = {\n",
    "    \"TF-IDF_lem\": (tfidf_vectorizer, X_train_tfidf_lem, X_test_tfidf_lem, y_train_lem, y_test_lem),\n",
    "    \"BoW_lem\": (bow_vectorizer, X_train_bow_lem, X_test_bow_lem, y_train_lem, y_test_lem),\n",
    "    \"TF-IDF_stem\": (tfidf_vectorizer, X_train_tfidf_stem, X_test_tfidf_stem, y_train_stem, y_test_stem),\n",
    "    \"BoW_stem\": (bow_vectorizer, X_train_bow_stem, X_test_bow_stem, y_train_stem, y_test_stem),\n",
    "}\n",
    "\n",
    "# Scorers\n",
    "scorers = {\n",
    "    'f2': make_scorer(fbeta_score, beta=2),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'balanced_acc': make_scorer(balanced_accuracy_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Logistic_Regression with TF-IDF_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:03:29 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:03:36 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:03:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:03:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:03:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:03:39 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:03:39 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:03:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:03:39 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:03:39 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:03:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:03:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Logistic_Regression with TF-IDF_lem:\n",
      "Accuracy: 0.7721\n",
      "Precision: 0.7692\n",
      "Recall: 0.7774\n",
      "F1 Score: 0.7733\n",
      "F2 Score: 0.7758\n",
      "ROC AUC: 0.8535\n",
      "\n",
      "Confusion matrix:\n",
      "[[3834 1166]\n",
      " [1113 3887]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      5000\n",
      "           1       0.77      0.78      0.77      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:03:41 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Logistic_Regression with TF-IDF_lem:   6%|▋         | 1/16 [00:14<03:39, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.0, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Best CV score (F2): 0.7786\n",
      "F1 Score test: 0.7733\n",
      "F2 Score test: 0.7758\n",
      "ROC AUC test: 0.8535\n",
      "Training time: 12.43 secondes\n",
      "🏃 View run Basic_Model_Logistic_Regression_TF-IDF_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/4f254f2920c34b2986e4d4fcadd87194\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Logistic_Regression with BoW_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:03:43 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2025/08/26 13:03:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:03:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:00 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:00 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:00 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:00 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:04:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Logistic_Regression with BoW_lem:\n",
      "Accuracy: 0.7682\n",
      "Precision: 0.7609\n",
      "Recall: 0.7822\n",
      "F1 Score: 0.7714\n",
      "F2 Score: 0.7778\n",
      "ROC AUC: 0.8431\n",
      "\n",
      "Confusion matrix:\n",
      "[[3771 1229]\n",
      " [1089 3911]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      5000\n",
      "           1       0.76      0.78      0.77      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:02 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Logistic_Regression with BoW_lem:  12%|█▎        | 2/16 [00:35<04:19, 18.54s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Best CV score (F2): 0.7815\n",
      "F1 Score test: 0.7714\n",
      "F2 Score test: 0.7778\n",
      "ROC AUC test: 0.8431\n",
      "Training time: 19.46 secondes\n",
      "🏃 View run Basic_Model_Logistic_Regression_BoW_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/ae48ee9638d94f519a2192a8852601d6\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Logistic_Regression with TF-IDF_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:04 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:07 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:10 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:10 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:10 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:10 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:04:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Logistic_Regression with TF-IDF_stem:\n",
      "Accuracy: 0.7724\n",
      "Precision: 0.7722\n",
      "Recall: 0.7728\n",
      "F1 Score: 0.7725\n",
      "F2 Score: 0.7727\n",
      "ROC AUC: 0.8546\n",
      "\n",
      "Confusion matrix:\n",
      "[[3860 1140]\n",
      " [1136 3864]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      5000\n",
      "           1       0.77      0.77      0.77      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:12 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Logistic_Regression with TF-IDF_stem:  19%|█▉        | 3/16 [00:45<03:08, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1.0, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Best CV score (F2): 0.7810\n",
      "F1 Score test: 0.7725\n",
      "F2 Score test: 0.7727\n",
      "ROC AUC test: 0.8546\n",
      "Training time: 7.80 secondes\n",
      "🏃 View run Basic_Model_Logistic_Regression_TF-IDF_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/faa8a94fb8154c23b67d884c9f59087c\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Logistic_Regression with BoW_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:13 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2025/08/26 13:04:28 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:28 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:32 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:32 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:32 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:32 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:32 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:32 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:04:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Logistic_Regression with BoW_stem:\n",
      "Accuracy: 0.7721\n",
      "Precision: 0.7648\n",
      "Recall: 0.7858\n",
      "F1 Score: 0.7752\n",
      "F2 Score: 0.7815\n",
      "ROC AUC: 0.8452\n",
      "\n",
      "Confusion matrix:\n",
      "[[3792 1208]\n",
      " [1071 3929]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      5000\n",
      "           1       0.76      0.79      0.78      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:33 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Logistic_Regression with BoW_stem:  25%|██▌       | 4/16 [01:07<03:27, 17.28s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Best CV score (F2): 0.7834\n",
      "F1 Score test: 0.7752\n",
      "F2 Score test: 0.7815\n",
      "ROC AUC test: 0.8452\n",
      "Training time: 19.77 secondes\n",
      "🏃 View run Basic_Model_Logistic_Regression_BoW_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/f3d1111704dd444bb8963d1abf2b2485\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for SVM_Lineaire with TF-IDF_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:35 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:40 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:43 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:43 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:04:43 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:04:43 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:04:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:04:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM_Lineaire with TF-IDF_lem:\n",
      "Accuracy: 0.7724\n",
      "Precision: 0.7692\n",
      "Recall: 0.7784\n",
      "F1 Score: 0.7738\n",
      "F2 Score: 0.7765\n",
      "ROC AUC: 0.8536\n",
      "\n",
      "Confusion matrix:\n",
      "[[3832 1168]\n",
      " [1108 3892]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      5000\n",
      "           1       0.77      0.78      0.77      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: SVM_Lineaire with TF-IDF_lem:  31%|███▏      | 5/16 [01:18<02:45, 15.03s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'dual': True, 'max_iter': 1000}\n",
      "Best CV score (F2): 0.7801\n",
      "F1 Score test: 0.7738\n",
      "F2 Score test: 0.7765\n",
      "ROC AUC test: 0.8536\n",
      "Training time: 9.29 secondes\n",
      "🏃 View run Basic_Model_SVM_Lineaire_TF-IDF_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/96d421267a874107bf8d28e9269725b7\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for SVM_Lineaire with BoW_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:04:46 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "2025/08/26 13:04:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:04:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:05:00 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:05:00 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:05:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:05:00 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:05:00 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:05:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:05:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM_Lineaire with BoW_lem:\n",
      "Accuracy: 0.7691\n",
      "Precision: 0.7593\n",
      "Recall: 0.7880\n",
      "F1 Score: 0.7734\n",
      "F2 Score: 0.7821\n",
      "ROC AUC: 0.8434\n",
      "\n",
      "Confusion matrix:\n",
      "[[3751 1249]\n",
      " [1060 3940]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      5000\n",
      "           1       0.76      0.79      0.77      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:02 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: SVM_Lineaire with BoW_lem:  38%|███▊      | 6/16 [01:35<02:38, 15.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'dual': True, 'max_iter': 1000}\n",
      "Best CV score (F2): 0.7843\n",
      "F1 Score test: 0.7734\n",
      "F2 Score test: 0.7821\n",
      "ROC AUC test: 0.8434\n",
      "Training time: 15.71 secondes\n",
      "🏃 View run Basic_Model_SVM_Lineaire_BoW_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/7a21d916af654d1085a3f09fbbabd9a0\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for SVM_Lineaire with TF-IDF_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:04 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:05:11 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:05:11 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:05:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:05:11 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:05:11 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:05:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:05:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM_Lineaire with TF-IDF_stem:\n",
      "Accuracy: 0.7726\n",
      "Precision: 0.7714\n",
      "Recall: 0.7748\n",
      "F1 Score: 0.7731\n",
      "F2 Score: 0.7741\n",
      "ROC AUC: 0.8547\n",
      "\n",
      "Confusion matrix:\n",
      "[[3852 1148]\n",
      " [1126 3874]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      5000\n",
      "           1       0.77      0.77      0.77      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:13 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: SVM_Lineaire with TF-IDF_stem:  44%|████▍     | 7/16 [01:46<02:08, 14.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'dual': False, 'max_iter': 1000}\n",
      "Best CV score (F2): 0.7811\n",
      "F1 Score test: 0.7731\n",
      "F2 Score test: 0.7741\n",
      "ROC AUC test: 0.8547\n",
      "Training time: 9.08 secondes\n",
      "🏃 View run Basic_Model_SVM_Lineaire_TF-IDF_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/ce95f61337534530afc87d9b8348613b\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for SVM_Lineaire with BoW_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "2025/08/26 13:05:26 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:26 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:29 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:29 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:05:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:05:29 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:05:29 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:05:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:05:29 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/26 13:05:29 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:05:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:05:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM_Lineaire with BoW_stem:\n",
      "Accuracy: 0.7725\n",
      "Precision: 0.7631\n",
      "Recall: 0.7904\n",
      "F1 Score: 0.7765\n",
      "F2 Score: 0.7848\n",
      "ROC AUC: 0.8454\n",
      "\n",
      "Confusion matrix:\n",
      "[[3773 1227]\n",
      " [1048 3952]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77      5000\n",
      "           1       0.76      0.79      0.78      5000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: SVM_Lineaire with BoW_stem:  50%|█████     | 8/16 [02:04<02:04, 15.54s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'dual': True, 'max_iter': 1000}\n",
      "Best CV score (F2): 0.7858\n",
      "F1 Score test: 0.7765\n",
      "F2 Score test: 0.7848\n",
      "ROC AUC test: 0.8454\n",
      "Training time: 16.31 secondes\n",
      "🏃 View run Basic_Model_SVM_Lineaire_BoW_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/0605230b682e479c85442a2036e342ea\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Random_Forest with TF-IDF_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:05:33 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:08:46 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:09:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:09:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:09:24 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:09:24 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:09:24 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:09:24 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:09:24 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:09:24 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:09:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:09:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Random_Forest with TF-IDF_lem:\n",
      "Accuracy: 0.7501\n",
      "Precision: 0.7489\n",
      "Recall: 0.7526\n",
      "F1 Score: 0.7507\n",
      "F2 Score: 0.7518\n",
      "ROC AUC: 0.8289\n",
      "\n",
      "Confusion matrix:\n",
      "[[3738 1262]\n",
      " [1237 3763]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      5000\n",
      "           1       0.75      0.75      0.75      5000\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:09:30 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Random_Forest with TF-IDF_lem:  56%|█████▋    | 9/16 [06:04<10:00, 85.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV score (F2): 0.7606\n",
      "F1 Score test: 0.7507\n",
      "F2 Score test: 0.7518\n",
      "ROC AUC test: 0.8289\n",
      "Training time: 232.46 secondes\n",
      "🏃 View run Basic_Model_Random_Forest_TF-IDF_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/3f6d4ee523184eda87876b89a65a59e4\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Random_Forest with BoW_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:09:33 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:12:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:12:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:12:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:12:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:12:35 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:12:35 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:12:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:12:35 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:12:35 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:12:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:12:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Random_Forest with BoW_lem:\n",
      "Accuracy: 0.7520\n",
      "Precision: 0.7597\n",
      "Recall: 0.7372\n",
      "F1 Score: 0.7483\n",
      "F2 Score: 0.7416\n",
      "ROC AUC: 0.8329\n",
      "\n",
      "Confusion matrix:\n",
      "[[3834 1166]\n",
      " [1314 3686]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      5000\n",
      "           1       0.76      0.74      0.75      5000\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:12:38 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Random_Forest with BoW_lem:  62%|██████▎   | 10/16 [09:11<11:42, 117.01s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best CV score (F2): 0.7528\n",
      "F1 Score test: 0.7483\n",
      "F2 Score test: 0.7416\n",
      "ROC AUC test: 0.8329\n",
      "Training time: 183.64 secondes\n",
      "🏃 View run Basic_Model_Random_Forest_BoW_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/64d45425797043d382fd38a45b3450c2\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Random_Forest with TF-IDF_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:12:40 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:15:27 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:15:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:15:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:15:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:15:31 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:15:31 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:15:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:15:31 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:15:31 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:15:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:15:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Random_Forest with TF-IDF_stem:\n",
      "Accuracy: 0.7274\n",
      "Precision: 0.7037\n",
      "Recall: 0.7856\n",
      "F1 Score: 0.7424\n",
      "F2 Score: 0.7677\n",
      "ROC AUC: 0.8048\n",
      "\n",
      "Confusion matrix:\n",
      "[[3346 1654]\n",
      " [1072 3928]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      5000\n",
      "           1       0.70      0.79      0.74      5000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.73      0.73     10000\n",
      "weighted avg       0.73      0.73      0.73     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:15:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Random_Forest with TF-IDF_stem:  69%|██████▉   | 11/16 [12:06<11:12, 134.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best CV score (F2): 0.7668\n",
      "F1 Score test: 0.7424\n",
      "F2 Score test: 0.7677\n",
      "ROC AUC test: 0.8048\n",
      "Training time: 172.47 secondes\n",
      "🏃 View run Basic_Model_Random_Forest_TF-IDF_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/afcf262de5334ff48d0380db0671c71b\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Random_Forest with BoW_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:15:35 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "2025/08/26 13:18:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:23 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:26 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:26 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:26 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:18:26 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:26 INFO mlflow.sklearn.utils: Logging the 5 best runs, 13 runs will be omitted.\n",
      "2025/08/26 13:18:26 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:18:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Random_Forest with BoW_stem:\n",
      "Accuracy: 0.7142\n",
      "Precision: 0.6911\n",
      "Recall: 0.7746\n",
      "F1 Score: 0.7305\n",
      "F2 Score: 0.7563\n",
      "ROC AUC: 0.7844\n",
      "\n",
      "Confusion matrix:\n",
      "[[3269 1731]\n",
      " [1127 3873]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.70      5000\n",
      "           1       0.69      0.77      0.73      5000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:28 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Random_Forest with BoW_stem:  75%|███████▌  | 12/16 [15:01<09:48, 147.02s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best CV score (F2): 0.7794\n",
      "F1 Score test: 0.7305\n",
      "F2 Score test: 0.7563\n",
      "ROC AUC test: 0.7844\n",
      "Training time: 173.84 secondes\n",
      "🏃 View run Basic_Model_Random_Forest_BoW_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/dd3be3b430ec456f97988f9c4fccaddf\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Naive_Bayes with TF-IDF_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:30 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:34 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:34 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:34 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:34 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:18:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Naive_Bayes with TF-IDF_lem:\n",
      "Accuracy: 0.7646\n",
      "Precision: 0.7769\n",
      "Recall: 0.7424\n",
      "F1 Score: 0.7593\n",
      "F2 Score: 0.7491\n",
      "ROC AUC: 0.8451\n",
      "\n",
      "Confusion matrix:\n",
      "[[3934 1066]\n",
      " [1288 3712]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      5000\n",
      "           1       0.78      0.74      0.76      5000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:36 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Naive_Bayes with TF-IDF_lem:  81%|████████▏ | 13/16 [15:09<05:14, 104.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 2.0}\n",
      "Best CV score (F2): 0.7531\n",
      "F1 Score test: 0.7593\n",
      "F2 Score test: 0.7491\n",
      "ROC AUC test: 0.8451\n",
      "Training time: 6.33 secondes\n",
      "🏃 View run Basic_Model_Naive_Bayes_TF-IDF_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/da46af3630784beda44690ea50247433\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Naive_Bayes with BoW_lem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:38 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:42 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:42 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:42 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:42 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:42 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:42 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:18:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Naive_Bayes with BoW_lem:\n",
      "Accuracy: 0.7630\n",
      "Precision: 0.7700\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.7599\n",
      "F2 Score: 0.7539\n",
      "ROC AUC: 0.8361\n",
      "\n",
      "Confusion matrix:\n",
      "[[3880 1120]\n",
      " [1250 3750]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      5000\n",
      "           1       0.77      0.75      0.76      5000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Naive_Bayes with BoW_lem:  88%|████████▊ | 14/16 [15:17<02:31, 75.53s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 2.0}\n",
      "Best CV score (F2): 0.7567\n",
      "F1 Score test: 0.7599\n",
      "F2 Score test: 0.7539\n",
      "ROC AUC test: 0.8361\n",
      "Training time: 6.08 secondes\n",
      "🏃 View run Basic_Model_Naive_Bayes_BoW_lem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/baef66d4d47646bb81550855400af89f\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Naive_Bayes with TF-IDF_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:46 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:47 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:51 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:51 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:51 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:51 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:51 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:51 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:18:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Naive_Bayes with TF-IDF_stem:\n",
      "Accuracy: 0.7612\n",
      "Precision: 0.7735\n",
      "Recall: 0.7388\n",
      "F1 Score: 0.7557\n",
      "F2 Score: 0.7455\n",
      "ROC AUC: 0.8456\n",
      "\n",
      "Confusion matrix:\n",
      "[[3918 1082]\n",
      " [1306 3694]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      5000\n",
      "           1       0.77      0.74      0.76      5000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:52 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Naive_Bayes with TF-IDF_stem:  94%|█████████▍| 15/16 [15:26<00:55, 55.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 2.0}\n",
      "Best CV score (F2): 0.7553\n",
      "F1 Score test: 0.7557\n",
      "F2 Score test: 0.7455\n",
      "ROC AUC test: 0.8456\n",
      "Training time: 6.95 secondes\n",
      "🏃 View run Basic_Model_Naive_Bayes_TF-IDF_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/b2a80ec0296c40f0a6976e9988a2bdc5\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n",
      "\n",
      "================================================================================\n",
      "Starting GridSearchCV for Naive_Bayes with BoW_stem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:54 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:18:56 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:59 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:59 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 13:18:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:59 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:59 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/laetitiataddei/Desktop/code/Laeti-dev/data/ia-engineer/P7-Sentiments_analysis/.uv-venv/lib/python3.11/site-packages/mlflow/sklearn/utils.py:853: UserWarning: Top 5 child runs will be created based on ordering in rank_test_f2 column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/26 13:18:59 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2025/08/26 13:18:59 WARNING mlflow.sklearn: Encountered exception during creation of child runs for parameter search. Child runs may be missing. Exception: 'NoneType' object has no attribute '_to_mlflow_entity'\n",
      "2025/08/26 13:18:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/26 13:18:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Naive_Bayes with BoW_stem:\n",
      "Accuracy: 0.7629\n",
      "Precision: 0.7709\n",
      "Recall: 0.7482\n",
      "F1 Score: 0.7594\n",
      "F2 Score: 0.7526\n",
      "ROC AUC: 0.8373\n",
      "\n",
      "Confusion matrix:\n",
      "[[3888 1112]\n",
      " [1259 3741]]\n",
      "\n",
      "Classificatin report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      5000\n",
      "           1       0.77      0.75      0.76      5000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 13:19:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Last model: Naive_Bayes with BoW_stem: 100%|██████████| 16/16 [15:34<00:00, 58.41s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 2.0}\n",
      "Best CV score (F2): 0.7593\n",
      "F1 Score test: 0.7594\n",
      "F2 Score test: 0.7526\n",
      "ROC AUC test: 0.8373\n",
      "Training time: 6.79 secondes\n",
      "🏃 View run Basic_Model_Naive_Bayes_BoW_stem at: http://127.0.0.1:8080/#/experiments/459239379042760612/runs/7f322d6aa5294496b863cd0dcb7147bd\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/459239379042760612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_models = True  # Set to True to train models\n",
    "if train_models:\n",
    "\n",
    "    # Total iterations for the progress bar\n",
    "    total_iterations = len(base_models) * len(vectorizers)\n",
    "    progress_bar = tqdm(total=total_iterations, desc=\"Overall Progress\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Test each model with the two types of vectorization\n",
    "    for model_name, base_model in base_models.items():\n",
    "        for vectorizer_name, (vectorizer, X_train_vec, X_test_vec, y_train_vec, y_test_vec) in vectorizers.items():\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Starting GridSearchCV for {model_name} with {vectorizer_name}...\")\n",
    "\n",
    "            # Define the parameter grid and create GridSearchCV\n",
    "            param_grid = param_grids[model_name]\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                base_model,\n",
    "                param_grid,\n",
    "                cv=5,\n",
    "                scoring=scorers,\n",
    "                refit='f2',\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                return_train_score=True\n",
    "            )\n",
    "\n",
    "            # Start MLflow run\n",
    "            with mlflow.start_run(run_name=f\"Basic_Model_{model_name}_{vectorizer_name}\"):\n",
    "                # Log parameters\n",
    "                mlflow.log_param(\"model_type\", model_name)\n",
    "                mlflow.log_param(\"vectorizer_type\", vectorizer_name)\n",
    "                mlflow.log_param(\"dataset_size\", X_train_shape[0] + X_test_shape[0])\n",
    "                mlflow.log_param(\"train_size\", X_train_shape[0])\n",
    "                mlflow.log_param(\"test_size\", X_test_shape[0])\n",
    "                mlflow.log_param(\"max_features\", 10000)\n",
    "                mlflow.log_param(\"ngram_range\", \"(1, 2)\")\n",
    "                mlflow.log_param(\"scoring_metric\", \"f2_score\")\n",
    "\n",
    "                # Initialize the timer\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Grid search with cross-validation\n",
    "                grid_search.fit(X_train_vec, y_train_vec)\n",
    "\n",
    "                # Training time\n",
    "                training_time = time.time() - start_time\n",
    "\n",
    "                # Log the training time\n",
    "                mlflow.log_metric(\"training_time\", training_time)\n",
    "\n",
    "                # Get and log the best parameters\n",
    "                best_params = grid_search.best_params_\n",
    "                for param, value in best_params.items():\n",
    "                    mlflow.log_param(f\"best_{param}\", value)\n",
    "\n",
    "                # Log the best cross-validation F2 score\n",
    "                mlflow.log_metric(\"best_cv_f2_score\", grid_search.best_score_)\n",
    "\n",
    "                # Get the best model\n",
    "                best_model = grid_search.best_estimator_\n",
    "\n",
    "                # Evaluate the best model on the test set\n",
    "                acc, prec, rec, f1, f2, roc_auc, fig_cm, fig_roc, y_pred = evaluate_model(\n",
    "                    best_model, X_test_vec, y_test_vec, model_name, vectorizer_name\n",
    "                )\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", acc)\n",
    "                mlflow.log_metric(\"precision\", prec)\n",
    "                mlflow.log_metric(\"recall\", rec)\n",
    "                mlflow.log_metric(\"f1\", f1)\n",
    "                mlflow.log_metric(\"f2\", f2)\n",
    "                mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "                # Log confusion matrix and ROC curve figures\n",
    "                mlflow.log_figure(fig_cm, \"confusion_matrix.png\")\n",
    "                mlflow.log_figure(fig_roc, \"roc_curve.png\")\n",
    "                plt.close(fig_cm)\n",
    "                plt.close(fig_roc)\n",
    "\n",
    "                # Log the model\n",
    "                signature = infer_signature(X_train_vec, y_pred)\n",
    "                mlflow.sklearn.log_model(best_model, \"model\", signature=signature)\n",
    "\n",
    "                # Save the model artifacts into a specific directory\n",
    "                os.makedirs(\"./content/basic-model\", exist_ok=True)\n",
    "\n",
    "                # Save and log the vectorizer\n",
    "                vectorizer_path = f\"./content/basic-model/vectorizer_{vectorizer_name}.pkl\"\n",
    "                with open(vectorizer_path, \"wb\") as f:\n",
    "                    pickle.dump(vectorizer, f)\n",
    "                mlflow.log_artifact(vectorizer_path)\n",
    "\n",
    "                # Log the GridSearchCV results\n",
    "                cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "                cv_results_path = \"./content/basic-model/cv_results.csv\"\n",
    "                cv_results.to_csv(cv_results_path, index=False)\n",
    "                mlflow.log_artifact(cv_results_path)\n",
    "\n",
    "                # Log the best parameters and scores\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                params = [f\"{k}={v}\" for k, v in best_params.items()]\n",
    "                params_str = \", \".join(params)\n",
    "\n",
    "                # Plot the results of GridSearchCV\n",
    "                for param in param_grid.keys():\n",
    "                    if len(param_grid[param]) > 1:  # Only if the parameter has multiple values\n",
    "                        param_name = f\"param_{param}\"\n",
    "                        if param_name in cv_results.columns:\n",
    "                            # Use the column specific to the f2 metric (which you defined as primary)\n",
    "                            scores_df = cv_results[[param_name, \"mean_test_f2\", \"std_test_f2\"]]\n",
    "                            scores_df = scores_df.sort_values(param_name)\n",
    "\n",
    "                            plt.figure(figsize=(10, 6))\n",
    "                            plt.errorbar(\n",
    "                                scores_df[param_name].astype(str),\n",
    "                                scores_df[\"mean_test_f2\"],\n",
    "                                yerr=scores_df[\"std_test_f2\"],\n",
    "                                fmt='-o'\n",
    "                            )\n",
    "                            plt.title(f'Cross-validation score {param}')\n",
    "                            plt.xlabel(param)\n",
    "                            plt.ylabel('Average F2 Score')\n",
    "                            plt.grid(True)\n",
    "                            mlflow.log_figure(plt.gcf(), f\"cv_results_{param}.png\")\n",
    "                            plt.close()\n",
    "\n",
    "                # Log the best parameters and scores\n",
    "                if hasattr(best_model, 'coef_'):\n",
    "                    # Get the most important features\n",
    "                    if isinstance(best_model, LogisticRegression) or isinstance(best_model, LinearSVC):\n",
    "                        coefs = best_model.coef_[0]\n",
    "                        if vectorizer_name == \"TF-IDF\":\n",
    "                            feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "                        else:\n",
    "                            feature_names = bow_vectorizer.get_feature_names_out()\n",
    "\n",
    "                        # Create a DataFrame for the coefficients\n",
    "                        coefs_df = pd.DataFrame({\n",
    "                            'feature': feature_names,\n",
    "                            'importance': coefs\n",
    "                        })\n",
    "\n",
    "                        # Sort and filter the coefficients\n",
    "                        coefs_df['abs_importance'] = abs(coefs_df['importance'])\n",
    "                        coefs_df = coefs_df.sort_values('abs_importance', ascending=False).head(20)\n",
    "\n",
    "                        # Log the top features\n",
    "                        top_features_path = \"./content/basic-model/top_features.csv\"\n",
    "                        coefs_df.to_csv(top_features_path, index=False)\n",
    "                        mlflow.log_artifact(top_features_path)\n",
    "\n",
    "                        # Plot the top positive and negative features\n",
    "                        plt.figure(figsize=(10, 8))\n",
    "                        sns.barplot(x='importance', y='feature', data=coefs_df.sort_values('importance', ascending=False).head(20))\n",
    "                        plt.title(f'Top 20 positive features')\n",
    "                        plt.tight_layout()\n",
    "                        mlflow.log_figure(plt.gcf(), \"top_positive_features.png\")\n",
    "                        plt.close()\n",
    "\n",
    "                        plt.figure(figsize=(10, 8))\n",
    "                        sns.barplot(x='importance', y='feature', data=coefs_df.sort_values('importance').head(20))\n",
    "                        plt.title(f'Top 20 negative features')\n",
    "                        plt.tight_layout()\n",
    "                        mlflow.log_figure(plt.gcf(), \"top_negative_features.png\")\n",
    "                        plt.close()\n",
    "\n",
    "                # Save the results in a list\n",
    "                results.append({\n",
    "                    \"Model\": model_name.replace(\"_\", \" \"),\n",
    "                    \"Vectorization\": vectorizer_name,\n",
    "                    \"Best params\": str(best_params),\n",
    "                    \"Accuracy\": acc,\n",
    "                    \"Precision\": prec,\n",
    "                    \"Recall\": rec,\n",
    "                    \"F1 Score\": f1,\n",
    "                    \"F2 Score\": f2,\n",
    "                    \"ROC AUC\": roc_auc,\n",
    "                    \"Training time (s)\": training_time\n",
    "                })\n",
    "\n",
    "                # Display the results\n",
    "                print(f\"Best params: {best_params}\")\n",
    "                print(f\"Best CV score (F2): {grid_search.best_score_:.4f}\")\n",
    "                print(f\"F1 Score test: {f1:.4f}\")\n",
    "                print(f\"F2 Score test: {f2:.4f}\")\n",
    "                print(f\"ROC AUC test: {roc_auc:.4f}\")\n",
    "                print(f\"Training time: {training_time:.2f} secondes\")\n",
    "\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_description(f\"Last model: {model_name} with {vectorizer_name}\")\n",
    "\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F2 Score as the Primary Metric\n",
    "\n",
    "The **F-beta score** is a metric that provides a weighted average of Precision and Recall. The **F2 score** is a specific version where `beta = 2`, which gives **twice as much weight to Recall as to Precision**.\n",
    "\n",
    "*   **Precision**: Of all the tweets your model labeled as \"positive,\" how many were actually positive? (Minimizes False Positives).\n",
    "*   **Recall**: Of all the tweets that were *actually* positive, how many did your model correctly identify? (Minimizes False Negatives).\n",
    "\n",
    "In this context, choosing the F2 score means we are prioritizing **Recall**. This is a strategic choice because for many sentiment analysis applications (like identifying happy customers or positive feedback), **it is more costly to miss a positive tweet (a False Negative) than to incorrectly classify a negative one as positive (a False Positive).**\n",
    "\n",
    "By setting `refit='f2'` in our `GridSearchCV`, we instruct it to find the model that is best at identifying the maximum number of *actual* positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mlflow results\n",
    "def get_mlflow_results(experiment_name:str =\"P7-Sentiments_Analysis\", run_name: str = \"Basic_Model\", uri: str = None):\n",
    "    \"\"\"\n",
    "    Retrieves the results of the MLflow runs for the basic models.\n",
    "    Args:\n",
    "        experiment_name (str): The name of the MLflow experiment to search in.\n",
    "        run_name (str): The name of the runs to filter by.\n",
    "        uri (str): Optional; the URI of the MLflow tracking server. If None, uses the default tracking URI.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the results of the MLflow runs.\n",
    "    \"\"\"\n",
    "    # Connect to the MLflow tracking server\n",
    "    if uri:\n",
    "        mlflow.set_tracking_uri(uri)\n",
    "\n",
    "    # Create mlflow client\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Get the experiment ID by name\n",
    "    try:\n",
    "        experiment = client.get_experiment_by_name(experiment_name)\n",
    "        if not experiment:\n",
    "            raise ValueError(f\"Experiment '{experiment_name}' not found.\")\n",
    "        experiment_id = experiment.experiment_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving experiment '{experiment_name}': {experiment}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Load the MLflow runs\n",
    "    runs = client.search_runs(experiment_ids=[experiment_id],\n",
    "                            filter_string=f\"tags.mlflow.runName LIKE '%{run_name}%'\",\n",
    "                            order_by=[\"metrics.f2 DESC\"])\n",
    "\n",
    "    # Store results in a list\n",
    "    results = []\n",
    "\n",
    "    for run in runs:\n",
    "        # Get run name\n",
    "        run_name = run.data.tags.get(\"mlflow.runName\", \"\")\n",
    "\n",
    "        # Get model type and vectorization type\n",
    "        model_type = run.data.params.get(\"model_type\", \"\")\n",
    "        vectorization_type = run.data.params.get(\"vectorizer_type\", \"\")\n",
    "\n",
    "        # Rename model\n",
    "        model_type = model_type.replace(\"_\", \" \")\n",
    "\n",
    "        # Get metrics\n",
    "        metrics = run.data.metrics\n",
    "        params = run.data.params\n",
    "\n",
    "        # Get the best parameters\n",
    "        best_params = {k: v for k, v in params.items() if k.startswith(\"best_\")}\n",
    "\n",
    "        results.append({\n",
    "            \"Run Name\": run_name,\n",
    "            \"Model\": model_type,\n",
    "            \"Vectorization\": vectorization_type,\n",
    "            \"Best Params\": str(best_params),\n",
    "            \"Accuracy\": metrics.get(\"accuracy\", None),\n",
    "            \"Precision\": metrics.get(\"precision\", None),\n",
    "            \"Recall\": metrics.get(\"recall\", None),\n",
    "            \"F1 Score\": metrics.get(\"f1\", None),\n",
    "            \"F2 Score\": metrics.get(\"f2\", None),\n",
    "            \"ROC AUC\": metrics.get(\"roc_auc\", None),\n",
    "            \"Training Time (s)\": metrics.get(\"training_time\", None)\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    if not results_df.empty:\n",
    "        results_df = results_df.sort_values(by=\"F2 Score\", ascending=False)\n",
    "        results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mlflow_results(experiment_name=\"P7-Sentiments_Analysis\", run_name=\"Basic_Model_\", uri=tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic_Model_SVM_Lineaire_BoW_stem</td>\n",
       "      <td>SVM Lineaire</td>\n",
       "      <td>BoW_stem</td>\n",
       "      <td>{'best_C': '0.01', 'best_max_iter': '1000', 'b...</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.763082</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.776501</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>0.845413</td>\n",
       "      <td>16.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic_Model_SVM_Lineaire_BoW_lem</td>\n",
       "      <td>SVM Lineaire</td>\n",
       "      <td>BoW_lem</td>\n",
       "      <td>{'best_C': '0.01', 'best_max_iter': '1000', 'b...</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>0.759299</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.773383</td>\n",
       "      <td>0.782087</td>\n",
       "      <td>0.843445</td>\n",
       "      <td>15.705644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic_Model_Logistic_Regression_BoW_stem</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>BoW_stem</td>\n",
       "      <td>{'best_C': '0.1', 'best_max_iter': '1000', 'be...</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>0.764843</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.775180</td>\n",
       "      <td>0.781517</td>\n",
       "      <td>0.845166</td>\n",
       "      <td>19.774630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic_Model_Logistic_Regression_BoW_lem</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>BoW_lem</td>\n",
       "      <td>{'best_C': '0.1', 'best_max_iter': '1000', 'be...</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.760895</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.777844</td>\n",
       "      <td>0.843118</td>\n",
       "      <td>19.458396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basic_Model_SVM_Lineaire_TF-IDF_lem</td>\n",
       "      <td>SVM Lineaire</td>\n",
       "      <td>TF-IDF_lem</td>\n",
       "      <td>{'best_C': '0.1', 'best_max_iter': '1000', 'be...</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.769170</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.773757</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.853643</td>\n",
       "      <td>9.287599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Basic_Model_Logistic_Regression_TF-IDF_lem</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF_lem</td>\n",
       "      <td>{'best_C': '1.0', 'best_max_iter': '1000', 'be...</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>0.769246</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.773302</td>\n",
       "      <td>0.775755</td>\n",
       "      <td>0.853455</td>\n",
       "      <td>12.429723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Basic_Model_SVM_Lineaire_TF-IDF_stem</td>\n",
       "      <td>SVM Lineaire</td>\n",
       "      <td>TF-IDF_stem</td>\n",
       "      <td>{'best_C': '0.1', 'best_max_iter': '1000', 'be...</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.771406</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.773099</td>\n",
       "      <td>0.774119</td>\n",
       "      <td>0.854659</td>\n",
       "      <td>9.081667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Basic_Model_Logistic_Regression_TF-IDF_stem</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF_stem</td>\n",
       "      <td>{'best_C': '1.0', 'best_max_iter': '1000', 'be...</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>0.7728</td>\n",
       "      <td>0.772491</td>\n",
       "      <td>0.772676</td>\n",
       "      <td>0.854628</td>\n",
       "      <td>7.804892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Basic_Model_Random_Forest_TF-IDF_stem</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF_stem</td>\n",
       "      <td>{'best_max_depth': '20', 'best_n_estimators': ...</td>\n",
       "      <td>0.7274</td>\n",
       "      <td>0.703690</td>\n",
       "      <td>0.7856</td>\n",
       "      <td>0.742393</td>\n",
       "      <td>0.767727</td>\n",
       "      <td>0.804815</td>\n",
       "      <td>172.471045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Basic_Model_Random_Forest_BoW_stem</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>BoW_stem</td>\n",
       "      <td>{'best_max_depth': '10', 'best_n_estimators': ...</td>\n",
       "      <td>0.7142</td>\n",
       "      <td>0.691113</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>0.730479</td>\n",
       "      <td>0.756327</td>\n",
       "      <td>0.784450</td>\n",
       "      <td>173.838465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Basic_Model_Naive_Bayes_BoW_lem</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>BoW_lem</td>\n",
       "      <td>{'best_alpha': '2.0'}</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.770021</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.759878</td>\n",
       "      <td>0.753920</td>\n",
       "      <td>0.836135</td>\n",
       "      <td>6.079231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Basic_Model_Naive_Bayes_BoW_stem</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>BoW_stem</td>\n",
       "      <td>{'best_alpha': '2.0'}</td>\n",
       "      <td>0.7629</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.759363</td>\n",
       "      <td>0.752625</td>\n",
       "      <td>0.837333</td>\n",
       "      <td>6.787270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Basic_Model_Random_Forest_TF-IDF_lem</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF_lem</td>\n",
       "      <td>{'best_max_depth': 'None', 'best_n_estimators'...</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>0.748856</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.750723</td>\n",
       "      <td>0.751848</td>\n",
       "      <td>0.828903</td>\n",
       "      <td>232.464568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Basic_Model_Naive_Bayes_TF-IDF_lem</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF_lem</td>\n",
       "      <td>{'best_alpha': '2.0'}</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>0.776894</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.759255</td>\n",
       "      <td>0.749052</td>\n",
       "      <td>0.845126</td>\n",
       "      <td>6.326715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Basic_Model_Naive_Bayes_TF-IDF_stem</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF_stem</td>\n",
       "      <td>{'best_alpha': '2.0'}</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.773451</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>0.745479</td>\n",
       "      <td>0.845566</td>\n",
       "      <td>6.951088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Basic_Model_Random_Forest_BoW_lem</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>BoW_lem</td>\n",
       "      <td>{'best_max_depth': 'None', 'best_n_estimators'...</td>\n",
       "      <td>0.7520</td>\n",
       "      <td>0.759687</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.748274</td>\n",
       "      <td>0.741590</td>\n",
       "      <td>0.832853</td>\n",
       "      <td>183.643106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Run Name                Model  \\\n",
       "0             Basic_Model_SVM_Lineaire_BoW_stem         SVM Lineaire   \n",
       "1              Basic_Model_SVM_Lineaire_BoW_lem         SVM Lineaire   \n",
       "2      Basic_Model_Logistic_Regression_BoW_stem  Logistic Regression   \n",
       "3       Basic_Model_Logistic_Regression_BoW_lem  Logistic Regression   \n",
       "4           Basic_Model_SVM_Lineaire_TF-IDF_lem         SVM Lineaire   \n",
       "5    Basic_Model_Logistic_Regression_TF-IDF_lem  Logistic Regression   \n",
       "6          Basic_Model_SVM_Lineaire_TF-IDF_stem         SVM Lineaire   \n",
       "7   Basic_Model_Logistic_Regression_TF-IDF_stem  Logistic Regression   \n",
       "8         Basic_Model_Random_Forest_TF-IDF_stem        Random Forest   \n",
       "9            Basic_Model_Random_Forest_BoW_stem        Random Forest   \n",
       "10              Basic_Model_Naive_Bayes_BoW_lem          Naive Bayes   \n",
       "11             Basic_Model_Naive_Bayes_BoW_stem          Naive Bayes   \n",
       "12         Basic_Model_Random_Forest_TF-IDF_lem        Random Forest   \n",
       "13           Basic_Model_Naive_Bayes_TF-IDF_lem          Naive Bayes   \n",
       "14          Basic_Model_Naive_Bayes_TF-IDF_stem          Naive Bayes   \n",
       "15            Basic_Model_Random_Forest_BoW_lem        Random Forest   \n",
       "\n",
       "   Vectorization                                        Best Params  Accuracy  \\\n",
       "0       BoW_stem  {'best_C': '0.01', 'best_max_iter': '1000', 'b...    0.7725   \n",
       "1        BoW_lem  {'best_C': '0.01', 'best_max_iter': '1000', 'b...    0.7691   \n",
       "2       BoW_stem  {'best_C': '0.1', 'best_max_iter': '1000', 'be...    0.7721   \n",
       "3        BoW_lem  {'best_C': '0.1', 'best_max_iter': '1000', 'be...    0.7682   \n",
       "4     TF-IDF_lem  {'best_C': '0.1', 'best_max_iter': '1000', 'be...    0.7724   \n",
       "5     TF-IDF_lem  {'best_C': '1.0', 'best_max_iter': '1000', 'be...    0.7721   \n",
       "6    TF-IDF_stem  {'best_C': '0.1', 'best_max_iter': '1000', 'be...    0.7726   \n",
       "7    TF-IDF_stem  {'best_C': '1.0', 'best_max_iter': '1000', 'be...    0.7724   \n",
       "8    TF-IDF_stem  {'best_max_depth': '20', 'best_n_estimators': ...    0.7274   \n",
       "9       BoW_stem  {'best_max_depth': '10', 'best_n_estimators': ...    0.7142   \n",
       "10       BoW_lem                              {'best_alpha': '2.0'}    0.7630   \n",
       "11      BoW_stem                              {'best_alpha': '2.0'}    0.7629   \n",
       "12    TF-IDF_lem  {'best_max_depth': 'None', 'best_n_estimators'...    0.7501   \n",
       "13    TF-IDF_lem                              {'best_alpha': '2.0'}    0.7646   \n",
       "14   TF-IDF_stem                              {'best_alpha': '2.0'}    0.7612   \n",
       "15       BoW_lem  {'best_max_depth': 'None', 'best_n_estimators'...    0.7520   \n",
       "\n",
       "    Precision  Recall  F1 Score  F2 Score   ROC AUC  Training Time (s)  \n",
       "0    0.763082  0.7904  0.776501  0.784781  0.845413          16.311300  \n",
       "1    0.759299  0.7880  0.773383  0.782087  0.843445          15.705644  \n",
       "2    0.764843  0.7858  0.775180  0.781517  0.845166          19.774630  \n",
       "3    0.760895  0.7822  0.771400  0.777844  0.843118          19.458396  \n",
       "4    0.769170  0.7784  0.773757  0.776536  0.853643           9.287599  \n",
       "5    0.769246  0.7774  0.773302  0.775755  0.853455          12.429723  \n",
       "6    0.771406  0.7748  0.773099  0.774119  0.854659           9.081667  \n",
       "7    0.772182  0.7728  0.772491  0.772676  0.854628           7.804892  \n",
       "8    0.703690  0.7856  0.742393  0.767727  0.804815         172.471045  \n",
       "9    0.691113  0.7746  0.730479  0.756327  0.784450         173.838465  \n",
       "10   0.770021  0.7500  0.759878  0.753920  0.836135           6.079231  \n",
       "11   0.770863  0.7482  0.759363  0.752625  0.837333           6.787270  \n",
       "12   0.748856  0.7526  0.750723  0.751848  0.828903         232.464568  \n",
       "13   0.776894  0.7424  0.759255  0.749052  0.845126           6.326715  \n",
       "14   0.773451  0.7388  0.755728  0.745479  0.845566           6.951088  \n",
       "15   0.759687  0.7372  0.748274  0.741590  0.832853         183.643106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results of the models\n",
    "# Display the results in a table\n",
    "def compare_models(results_df):\n",
    "    \"\"\"\n",
    "    Compares the results of different machine learning models and vectorization methods.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): Results DataFrame containing model performance metrics.\n",
    "    \"\"\"\n",
    "    if results_df.empty:\n",
    "        print(\"No results to compare.\")\n",
    "        return\n",
    "\n",
    "    # Columns to display\n",
    "    columns_to_display = [\n",
    "        \"Model\",\n",
    "        \"Vectorization\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1 Score\",\n",
    "        \"F2 Score\",\n",
    "        \"ROC AUC\",\n",
    "        \"Training Time (s)\"\n",
    "    ]\n",
    "\n",
    "    # Format the DataFrame for better readability\n",
    "    for col in [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"F2 Score\", \"ROC AUC\"]:\n",
    "        results_df[col] = results_df[col].apply(lambda x: f\"{x:.4f}\" if x is not None else \"N/A\")\n",
    "\n",
    "    if 'Training Time (s)' in results_df.columns:\n",
    "        results_df['Training Time (s)'] = results_df['Training Time (s)'].apply(lambda x: f\"{x:.2f}\" if x is not None else \"N/A\")\n",
    "\n",
    "    # Display the results\n",
    "    print(\"\\nComparison of Models and Vectorization Methods:\")\n",
    "    print(results_df[columns_to_display].to_string(index=False))\n",
    "\n",
    "    # Get the best model based on F2 Score\n",
    "    best_model = results_df.loc[results_df['F2 Score'].idxmax()]\n",
    "    print(\"\\nBest Model:\")\n",
    "    print(f\"Model: {best_model['Model']}\")\n",
    "    print(f\"Vectorization: {best_model['Vectorization']}\")\n",
    "    print(f\"F2 Score: {best_model['F2 Score']}\")\n",
    "    print(f\"Best params: {best_model['Best Params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Models and Vectorization Methods:\n",
      "              Model Vectorization Accuracy Precision Recall F1 Score F2 Score ROC AUC Training Time (s)\n",
      "       SVM Lineaire      BoW_stem   0.7725    0.7631 0.7904   0.7765   0.7848  0.8454             16.31\n",
      "       SVM Lineaire       BoW_lem   0.7691    0.7593 0.7880   0.7734   0.7821  0.8434             15.71\n",
      "Logistic Regression      BoW_stem   0.7721    0.7648 0.7858   0.7752   0.7815  0.8452             19.77\n",
      "Logistic Regression       BoW_lem   0.7682    0.7609 0.7822   0.7714   0.7778  0.8431             19.46\n",
      "       SVM Lineaire    TF-IDF_lem   0.7724    0.7692 0.7784   0.7738   0.7765  0.8536              9.29\n",
      "Logistic Regression    TF-IDF_lem   0.7721    0.7692 0.7774   0.7733   0.7758  0.8535             12.43\n",
      "       SVM Lineaire   TF-IDF_stem   0.7726    0.7714 0.7748   0.7731   0.7741  0.8547              9.08\n",
      "Logistic Regression   TF-IDF_stem   0.7724    0.7722 0.7728   0.7725   0.7727  0.8546              7.80\n",
      "      Random Forest   TF-IDF_stem   0.7274    0.7037 0.7856   0.7424   0.7677  0.8048            172.47\n",
      "      Random Forest      BoW_stem   0.7142    0.6911 0.7746   0.7305   0.7563  0.7844            173.84\n",
      "        Naive Bayes       BoW_lem   0.7630    0.7700 0.7500   0.7599   0.7539  0.8361              6.08\n",
      "        Naive Bayes      BoW_stem   0.7629    0.7709 0.7482   0.7594   0.7526  0.8373              6.79\n",
      "      Random Forest    TF-IDF_lem   0.7501    0.7489 0.7526   0.7507   0.7518  0.8289            232.46\n",
      "        Naive Bayes    TF-IDF_lem   0.7646    0.7769 0.7424   0.7593   0.7491  0.8451              6.33\n",
      "        Naive Bayes   TF-IDF_stem   0.7612    0.7735 0.7388   0.7557   0.7455  0.8456              6.95\n",
      "      Random Forest       BoW_lem   0.7520    0.7597 0.7372   0.7483   0.7416  0.8329            183.64\n",
      "\n",
      "Best Model:\n",
      "Model: SVM Lineaire\n",
      "Vectorization: BoW_stem\n",
      "F2 Score: 0.7848\n",
      "Best params: {'best_C': '0.01', 'best_max_iter': '1000', 'best_dual': 'True'}\n"
     ]
    }
   ],
   "source": [
    "compare_models(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Sentiments Analysis)",
   "language": "python",
   "name": "sentiments-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
