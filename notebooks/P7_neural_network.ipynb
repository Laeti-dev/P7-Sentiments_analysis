{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709265a1",
   "metadata": {},
   "source": [
    "# Strategies\n",
    "\n",
    "This notebook aims to test a neural network using different word embedding methods.\n",
    "\n",
    "**Word embedding methods:**\n",
    "\n",
    "| Method       | Definition                                                                 | Advantages                                                                                     | Limitations                                                                 |\n",
    "|--------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| Word2Vec     | Represents words as dense vectors in a continuous space, capturing semantic relationships based on context. | Effective for capturing semantic relationships; widely used in NLP tasks.                     | Requires large datasets; struggles with out-of-vocabulary words.            |\n",
    "| Glove        | Generates word embeddings by factorizing a co-occurrence matrix, capturing both local and global semantic relationships. | Captures both local and global context; effective for text classification and sentiment analysis. | Computationally expensive; requires pre-computed co-occurrence statistics.  |\n",
    "| USE (Universal Sentence Encoder) | Produces embeddings for entire sentences rather than individual words, leveraging deep learning models. | Captures sentence-level semantics; pre-trained models available for quick use.                | Higher computational cost; less effective for word-level tasks.             |\n",
    "| BERT |  |                 |              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dded7f0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6b913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/ikusawalaetitia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ikusawalaetitia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ikusawalaetitia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.16.2\n",
      "GPU disponible : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             fbeta_score, make_scorer, matthews_corrcoef, balanced_accuracy_score,\n",
    "                             classification_report, confusion_matrix, roc_auc_score, roc_curve)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Add Hugging Face transformers for BERT\n",
    "# try:\n",
    "#     from transformers import BertTokenizer, TFBertModel\n",
    "# except ImportError:\n",
    "#     print(\"Installing transformers library...\")\n",
    "#     import sys\n",
    "#     !{sys.executable} -m pip install transformers\n",
    "#     from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "print(\"Version:\", tf.__version__)\n",
    "print(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a01571",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43516f9",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca74829",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e4c1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text_lem</th>\n",
       "      <th>advanced_processed_text_lem</th>\n",
       "      <th>processed_text_stem</th>\n",
       "      <th>advanced_processed_text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2065378704</td>\n",
       "      <td>2009-06-07 08:28:25</td>\n",
       "      <td>juliaindelicate</td>\n",
       "      <td>@christt I really wanted to go  i didn't get t...</td>\n",
       "      <td>&lt; mention &gt; really wanted go not get go anal b...</td>\n",
       "      <td>&lt; mention &gt; really wanted go not get go anal b...</td>\n",
       "      <td>&lt; mention &gt; realli want go not get go ani anal...</td>\n",
       "      <td>&lt; mention &gt; realli want go not get go ani anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2198776518</td>\n",
       "      <td>2009-06-16 16:33:19</td>\n",
       "      <td>hxcfairy</td>\n",
       "      <td>Finally home from my sisters and I'm so tired</td>\n",
       "      <td>finally home sister tired</td>\n",
       "      <td>finally home sister tired</td>\n",
       "      <td>final home sister tire</td>\n",
       "      <td>final home sister tire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2258118867</td>\n",
       "      <td>2009-06-20 15:24:59</td>\n",
       "      <td>TranceGemini613</td>\n",
       "      <td>I really, really wish I'd known all the stuff ...</td>\n",
       "      <td>really really wish would known stuff james tel...</td>\n",
       "      <td>really really wish would known stuff james tel...</td>\n",
       "      <td>realli realli wish would known stuff jame tell...</td>\n",
       "      <td>realli realli wish would known stuff jame tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1755733793</td>\n",
       "      <td>2009-05-10 09:53:26</td>\n",
       "      <td>jwatkins5377</td>\n",
       "      <td>Can officially say I have been at work EVERYDA...</td>\n",
       "      <td>officially say work everyday week ... bad toda...</td>\n",
       "      <td>officially say work everyday week ... bad toda...</td>\n",
       "      <td>offici say work everyday thi week ... bad toda...</td>\n",
       "      <td>offici say work everyday thi week ... bad toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1881082418</td>\n",
       "      <td>2009-05-22 03:32:26</td>\n",
       "      <td>davelee</td>\n",
       "      <td>#FirstRecord The Mr Blobby single  Sorry folks.</td>\n",
       "      <td>&lt; hashtag &gt; mr blobby single sorry folk .</td>\n",
       "      <td>&lt; hashtag &gt; mr lobby single sorry folk .</td>\n",
       "      <td>&lt; hashtag &gt; mr blobbi singl sorri folk .</td>\n",
       "      <td>&lt; hashtag &gt; mr lobbi singl sorri folk .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2045678642</td>\n",
       "      <td>2009-06-05 11:04:38</td>\n",
       "      <td>johnny101</td>\n",
       "      <td>My turkey and ham salad wrap is not sitting we...</td>\n",
       "      <td>turkey ham salad wrap not sitting well .</td>\n",
       "      <td>turkey ham salad wrap not sitting well .</td>\n",
       "      <td>turkey ham salad wrap not sit well .</td>\n",
       "      <td>turkey ham salad wrap not sit well .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2323712552</td>\n",
       "      <td>2009-06-25 01:17:50</td>\n",
       "      <td>Matt_Whiting</td>\n",
       "      <td>Footy Trainin Was called off     Now i Dont kn...</td>\n",
       "      <td>footy trainin wa called dont know ? laugh loud</td>\n",
       "      <td>footy training wa called not know ? lot</td>\n",
       "      <td>footi trainin wa call dont know ? laugh loud</td>\n",
       "      <td>footi train wa call not know ? lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2200119346</td>\n",
       "      <td>2009-06-16 18:27:54</td>\n",
       "      <td>JoePaley17</td>\n",
       "      <td>Just got bacl from ftbl summer school tomorrow</td>\n",
       "      <td>got bacl ftbl summer school tomorrow</td>\n",
       "      <td>got back feel summer school tomorrow</td>\n",
       "      <td>got bacl ftbl summer school tomorrow</td>\n",
       "      <td>got back feel summer school tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2247872282</td>\n",
       "      <td>2009-06-19 19:45:15</td>\n",
       "      <td>trexsandwich</td>\n",
       "      <td>@writesfortea Cool teachers are the best, but ...</td>\n",
       "      <td>&lt; mention &gt; cool teacher best never lasted sch...</td>\n",
       "      <td>&lt; mention &gt; cool teacher best never lasted sch...</td>\n",
       "      <td>&lt; mention &gt; cool teacher best never last schoo...</td>\n",
       "      <td>&lt; mention &gt; cool teacher best never last schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1835988160</td>\n",
       "      <td>2009-05-18 07:09:13</td>\n",
       "      <td>renzzee</td>\n",
       "      <td>@rediska08 awts.  friday, parteeey! hahaha! sa...</td>\n",
       "      <td>&lt; mention &gt; awts . friday parteey ! hahaha ! s...</td>\n",
       "      <td>&lt; mention &gt; awts . friday parteey ! hahaha ! s...</td>\n",
       "      <td>&lt; mention &gt; awt . friday parteey ! hahaha ! sa...</td>\n",
       "      <td>&lt; mention &gt; awt . friday parteey ! hahaha ! sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                 date             user  \\\n",
       "0       0  2065378704  2009-06-07 08:28:25  juliaindelicate   \n",
       "1       0  2198776518  2009-06-16 16:33:19         hxcfairy   \n",
       "2       0  2258118867  2009-06-20 15:24:59  TranceGemini613   \n",
       "3       0  1755733793  2009-05-10 09:53:26     jwatkins5377   \n",
       "4       0  1881082418  2009-05-22 03:32:26          davelee   \n",
       "5       0  2045678642  2009-06-05 11:04:38        johnny101   \n",
       "6       0  2323712552  2009-06-25 01:17:50     Matt_Whiting   \n",
       "7       0  2200119346  2009-06-16 18:27:54       JoePaley17   \n",
       "8       0  2247872282  2009-06-19 19:45:15     trexsandwich   \n",
       "9       0  1835988160  2009-05-18 07:09:13          renzzee   \n",
       "\n",
       "                                                text  \\\n",
       "0  @christt I really wanted to go  i didn't get t...   \n",
       "1     Finally home from my sisters and I'm so tired    \n",
       "2  I really, really wish I'd known all the stuff ...   \n",
       "3  Can officially say I have been at work EVERYDA...   \n",
       "4    #FirstRecord The Mr Blobby single  Sorry folks.   \n",
       "5  My turkey and ham salad wrap is not sitting we...   \n",
       "6  Footy Trainin Was called off     Now i Dont kn...   \n",
       "7    Just got bacl from ftbl summer school tomorrow    \n",
       "8  @writesfortea Cool teachers are the best, but ...   \n",
       "9  @rediska08 awts.  friday, parteeey! hahaha! sa...   \n",
       "\n",
       "                                  processed_text_lem  \\\n",
       "0  < mention > really wanted go not get go anal b...   \n",
       "1                          finally home sister tired   \n",
       "2  really really wish would known stuff james tel...   \n",
       "3  officially say work everyday week ... bad toda...   \n",
       "4          < hashtag > mr blobby single sorry folk .   \n",
       "5           turkey ham salad wrap not sitting well .   \n",
       "6     footy trainin wa called dont know ? laugh loud   \n",
       "7               got bacl ftbl summer school tomorrow   \n",
       "8  < mention > cool teacher best never lasted sch...   \n",
       "9  < mention > awts . friday parteey ! hahaha ! s...   \n",
       "\n",
       "                         advanced_processed_text_lem  \\\n",
       "0  < mention > really wanted go not get go anal b...   \n",
       "1                          finally home sister tired   \n",
       "2  really really wish would known stuff james tel...   \n",
       "3  officially say work everyday week ... bad toda...   \n",
       "4           < hashtag > mr lobby single sorry folk .   \n",
       "5           turkey ham salad wrap not sitting well .   \n",
       "6            footy training wa called not know ? lot   \n",
       "7               got back feel summer school tomorrow   \n",
       "8  < mention > cool teacher best never lasted sch...   \n",
       "9  < mention > awts . friday parteey ! hahaha ! s...   \n",
       "\n",
       "                                 processed_text_stem  \\\n",
       "0  < mention > realli want go not get go ani anal...   \n",
       "1                             final home sister tire   \n",
       "2  realli realli wish would known stuff jame tell...   \n",
       "3  offici say work everyday thi week ... bad toda...   \n",
       "4           < hashtag > mr blobbi singl sorri folk .   \n",
       "5               turkey ham salad wrap not sit well .   \n",
       "6       footi trainin wa call dont know ? laugh loud   \n",
       "7               got bacl ftbl summer school tomorrow   \n",
       "8  < mention > cool teacher best never last schoo...   \n",
       "9  < mention > awt . friday parteey ! hahaha ! sa...   \n",
       "\n",
       "                        advanced_processed_text_stem  \n",
       "0  < mention > realli want go not get go ani anal...  \n",
       "1                             final home sister tire  \n",
       "2  realli realli wish would known stuff jame tell...  \n",
       "3  offici say work everyday thi week ... bad toda...  \n",
       "4            < hashtag > mr lobbi singl sorri folk .  \n",
       "5               turkey ham salad wrap not sit well .  \n",
       "6                 footi train wa call not know ? lot  \n",
       "7               got back feel summer school tomorrow  \n",
       "8  < mention > cool teacher best never last schoo...  \n",
       "9  < mention > awt . friday parteey ! hahaha ! sa...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_sample = \"../data/processed_sample_tweets.csv\"\n",
    "\n",
    "sample_df = pd.read_csv(path_to_sample, encoding='utf-8')\n",
    "# Display the first few rows of the dataframe\n",
    "sample_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90c7af",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85302e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lem shape: (30000,)\n",
      "X_test_lem shape: (10000,)\n",
      "y_train_lem shape: (30000,)\n",
      "y_test_lem shape: (10000,)\n",
      "X_train_stem shape: (30000,)\n",
      "X_val_stem shape: (10000,)\n",
      "X_test_stem shape: (10000,)\n",
      "y_train_stem shape: (30000,)\n",
      "X_val_stem shape: (10000,)\n",
      "y_test_stem shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X_lem = sample_df['processed_text_lem']\n",
    "X_stem = sample_df['processed_text_stem']\n",
    "\n",
    "y = sample_df['target']\n",
    "\n",
    "# Split the data into training, testing and validation sets\n",
    "X_temp_lem, X_test_lem, y_temp_lem, y_test_lem = train_test_split(\n",
    "    X_lem, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "X_train_lem, X_val_lem, y_train_lem, y_val_lem = train_test_split(\n",
    "    X_temp_lem, y_temp_lem,\n",
    "    test_size=0.25,  # 0.25 x 0.8 = 0.2\n",
    "    random_state=42,\n",
    "    stratify=y_temp_lem\n",
    ")\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train_lem shape: {X_train_lem.shape}\")\n",
    "print(f\"X_test_lem shape: {X_test_lem.shape}\")\n",
    "print(f\"y_train_lem shape: {y_train_lem.shape}\")\n",
    "print(f\"y_test_lem shape: {y_test_lem.shape}\")\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_temp_stem, X_test_stem, y_temp_stem, y_test_stem = train_test_split(\n",
    "    X_stem, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "X_train_stem, X_val_stem, y_train_stem, y_val_stem = train_test_split(\n",
    "    X_temp_stem, y_temp_stem,\n",
    "    test_size=0.25,  # 0.25 x 0.8 = 0.2\n",
    "    random_state=42,\n",
    "    stratify=y_temp_stem\n",
    ")\n",
    "\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train_stem shape: {X_train_stem.shape}\")\n",
    "print(f\"X_val_stem shape: {X_val_stem.shape}\")\n",
    "print(f\"X_test_stem shape: {X_test_stem.shape}\")\n",
    "print(f\"y_train_stem shape: {y_train_stem.shape}\")\n",
    "print(f\"X_val_stem shape: {X_val_stem.shape}\")\n",
    "print(f\"y_test_stem shape: {y_test_stem.shape}\")\n",
    "\n",
    "X_train_shape = X_train_lem.shape\n",
    "X_val_shape = X_val_lem.shape\n",
    "X_test_shape = X_test_lem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c479d",
   "metadata": {},
   "source": [
    "## MLFlow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2822e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://localhost:8080\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# For scikit-learn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Configuring MLflow\n",
    "load_dotenv()\n",
    "tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "print(f\"MLflow Tracking URI: {tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c459fb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing experiment 'P7-Sentiments_Analysis_neural_network' with ID: 915290206608231433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/915290206608231433', creation_time=1758900314087, experiment_id='915290206608231433', last_update_time=1758900314087, lifecycle_stage='active', name='P7-Sentiments_Analysis_neural_network', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new MLflow Experiment\n",
    "experiment_name = \"P7-Sentiments_Analysis_neural_network\"\n",
    "\n",
    "# Check if the experiment exists, create it if it doesn't\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    print(f\"Created new experiment '{experiment_name}' with ID: {experiment_id}\")\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    print(f\"Using existing experiment '{experiment_name}' with ID: {experiment_id}\")\n",
    "\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b11b80",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c08eb",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7c7dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, model_name):\n",
    "    \"\"\"\n",
    "    Plots training and validation learning curves and saves them to MLflow.\n",
    "\n",
    "    Args:\n",
    "        history: History object returned by model.fit()\n",
    "        model_name: Name of the model for labeling the plots\n",
    "    \"\"\"\n",
    "    # Create a figure with two subplots (loss and accuracy)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} - Loss Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Add tight layout to make sure plots don't overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure locally\n",
    "    learning_curve_path = f\"learning_curve_{model_name}.png\"\n",
    "    plt.savefig(learning_curve_path)\n",
    "\n",
    "    # Log the figure to MLflow\n",
    "    mlflow.log_artifact(learning_curve_path)\n",
    "\n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Learning curves for {model_name} saved and logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ccf4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Creates and saves a confusion matrix visualization.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels (should be binary 0/1 values, not probabilities)\n",
    "        model_name: Name of the model for labeling\n",
    "    \"\"\"\n",
    "    # Convert predictions to binary labels if they're probabilities\n",
    "    if isinstance(y_pred[0], (np.float32, np.float64)):\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred_binary = y_pred\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "    plt.yticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "\n",
    "    # Save the figure\n",
    "    cm_path = f\"confusion_matrix_{model_name}.png\"\n",
    "    plt.savefig(cm_path)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.log_artifact(cm_path)\n",
    "\n",
    "    # Close the figure\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Confusion matrix for {model_name} saved and logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7991036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics_summary_table(metrics, dataset_type, embedding_type):\n",
    "    \"\"\"\n",
    "    Creates and logs a detailed metrics summary table as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        metrics: Dictionary of evaluation metrics\n",
    "        dataset_type: 'validation' or 'test'\n",
    "        embedding_type: Type of embedding used (w2v, fasttext, glove)\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from the metrics dictionary\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "\n",
    "    # Add embedding type and dataset information\n",
    "    metrics_df['embedding'] = embedding_type\n",
    "    metrics_df['dataset'] = dataset_type\n",
    "\n",
    "    # Save as CSV\n",
    "    csv_path = f\"{dataset_type}_metrics_{embedding_type}.csv\"\n",
    "    metrics_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.log_artifact(csv_path)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92463131",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdce05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetVectorizer:\n",
    "    def __init__(self, preprocessor: str = None, vectoriser: str = 'w2v'):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.vectoriser = vectoriser\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        # Initialize vectorizers\n",
    "        if vectoriser == 'w2v':\n",
    "            from gensim.models import Word2Vec\n",
    "            self.model = None # Will be initialized during fit\n",
    "        elif vectoriser == 'fasttext':\n",
    "            from gensim.models import FastText\n",
    "            self.model = FastText(vector_size=100, window=5, min_count=1, workers=4)\n",
    "        elif vectoriser == 'glove':\n",
    "            self.model = None  # Will be loaded from gensim-data when needed\n",
    "        elif vectoriser == 'use':\n",
    "            import tensorflow_hub as hub\n",
    "            self.model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "        elif vectoriser == 'bert':\n",
    "            # Initialize BERT tokenizer and model\n",
    "            from transformers import BertTokenizer, TFBertModel\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "            self.model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported vectoriser. Choose from 'w2v', 'fasttext', 'glove', 'use', or 'bert'.\")\n",
    "\n",
    "    def preprocess(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Cleans and preprocesses a single text string by replacing URLs, mentions, and hashtags,\n",
    "        converting to lowercase, removing special characters, and removing stopwords.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text string to process.\n",
    "\n",
    "        Returns:\n",
    "            str: The processed text string.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        # Replace URLs with <URL>\n",
    "        processed = re.sub(r'https?://\\S+', '<URL>', text)\n",
    "        # Replace mentions with <MENTION>\n",
    "        processed = re.sub(r'@[A-Za-z0-9_]+', '<MENTION>', processed)\n",
    "        # Separate # from word and replace the word with <HASHTAG>\n",
    "        processed = re.sub(r'#([A-Za-z0-9_]+)', r'#<HASHTAG>', processed)\n",
    "\n",
    "        # Convert text to lowercase\n",
    "        processed = processed.lower()\n",
    "\n",
    "        # Remove special characters and numbers, keeping !, ?, and ellipsis (...)\n",
    "        # Also keeps the placeholders <URL>, <MENTION>, <HASHTAG>\n",
    "        processed = re.sub(r'[^a-z0-9\\s.!?<>#]', '', processed)\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(processed)\n",
    "\n",
    "        # Initialize lemmatizer\n",
    "        if self.preprocessor == 'lemmatization':\n",
    "            tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        # Initialize stemmer\n",
    "        if self.preprocessor == 'stemming':\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "\n",
    "        # Define negative words that should not be removed\n",
    "        negative_words = {\n",
    "            'no', 'not', 'nor', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\",\n",
    "            \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\",\n",
    "            \"needn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\",\n",
    "            \"never\", \"none\", \"nobody\", \"nothing\", \"nowhere\", \"neither\"\n",
    "        }\n",
    "        # Create a set of stopwords to remove, excluding the negative words\n",
    "        stop_words_to_remove = set(stopwords.words('english')) - negative_words\n",
    "\n",
    "        # remove stopwords, and join back to string\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words_to_remove]\n",
    "\n",
    "        return ' '.join(filtered_tokens)\n",
    "\n",
    "    def fit_transform(self, texts: pd.Series):\n",
    "        \"\"\"\n",
    "        Fits the vectorizer model (if applicable) and transforms the input texts into vectors.\n",
    "\n",
    "        Args:\n",
    "            texts (pd.Series): Series of text strings to fit and transform.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Array of vectorized texts.\n",
    "        \"\"\"\n",
    "        processed_texts = texts.apply(self.preprocess).tolist()\n",
    "\n",
    "        if self.vectoriser == 'w2v':\n",
    "            from gensim.models import Word2Vec\n",
    "            tokenized_texts = [text.split() for text in processed_texts]\n",
    "            self.model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "            vectors = np.array([np.mean([self.model.wv[word] for word in text.split() if word in self.model.wv] or [np.zeros(100)], axis=0) for text in processed_texts])\n",
    "        elif self.vectoriser == 'glove':\n",
    "            import gensim.downloader as api\n",
    "            if self.model is None:\n",
    "                self.model = api.load(\"glove-twitter-100\")\n",
    "            vectors = np.array([np.mean([self.model[word] for word in text.split() if word in self.model] or [np.zeros(100)], axis=0) for text in processed_texts])\n",
    "        elif self.vectoriser == 'fasttext':\n",
    "            tokenized_texts = [text.split() for text in processed_texts]\n",
    "            self.model.build_vocab(tokenized_texts, update=True)\n",
    "            self.model.train(tokenized_texts, total_examples=len(tokenized_texts), epochs=self.model.epochs)\n",
    "            vectors = np.array([np.mean([self.model.wv[word] for word in text.split() if word in self.model.wv] or [np.zeros(100)], axis=0) for text in processed_texts])\n",
    "        # elif self.vectoriser == 'bert':\n",
    "\n",
    "        elif self.vectoriser == 'bert':\n",
    "            # For BERT, we need to tokenize the text and return the encoded features\n",
    "            # This returns a batch of token IDs, attention masks, and token type IDs\n",
    "            encoded_inputs = self.tokenizer(\n",
    "                processed_texts,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "\n",
    "            # Get BERT embeddings - using CLS token (first token) as the sentence representation\n",
    "            outputs = self.model(encoded_inputs)\n",
    "            # We'll use the CLS token (first token) embeddings as the sentence representation\n",
    "            vectors = outputs.last_hidden_state[:, 0, :].numpy()  # Shape: (batch_size, hidden_size=768)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported vectoriser. Choose from 'w2v', 'fasttext', 'use', or 'bert'.\")\n",
    "\n",
    "        # Chech for 2D array\n",
    "        if vectors.ndim == 1:\n",
    "            vectors = vectors.reshape(-1, 1)\n",
    "        elif vectors.ndim == 2 and vectors.shape[1] == 1:\n",
    "            vectors = vectors.reshape(-1, vectors.shape[1])\n",
    "\n",
    "        return vectors\n",
    "\n",
    "    def transform(self, texts: pd.Series):\n",
    "        \"\"\"\n",
    "        Transforms the input texts into vectors using the fitted vectorizer model.\n",
    "\n",
    "        Args:\n",
    "            texts (pd.Series): Series of text strings to transform.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Array of vectorized texts.\n",
    "        \"\"\"\n",
    "        processed_texts = texts.apply(self.preprocess).tolist()\n",
    "\n",
    "        if self.vectoriser == 'w2v':\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"The Word2Vec model has not been fitted. Call fit_transform first.\")\n",
    "            vectors = np.array([np.mean([self.model.wv[word] for word in text.split() if word in self.model.wv] or [np.zeros(100)], axis=0) for text in processed_texts])\n",
    "        elif self.vectoriser == 'fasttext':\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"The FastText model has not been fitted. Call fit_transform first.\")\n",
    "            vectors = np.array([np.mean([self.model.wv[word] for word in text.split() if word in self.model.wv] or [np.zeros(100)], axis=0) for text in processed_texts])\n",
    "        elif self.vectoriser == 'glove':\n",
    "            import gensim.downloader as api\n",
    "            if self.model is None:\n",
    "                self.model = api.load(\"glove-twitter-100\")\n",
    "            vectors = np.array([np.mean([self.model[word] for word in text.split() if word in self.model] or [np.zeros(100)], axis=0) for text in processed_texts])\n",
    "        elif self.vectoriser == 'use':\n",
    "            vectors = self.model(processed_texts).numpy()\n",
    "        elif self.vectoriser == 'bert':\n",
    "            # For BERT, we need to tokenize the text and return the encoded features\n",
    "            encoded_inputs = self.tokenizer(\n",
    "                processed_texts,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "\n",
    "            # Get BERT embeddings - using CLS token (first token) as the sentence representation\n",
    "            outputs = self.model(encoded_inputs)\n",
    "            vectors = outputs.last_hidden_state[:, 0, :].numpy()  # Shape: (batch_size, hidden_size=768)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported vectoriser. Choose from 'w2v', 'fasttext', 'use', or 'bert'.\")\n",
    "\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class LSTMTweetClassifier:\n",
    "    def __init__(self, embedding:str, embedding_dim: int, lstm_units: int=128, max_length: int = 100):\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.model = None\n",
    "        self.word_index = self.tokenizer.word_index\n",
    "        self.model_dir = \"../models\"\n",
    "\n",
    "    def build_embedding_matrix(self):\n",
    "        if self.embedding == 'w2v':\n",
    "            from gensim.models import Word2Vec\n",
    "            embedding_model = Word2Vec.load(os.path.join(self.model_dir, \"word2vec.model\"))\n",
    "        elif self.embedding == 'fasttext':\n",
    "            from gensim.models import FastText\n",
    "            embedding_model = FastText.load(os.path.join(self.model_dir, \"fasttext.model\"))\n",
    "        elif self.embedding == 'glove':\n",
    "            import gensim.downloader as api\n",
    "            embedding_model = api.load(\"glove-twitter-100\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported embedding type. Choose 'w2v', 'fasttext', or 'glove'.\")\n",
    "\n",
    "        word_index = self.tokenizer.word_index\n",
    "        vocab_size = len(word_index) + 1\n",
    "        embedding_matrix = np.zeros((vocab_size, self.embedding_dim))\n",
    "\n",
    "        for word, i in word_index.items():\n",
    "            if self.embedding == 'glove':\n",
    "                if word in embedding_model:\n",
    "                    embedding_matrix[i] = embedding_model[word]\n",
    "                else:\n",
    "                    embedding_matrix[i] = np.random.normal(size=(self.embedding_dim,))\n",
    "            else:  # For Word2Vec and FastText\n",
    "                if word in embedding_model.wv:\n",
    "                    embedding_matrix[i] = embedding_model.wv[word]\n",
    "                else:\n",
    "                    embedding_matrix[i] = np.random.normal(size=(self.embedding_dim,))\n",
    "\n",
    "        return embedding_matrix\n",
    "\n",
    "    def build_RNN_model(self, vocab_size: int, embedding_matrix: np.ndarray):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=vocab_size, output_dim=self.embedding_dim, weights=[embedding_matrix], input_length=100, trainable=False))\n",
    "        model.add(SimpleRNN(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))\n",
    "        model.add(SimpleRNN(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3))\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def build_LSTM_model(self, vocab_size: int, embedding_matrix: np.ndarray, bidirectionnal: bool):\n",
    "        \"\"\"Builds the LSTM model architecture.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary.\n",
    "            embedding_matrix (np.ndarray): Pre-trained embedding matrix.\n",
    "        Returns:\n",
    "            keras.Model: Compiled LSTM model.\n",
    "        \"\"\"\n",
    "        # Initialize the model\n",
    "        model = Sequential()\n",
    "        # Add embedding layer with pre-trained weights\n",
    "        model.add(Embedding(input_dim=vocab_size,\n",
    "                            output_dim=self.embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=self.max_length,\n",
    "                            trainable=False))  # Freezing the embedding layer\n",
    "        if bidirectionnal:\n",
    "            # Add a Bidirectional LSTM layer\n",
    "            model.add(Bidirectional(LSTM(self.lstm_units, return_sequences=False)))\n",
    "        else:\n",
    "            model.add(LSTM(self.lstm_units, return_sequences=False))\n",
    "        # Add a Dense output layer with sigmoid activation for binary classification\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(learning_rate=0.001),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def get_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculates and returns various classification metrics.\n",
    "\n",
    "        Args:\n",
    "            y_true (np.ndarray): True labels.\n",
    "            y_pred (np.ndarray): Predicted labels.\n",
    "        Returns:\n",
    "            dict: Dictionary containing accuracy, precision, recall, f1-score, and MCC.\n",
    "        \"\"\"\n",
    "        accuracy = np.mean((y_pred > 0.5).flatten() == y_true)\n",
    "        specificity = np.sum((y_pred < 0.5).flatten() & (y_true == 0)) / np.sum(y_true == 0)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"specificity\", specificity)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'specificity': specificity,\n",
    "            'auc': auc\n",
    "        }\n",
    "\n",
    "    def train_and_evaluate(self, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
    "        \"\"\"Trains the LSTM model and evaluates it on the validation set.\n",
    "\n",
    "        Args:\n",
    "            X_train (np.ndarray): Training feature vectors.\n",
    "            y_train (np.ndarray): Training labels.\n",
    "            X_val (np.ndarray): Validation feature vectors.\n",
    "            y_val (np.ndarray): Validation labels.\n",
    "            epochs (int, optional): Number of training epochs. Defaults to 10.\n",
    "            batch_size (int, optional): Batch size for training. Defaults to 32.\n",
    "        Returns:\n",
    "            dict: Dictionary containing evaluation metrics on the validation set.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been built. Call build_model first.\")\n",
    "        with mlflow.start_run(run_name=f\"LSTM_{self.embedding}_{self.epochs}epochs_{self.lstm_units}units\", nested= True):\n",
    "            # log model parameters\n",
    "            mlflow.log_param(\"embedding\", self.embedding)\n",
    "            mlflow.log_param(\"embedding_dim\", self.embedding_dim)\n",
    "            mlflow.log_param(\"lstm_units\", self.lstm_units)\n",
    "            mlflow.log_param(\"max_length\", self.max_length)\n",
    "            mlflow.log_param(\"epochs\", epochs)\n",
    "            mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "            start_time = time.time()\n",
    "            history = self.model.fit(X_train, y_train,\n",
    "                                     validation_data=(X_val, y_val),\n",
    "                                     epochs=epochs,\n",
    "                                     batch_size=batch_size,\n",
    "                                     verbose=1)\n",
    "            training_time = time.time() - start_time\n",
    "            mlflow.log_metric(\"training_time\", training_time)\n",
    "\n",
    "            # Log training and validation metrics for each epoch\n",
    "            for epoch in range(epochs):\n",
    "                mlflow.log_metric(\"train_loss\", history.history['loss'][epoch], step=epoch)\n",
    "                mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][epoch], step=epoch)\n",
    "                mlflow.log_metric(\"val_loss\", history.history['val_loss'][epoch], step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][epoch], step=epoch)\n",
    "\n",
    "            # Plot and save learning curves\n",
    "            model_name = f\"LSTM_{self.embedding}_{self.lstm_units}units\"\n",
    "            plot_learning_curves(history, model_name)\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            start_prediction_time = time.time()\n",
    "            y_val_pred = self.model.predict(X_val).flatten()\n",
    "            prediction_time = time.time() - start_prediction_time\n",
    "            mlflow.log_metric(\"prediction_time\", prediction_time)\n",
    "\n",
    "            # Calulate validation metrics\n",
    "            val_metrics = {\n",
    "                'accuracy': accuracy_score(y_val, (y_val_pred > 0.5).astype(int)),\n",
    "                'precision': precision_score(y_val, (y_val_pred > 0.5).astype(int)),\n",
    "                'recall': recall_score(y_val, (y_val_pred > 0.5).astype(int)),\n",
    "                'f1_score': f1_score(y_val, (y_val_pred > 0.5).astype(int)),\n",
    "                'specificity': np.sum(np.logical_and((y_val_pred < 0.5).flatten(), y_val == 0)) / np.sum(y_val == 0),\n",
    "                'roc_auc': roc_auc_score(y_val, y_val_pred),\n",
    "                'prediction_time': prediction_time\n",
    "            }\n",
    "\n",
    "            # Log metrics to MLflow\n",
    "            for metric_name, metric_value in val_metrics.items():\n",
    "                mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "            # Create and log detailed metrics summary\n",
    "            val_metrics_df = log_metrics_summary_table(val_metrics, 'validation', self.embedding)\n",
    "\n",
    "            # check if artifact folder exists\n",
    "\n",
    "            # ROC AUC proba\n",
    "            y_val_proba = self.model.predict(X_val).flatten()\n",
    "            fpr, tpr, thresholds = roc_curve(y_val, y_val_proba)\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % val_metrics['roc_auc'])\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve - LSTM with {self.embedding} Embeddings')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "\n",
    "            # Create the artifact directory if it doesn't exist\n",
    "            os.makedirs(\"artifacts\", exist_ok=True)\n",
    "            roc_path = f\"roc_curve_{self.embedding}.png\"\n",
    "            plt.savefig(roc_path)\n",
    "            mlflow.log_artifact(roc_path)\n",
    "            plt.close()\n",
    "\n",
    "            # Create and log confusion matrix\n",
    "            y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "            model_name = f\"LSTM_{self.embedding}_{self.lstm_units}units\"\n",
    "            plot_confusion_matrix(y_val, y_val_pred_binary, model_name)\n",
    "\n",
    "            # Log the model\n",
    "            mlflow.keras.log_model(self.model, f\"LSTM_{self.embedding}_{self.lstm_units}units_model\")\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "            result= mlflow.register_model(f\"runs:/{run_id}/LSTM_{self.embedding}_{self.lstm_units}units_model\", f\"LSTM_{self.embedding}_{self.lstm_units}units_model\")\n",
    "\n",
    "    def fit(self, text: pd.Series, labels: pd.Series, test_size:float = 0.2, val_split:float = 0.2,epochs: int=10, batch_size: int=32):\n",
    "        # Tokenize and pad sequences\n",
    "        self.tokenizer.fit_on_texts(text)\n",
    "        sequences = self.tokenizer.texts_to_sequences(text)\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=self.max_length, padding='post', truncating='post')\n",
    "\n",
    "        vocab_size = len(self.tokenizer.word_index) + 1  # +1 for padding token\n",
    "\n",
    "        # Build embedding matrix\n",
    "        embedding_matrix = self.build_embedding_matrix()\n",
    "\n",
    "        # Build the model\n",
    "        self.build_model(vocab_size, embedding_matrix)\n",
    "\n",
    "        # split the data into training/val and test sets\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            padded_sequences, labels, test_size=test_size, random_state=42, stratify=labels\n",
    "        )\n",
    "\n",
    "        # Split into train set into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_split, random_state=42, stratify=y_temp)\n",
    "\n",
    "        print(f\"X_train shape: {X_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        self.epochs = epochs\n",
    "        self.train_and_evaluate(X_train, y_train, X_val, y_val, epochs, batch_size)\n",
    "\n",
    "        # Final evaluation on the test set\n",
    "        y_test_pred = self.model.predict(X_test).flatten()\n",
    "        test_metrics = self.get_metrics(y_test, y_test_pred)\n",
    "        print(\"Test Metrics:\", test_metrics)\n",
    "        for metric_name, metric_value in test_metrics.items():\n",
    "            mlflow.log_metric(f\"test_{metric_name}\", metric_value)\n",
    "\n",
    "        # Create and log detailed metrics summary for test set\n",
    "        test_metrics_df = log_metrics_summary_table(test_metrics, 'test', self.embedding)\n",
    "\n",
    "        # Create and log confusion matrix for test set\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        model_name = f\"LSTM_{self.embedding}_{self.lstm_units}units_TEST\"\n",
    "        plot_confusion_matrix(y_test, y_test_pred_binary, model_name)\n",
    "\n",
    "        # ROC Curve for test set\n",
    "        fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr_test, tpr_test, color='blue', lw=2,\n",
    "                label=f'ROC curve (area = {roc_auc_score(y_test, y_test_pred):.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Test Set ROC - LSTM with {self.embedding} Embeddings')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        test_roc_path = f\"test_roc_curve_{self.embedding}.png\"\n",
    "        plt.savefig(test_roc_path)\n",
    "        mlflow.log_artifact(test_roc_path)\n",
    "        plt.close()\n",
    "\n",
    "    def predict(self, texts: pd.Series):\n",
    "        \"\"\"Predicts the sentiment of the input texts.\n",
    "\n",
    "        Args:\n",
    "            texts (pd.Series): Series of text strings to predict.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Array of predicted labels.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been built or trained. Call fit first.\")\n",
    "\n",
    "        # Preprocess and tokenize the input texts\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=self.max_length, padding='post', truncating='post')\n",
    "\n",
    "        # Predict using the trained model\n",
    "        predictions = self.model.predict(padded_sequences).flatten()\n",
    "        predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "        return predicted_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64b951",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4353b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config =[\n",
    "    # {\n",
    "    #     'preprocessor': 'lemmatization',\n",
    "    #     'train': X_train_lem,\n",
    "    #     'val': X_val_lem,\n",
    "    #     'test': X_test_lem,\n",
    "    #     'labels': y,\n",
    "    #     'embedding': 'w2v',\n",
    "    #     'embedding_dim': 100,\n",
    "    #     'lstm_units': 128,\n",
    "    #     'max_length': 100,\n",
    "    #     'epochs': 5,\n",
    "    #     'batch_size': 32\n",
    "    # },\n",
    "    # {\n",
    "    #     'preprocessor': 'lemmatization',\n",
    "    #     'train': X_train_lem,\n",
    "    #     'val': X_val_lem,\n",
    "    #     'test': X_test_lem,\n",
    "    #     'labels': y,\n",
    "    #     'embedding': 'fasttext',\n",
    "    #     'embedding_dim': 100,\n",
    "    #     'lstm_units': 128,\n",
    "    #     'max_length': 100,\n",
    "    #     'epochs': 5,\n",
    "    #     'batch_size': 32\n",
    "    # },\n",
    "    {\n",
    "        'preprocessor': 'lemmatization',\n",
    "        'train': X_train_lem,\n",
    "        'val': X_val_lem,\n",
    "        'test': X_test_lem,\n",
    "        'labels': y,\n",
    "        'embedding': 'glove',\n",
    "        'embedding_dim': 100,\n",
    "        'lstm_units': 128,\n",
    "        'max_length': 100,\n",
    "        'epochs': 5,\n",
    "        'batch_size': 32\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bb52495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "print(api.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "924723e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"../models/\"\n",
    "def train_and_save_gensim_models(tokenized_corpus: pd.Series, vectorsize: int, path:str=PATH):\n",
    "    # --- Train and Save Word2Vec Model ---\n",
    "    print(\"Training Word2Vec model...\")\n",
    "    w2v_model = Word2Vec(sentences=tokenized_corpus,\n",
    "                        vector_size=vectorsize,  # Should match 'embedding_dim' in your config\n",
    "                        window=5,\n",
    "                        min_count=1,\n",
    "                        workers=4)\n",
    "    w2v_model.save(path+\"word2vec.model\")\n",
    "    print(\"Word2Vec model saved as word2vec.model\")\n",
    "\n",
    "\n",
    "    # --- Train and Save FastText Model ---\n",
    "    print(\"\\nTraining FastText model...\")\n",
    "    ft_model = FastText(sentences=tokenized_corpus,\n",
    "                        vector_size=vectorsize,  # Should match 'embedding_dim' in your config\n",
    "                        window=5,\n",
    "                        min_count=1,\n",
    "                        workers=4)\n",
    "    ft_model.save(path+\"fasttext.model\")\n",
    "    print(\"FastText model saved as fasttext.model\")\n",
    "\n",
    "    # Note: GloVe model is pre-trained and loaded directly from gensim-data\n",
    "    # No training or saving needed for GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ebc674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   target                        50000 non-null  int64 \n",
      " 1   ids                           50000 non-null  int64 \n",
      " 2   date                          50000 non-null  object\n",
      " 3   user                          50000 non-null  object\n",
      " 4   text                          50000 non-null  object\n",
      " 5   processed_text_lem            50000 non-null  object\n",
      " 6   advanced_processed_text_lem   50000 non-null  object\n",
      " 7   processed_text_stem           50000 non-null  object\n",
      " 8   advanced_processed_text_stem  50000 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df = sample_df.dropna(subset=['text', 'target'])\n",
    "document = clean_df[\"text\"]\n",
    "labels = clean_df[\"target\"]\n",
    "\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e33ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec and FastText models (GloVe is pre-trained and will be loaded when needed)\n",
      "Training Word2Vec model...\n",
      "Word2Vec model saved as word2vec.model\n",
      "\n",
      "Training FastText model...\n",
      "Word2Vec model saved as word2vec.model\n",
      "\n",
      "Training FastText model...\n",
      "FastText model saved as fasttext.model\n",
      "Training LSTM with glove embeddings...\n",
      "FastText model saved as fasttext.model\n",
      "Training LSTM with glove embeddings...\n",
      "X_train shape: (32000, 100)\n",
      "X_val shape: (8000, 100)\n",
      "X_test shape: (10000, 100)\n",
      "Epoch 1/5\n",
      "X_train shape: (32000, 100)\n",
      "X_val shape: (8000, 100)\n",
      "X_test shape: (10000, 100)\n",
      "Epoch 1/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.7211 - loss: 0.5479 - val_accuracy: 0.7425 - val_loss: 0.5260\n",
      "Epoch 2/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.7211 - loss: 0.5479 - val_accuracy: 0.7425 - val_loss: 0.5260\n",
      "Epoch 2/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.7630 - loss: 0.4896 - val_accuracy: 0.7614 - val_loss: 0.4921\n",
      "Epoch 3/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.7630 - loss: 0.4896 - val_accuracy: 0.7614 - val_loss: 0.4921\n",
      "Epoch 3/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.7877 - loss: 0.4502 - val_accuracy: 0.7665 - val_loss: 0.4844\n",
      "Epoch 4/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.7877 - loss: 0.4502 - val_accuracy: 0.7665 - val_loss: 0.4844\n",
      "Epoch 4/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8060 - loss: 0.4241 - val_accuracy: 0.7598 - val_loss: 0.4951\n",
      "Epoch 5/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8060 - loss: 0.4241 - val_accuracy: 0.7598 - val_loss: 0.4951\n",
      "Epoch 5/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8359 - loss: 0.3704 - val_accuracy: 0.7635 - val_loss: 0.4924\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8359 - loss: 0.3704 - val_accuracy: 0.7635 - val_loss: 0.4924\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 15:25:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/10 15:25:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/10/10 15:25:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/10/10 15:25:33 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/10 15:25:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/10/10 15:25:33 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/10/10 15:25:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'LSTM_glove_128units_model' already exists. Creating a new version of this model...\n",
      "2025/10/10 15:25:34 WARNING mlflow.tracking._model_registry.fluent: Run with id 29f1463d30e34065a4b6064fb5fc59e9 has no artifacts at artifact path 'LSTM_glove_128units_model', registering model based on models:/m-14fd22124cd748d79541f2ef389397c9 instead\n",
      "2025/10/10 15:25:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM_glove_128units_model, version 2\n",
      "Registered model 'LSTM_glove_128units_model' already exists. Creating a new version of this model...\n",
      "2025/10/10 15:25:34 WARNING mlflow.tracking._model_registry.fluent: Run with id 29f1463d30e34065a4b6064fb5fc59e9 has no artifacts at artifact path 'LSTM_glove_128units_model', registering model based on models:/m-14fd22124cd748d79541f2ef389397c9 instead\n",
      "2025/10/10 15:25:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM_glove_128units_model, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " View run LSTM_glove_5epochs_128units at: http://localhost:8080/#/experiments/915290206608231433/runs/29f1463d30e34065a4b6064fb5fc59e9\n",
      " View experiment at: http://localhost:8080/#/experiments/915290206608231433\n",
      "\u001b[1m  4/313\u001b[0m \u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'LSTM_glove_128units_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "Test Metrics: {'accuracy': 0.7568, 'specificity': 0.7706, 'auc': 0.84141632}\n",
      " View run LSTM_glove_5epochs_128units_model at: http://localhost:8080/#/experiments/915290206608231433/runs/d876ae30831a417abeb61a77e6d4f695\n",
      " View experiment at: http://localhost:8080/#/experiments/915290206608231433\n",
      "Completed training for glove embeddings.\n",
      "Test Metrics: {'accuracy': 0.7568, 'specificity': 0.7706, 'auc': 0.84141632}\n",
      " View run LSTM_glove_5epochs_128units_model at: http://localhost:8080/#/experiments/915290206608231433/runs/d876ae30831a417abeb61a77e6d4f695\n",
      " View experiment at: http://localhost:8080/#/experiments/915290206608231433\n",
      "Completed training for glove embeddings.\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"P7-Sentiments_Analysis_neural_network\"\n",
    "# document = sample_df[\"text\"]\n",
    "# labels = sample_df[\"target\"]\n",
    "validation_metrics = []\n",
    "\n",
    "# Train Word2Vec and FastText models on the tokenized processed text\n",
    "# Note: GloVe is pre-trained and doesn't need training\n",
    "print(\"Training Word2Vec and FastText models (GloVe is pre-trained and will be loaded when needed)\")\n",
    "tokenized_corpus = document.apply(str.split)\n",
    "train_and_save_gensim_models(tokenized_corpus, vectorsize=100)\n",
    "\n",
    "for cfg in config:\n",
    "    with mlflow.start_run(run_name=f\"LSTM_{cfg['embedding']}_{cfg['epochs']}epochs_{cfg['lstm_units']}units_model\", nested=False):\n",
    "\n",
    "        print(f\"Training LSTM with {cfg['embedding']} embeddings...\")\n",
    "        model = LSTMTweetClassifier(embedding=cfg['embedding'],\n",
    "                                    embedding_dim=cfg['embedding_dim'],\n",
    "                                    lstm_units=cfg['lstm_units'],\n",
    "                                    max_length=cfg['max_length'])\n",
    "\n",
    "        # Training\n",
    "        model.fit(document, labels, epochs=cfg['epochs'], batch_size=cfg['batch_size'])\n",
    "\n",
    "        mlflow.end_run()\n",
    "        print(f\"Completed training for {cfg['embedding']} embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba73cf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing experiment 'P7-Sentiments_Analysis_neural_network' with ID: 915290206608231433\n"
     ]
    }
   ],
   "source": [
    "# Create the experiment if it doesn't exist\n",
    "experiment_name = \"P7-Sentiments_Analysis_neural_network\"\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "        print(f\"Created experiment '{experiment_name}' with ID: {experiment_id}\")\n",
    "    else:\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\"Using existing experiment '{experiment_name}' with ID: {experiment_id}\")\n",
    "\n",
    "    # Set the active experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Error with MLflow setup: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e66a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>embedding</th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>epochs</th>\n",
       "      <th>max_length</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>training_time</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29f1463d30e34065a4b6064fb5fc59e9</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.844474</td>\n",
       "      <td>0.763500</td>\n",
       "      <td>0.370362</td>\n",
       "      <td>0.763500</td>\n",
       "      <td>152.823117</td>\n",
       "      <td>0.835906</td>\n",
       "      <td>4.296780</td>\n",
       "      <td>0.492444</td>\n",
       "      <td>0.77175</td>\n",
       "      <td>0.767921</td>\n",
       "      <td>0.75525</td>\n",
       "      <td>0.761533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d876ae30831a417abeb61a77e6d4f695</td>\n",
       "      <td>LSTM_glove_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841416</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.841416</td>\n",
       "      <td>0.7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52e306e2772448c1849c419c74b25c16</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.847352</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.357749</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>152.198973</td>\n",
       "      <td>0.843125</td>\n",
       "      <td>4.336998</td>\n",
       "      <td>0.513578</td>\n",
       "      <td>0.81300</td>\n",
       "      <td>0.794956</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.758368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d693a63906af4a5f978ff76b5ff7c195</td>\n",
       "      <td>LSTM_glove_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa4696301cc74bd59a0316eac345e667</td>\n",
       "      <td>LSTM_glove_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74a884d7c23243688652947286030c54</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.782248</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>152.451962</td>\n",
       "      <td>0.729375</td>\n",
       "      <td>4.344721</td>\n",
       "      <td>0.561974</td>\n",
       "      <td>0.71550</td>\n",
       "      <td>0.708802</td>\n",
       "      <td>0.69250</td>\n",
       "      <td>0.700556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3205b86fe0a946399d577bd4cb0c89ce</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787984</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.787984</td>\n",
       "      <td>0.7228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010b366dbbd4bbba3edf2c1d55d0342</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.754739</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>0.480329</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>151.806146</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>4.412064</td>\n",
       "      <td>0.613900</td>\n",
       "      <td>0.69950</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>0.67925</td>\n",
       "      <td>0.686198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c2dd5010f80c4740ad7899a449aff2a5</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94ebec2f9bef412c8f38777f9d592e0a</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.890865</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>275.115491</td>\n",
       "      <td>0.768960</td>\n",
       "      <td>4.066765</td>\n",
       "      <td>0.427517</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.812124</td>\n",
       "      <td>0.81050</td>\n",
       "      <td>0.811311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4d787195918746468d4fe447ceb289c6</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>142521e57609499ba7f2be319e72b928</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.887990</td>\n",
       "      <td>0.803250</td>\n",
       "      <td>0.482841</td>\n",
       "      <td>0.803250</td>\n",
       "      <td>271.703856</td>\n",
       "      <td>0.768580</td>\n",
       "      <td>4.362148</td>\n",
       "      <td>0.430828</td>\n",
       "      <td>0.83350</td>\n",
       "      <td>0.822778</td>\n",
       "      <td>0.77300</td>\n",
       "      <td>0.797113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84a4e871a87e489db612124ad0169154</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14f07c4330374f26bb38e5aa075aef69</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.894731</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.472045</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>272.751914</td>\n",
       "      <td>0.774120</td>\n",
       "      <td>4.464208</td>\n",
       "      <td>0.431794</td>\n",
       "      <td>0.89425</td>\n",
       "      <td>0.871272</td>\n",
       "      <td>0.71575</td>\n",
       "      <td>0.785891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1b94f6ed96c746f0854220e272f1fdc1</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>66678ca23d0f4bf79369eb05574209ee</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>0.492224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.558807</td>\n",
       "      <td>0.759640</td>\n",
       "      <td>4.520098</td>\n",
       "      <td>0.445012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bdc916b56d1143b5a1ca7bda8031f828</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2c1fb330a10840cdbd74917a0cb370fb</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>e614b4dcd5f04fb78bb3c95e0071fd8f</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5fbefa2aa28747c8bb6b658e952bec8b</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1a8ade3d04ef4ccb9fa72d754bb884ea</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              run_id                              run_name  \\\n",
       "0   29f1463d30e34065a4b6064fb5fc59e9           LSTM_glove_5epochs_128units   \n",
       "1   d876ae30831a417abeb61a77e6d4f695     LSTM_glove_5epochs_128units_model   \n",
       "2   52e306e2772448c1849c419c74b25c16           LSTM_glove_5epochs_128units   \n",
       "3   d693a63906af4a5f978ff76b5ff7c195     LSTM_glove_5epochs_128units_model   \n",
       "4   aa4696301cc74bd59a0316eac345e667     LSTM_glove_5epochs_128units_model   \n",
       "5   74a884d7c23243688652947286030c54        LSTM_fasttext_5epochs_128units   \n",
       "6   3205b86fe0a946399d577bd4cb0c89ce  LSTM_fasttext_5epochs_128units_model   \n",
       "7   2010b366dbbd4bbba3edf2c1d55d0342             LSTM_w2v_5epochs_128units   \n",
       "8   c2dd5010f80c4740ad7899a449aff2a5       LSTM_w2v_5epochs_128units_model   \n",
       "9   94ebec2f9bef412c8f38777f9d592e0a             LSTM_w2v_5epochs_128units   \n",
       "10  4d787195918746468d4fe447ceb289c6       LSTM_w2v_5epochs_128units_model   \n",
       "11  142521e57609499ba7f2be319e72b928             LSTM_w2v_5epochs_128units   \n",
       "12  84a4e871a87e489db612124ad0169154       LSTM_w2v_5epochs_128units_model   \n",
       "13  14f07c4330374f26bb38e5aa075aef69             LSTM_w2v_5epochs_128units   \n",
       "14  1b94f6ed96c746f0854220e272f1fdc1       LSTM_w2v_5epochs_128units_model   \n",
       "15  66678ca23d0f4bf79369eb05574209ee             LSTM_w2v_5epochs_128units   \n",
       "16  bdc916b56d1143b5a1ca7bda8031f828       LSTM_w2v_5epochs_128units_model   \n",
       "17  2c1fb330a10840cdbd74917a0cb370fb       LSTM_w2v_5epochs_128units_model   \n",
       "18  e614b4dcd5f04fb78bb3c95e0071fd8f       LSTM_w2v_5epochs_128units_model   \n",
       "19  5fbefa2aa28747c8bb6b658e952bec8b       LSTM_w2v_5epochs_128units_model   \n",
       "20  1a8ade3d04ef4ccb9fa72d754bb884ea       LSTM_w2v_5epochs_128units_model   \n",
       "\n",
       "   embedding lstm_units embedding_dim epochs max_length   roc_auc  \\\n",
       "0      glove        128           100      5        100  0.844474   \n",
       "1       None       None          None   None       None       NaN   \n",
       "2      glove        128           100      5        100  0.847352   \n",
       "3       None       None          None   None       None       NaN   \n",
       "4       None       None          None   None       None       NaN   \n",
       "5   fasttext        128           100      5        100  0.782248   \n",
       "6       None       None          None   None       None       NaN   \n",
       "7        w2v        128           100      5        100  0.754739   \n",
       "8       None       None          None   None       None       NaN   \n",
       "9        w2v        128           100      5        100  0.890865   \n",
       "10      None       None          None   None       None       NaN   \n",
       "11       w2v        128           100      5        100  0.887990   \n",
       "12      None       None          None   None       None       NaN   \n",
       "13       w2v        128           100      5        100  0.894731   \n",
       "14      None       None          None   None       None       NaN   \n",
       "15       w2v        128           100      5        100       NaN   \n",
       "16      None       None          None   None       None       NaN   \n",
       "17      None       None          None   None       None       NaN   \n",
       "18      None       None          None   None       None       NaN   \n",
       "19      None       None          None   None       None       NaN   \n",
       "20      None       None          None   None       None       NaN   \n",
       "\n",
       "    val_accuracy  train_loss  accuracy  training_time  train_accuracy  \\\n",
       "0       0.763500    0.370362  0.763500     152.823117        0.835906   \n",
       "1            NaN         NaN  0.756800            NaN             NaN   \n",
       "2       0.769000    0.357749  0.769000     152.198973        0.843125   \n",
       "3            NaN         NaN       NaN            NaN             NaN   \n",
       "4            NaN         NaN       NaN            NaN             NaN   \n",
       "5       0.704000    0.534061  0.704000     152.451962        0.729375   \n",
       "6            NaN         NaN  0.718100            NaN             NaN   \n",
       "7       0.689375    0.480329  0.689375     151.806146        0.771563   \n",
       "8            NaN         NaN  0.689100            NaN             NaN   \n",
       "9       0.811500    0.478890  0.811500     275.115491        0.768960   \n",
       "10           NaN         NaN       NaN            NaN             NaN   \n",
       "11      0.803250    0.482841  0.803250     271.703856        0.768580   \n",
       "12           NaN         NaN       NaN            NaN             NaN   \n",
       "13      0.805000    0.472045  0.805000     272.751914        0.774120   \n",
       "14           NaN         NaN       NaN            NaN             NaN   \n",
       "15      0.795250    0.492224       NaN     273.558807        0.759640   \n",
       "16           NaN         NaN       NaN            NaN             NaN   \n",
       "17           NaN         NaN       NaN            NaN             NaN   \n",
       "18           NaN         NaN       NaN            NaN             NaN   \n",
       "19           NaN         NaN       NaN            NaN             NaN   \n",
       "20           NaN         NaN       NaN            NaN             NaN   \n",
       "\n",
       "    prediction_time  val_loss  specificity  precision   recall  f1_score  \\\n",
       "0          4.296780  0.492444      0.77175   0.767921  0.75525  0.761533   \n",
       "1               NaN       NaN      0.77060        NaN      NaN       NaN   \n",
       "2          4.336998  0.513578      0.81300   0.794956  0.72500  0.758368   \n",
       "3               NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "4               NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "5          4.344721  0.561974      0.71550   0.708802  0.69250  0.700556   \n",
       "6               NaN       NaN      0.72280        NaN      NaN       NaN   \n",
       "7          4.412064  0.613900      0.69950   0.693289  0.67925  0.686198   \n",
       "8               NaN       NaN      0.69520        NaN      NaN       NaN   \n",
       "9          4.066765  0.427517      0.81250   0.812124  0.81050  0.811311   \n",
       "10              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "11         4.362148  0.430828      0.83350   0.822778  0.77300  0.797113   \n",
       "12              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "13         4.464208  0.431794      0.89425   0.871272  0.71575  0.785891   \n",
       "14              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "15         4.520098  0.445012          NaN        NaN      NaN       NaN   \n",
       "16              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "17              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "18              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "19              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "20              NaN       NaN          NaN        NaN      NaN       NaN   \n",
       "\n",
       "         auc  test_accuracy  test_auc  test_specificity  \n",
       "0        NaN            NaN       NaN               NaN  \n",
       "1   0.841416         0.7568  0.841416            0.7706  \n",
       "2        NaN            NaN       NaN               NaN  \n",
       "3        NaN            NaN       NaN               NaN  \n",
       "4        NaN            NaN       NaN               NaN  \n",
       "5        NaN            NaN       NaN               NaN  \n",
       "6   0.787984         0.7181  0.787984            0.7228  \n",
       "7        NaN            NaN       NaN               NaN  \n",
       "8   0.754897         0.6891  0.754897            0.6952  \n",
       "9        NaN            NaN       NaN               NaN  \n",
       "10       NaN            NaN       NaN               NaN  \n",
       "11       NaN            NaN       NaN               NaN  \n",
       "12       NaN            NaN       NaN               NaN  \n",
       "13       NaN            NaN       NaN               NaN  \n",
       "14       NaN            NaN       NaN               NaN  \n",
       "15       NaN            NaN       NaN               NaN  \n",
       "16       NaN            NaN       NaN               NaN  \n",
       "17       NaN            NaN       NaN               NaN  \n",
       "18       NaN            NaN       NaN               NaN  \n",
       "19       NaN            NaN       NaN               NaN  \n",
       "20       NaN            NaN       NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>embedding</th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>epochs</th>\n",
       "      <th>max_length</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d876ae30831a417abeb61a77e6d4f695</td>\n",
       "      <td>LSTM_glove_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.841416</td>\n",
       "      <td>0.7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3205b86fe0a946399d577bd4cb0c89ce</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.787984</td>\n",
       "      <td>0.7228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c2dd5010f80c4740ad7899a449aff2a5</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29f1463d30e34065a4b6064fb5fc59e9</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52e306e2772448c1849c419c74b25c16</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d693a63906af4a5f978ff76b5ff7c195</td>\n",
       "      <td>LSTM_glove_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa4696301cc74bd59a0316eac345e667</td>\n",
       "      <td>LSTM_glove_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74a884d7c23243688652947286030c54</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010b366dbbd4bbba3edf2c1d55d0342</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94ebec2f9bef412c8f38777f9d592e0a</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4d787195918746468d4fe447ceb289c6</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>142521e57609499ba7f2be319e72b928</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84a4e871a87e489db612124ad0169154</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14f07c4330374f26bb38e5aa075aef69</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1b94f6ed96c746f0854220e272f1fdc1</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>66678ca23d0f4bf79369eb05574209ee</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bdc916b56d1143b5a1ca7bda8031f828</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2c1fb330a10840cdbd74917a0cb370fb</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>e614b4dcd5f04fb78bb3c95e0071fd8f</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5fbefa2aa28747c8bb6b658e952bec8b</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1a8ade3d04ef4ccb9fa72d754bb884ea</td>\n",
       "      <td>LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              run_id                              run_name  \\\n",
       "1   d876ae30831a417abeb61a77e6d4f695     LSTM_glove_5epochs_128units_model   \n",
       "6   3205b86fe0a946399d577bd4cb0c89ce  LSTM_fasttext_5epochs_128units_model   \n",
       "8   c2dd5010f80c4740ad7899a449aff2a5       LSTM_w2v_5epochs_128units_model   \n",
       "0   29f1463d30e34065a4b6064fb5fc59e9           LSTM_glove_5epochs_128units   \n",
       "2   52e306e2772448c1849c419c74b25c16           LSTM_glove_5epochs_128units   \n",
       "3   d693a63906af4a5f978ff76b5ff7c195     LSTM_glove_5epochs_128units_model   \n",
       "4   aa4696301cc74bd59a0316eac345e667     LSTM_glove_5epochs_128units_model   \n",
       "5   74a884d7c23243688652947286030c54        LSTM_fasttext_5epochs_128units   \n",
       "7   2010b366dbbd4bbba3edf2c1d55d0342             LSTM_w2v_5epochs_128units   \n",
       "9   94ebec2f9bef412c8f38777f9d592e0a             LSTM_w2v_5epochs_128units   \n",
       "10  4d787195918746468d4fe447ceb289c6       LSTM_w2v_5epochs_128units_model   \n",
       "11  142521e57609499ba7f2be319e72b928             LSTM_w2v_5epochs_128units   \n",
       "12  84a4e871a87e489db612124ad0169154       LSTM_w2v_5epochs_128units_model   \n",
       "13  14f07c4330374f26bb38e5aa075aef69             LSTM_w2v_5epochs_128units   \n",
       "14  1b94f6ed96c746f0854220e272f1fdc1       LSTM_w2v_5epochs_128units_model   \n",
       "15  66678ca23d0f4bf79369eb05574209ee             LSTM_w2v_5epochs_128units   \n",
       "16  bdc916b56d1143b5a1ca7bda8031f828       LSTM_w2v_5epochs_128units_model   \n",
       "17  2c1fb330a10840cdbd74917a0cb370fb       LSTM_w2v_5epochs_128units_model   \n",
       "18  e614b4dcd5f04fb78bb3c95e0071fd8f       LSTM_w2v_5epochs_128units_model   \n",
       "19  5fbefa2aa28747c8bb6b658e952bec8b       LSTM_w2v_5epochs_128units_model   \n",
       "20  1a8ade3d04ef4ccb9fa72d754bb884ea       LSTM_w2v_5epochs_128units_model   \n",
       "\n",
       "   embedding lstm_units embedding_dim epochs max_length  test_accuracy  \\\n",
       "1       None       None          None   None       None         0.7568   \n",
       "6       None       None          None   None       None         0.7181   \n",
       "8       None       None          None   None       None         0.6891   \n",
       "0      glove        128           100      5        100            NaN   \n",
       "2      glove        128           100      5        100            NaN   \n",
       "3       None       None          None   None       None            NaN   \n",
       "4       None       None          None   None       None            NaN   \n",
       "5   fasttext        128           100      5        100            NaN   \n",
       "7        w2v        128           100      5        100            NaN   \n",
       "9        w2v        128           100      5        100            NaN   \n",
       "10      None       None          None   None       None            NaN   \n",
       "11       w2v        128           100      5        100            NaN   \n",
       "12      None       None          None   None       None            NaN   \n",
       "13       w2v        128           100      5        100            NaN   \n",
       "14      None       None          None   None       None            NaN   \n",
       "15       w2v        128           100      5        100            NaN   \n",
       "16      None       None          None   None       None            NaN   \n",
       "17      None       None          None   None       None            NaN   \n",
       "18      None       None          None   None       None            NaN   \n",
       "19      None       None          None   None       None            NaN   \n",
       "20      None       None          None   None       None            NaN   \n",
       "\n",
       "    test_auc  test_specificity  \n",
       "1   0.841416            0.7706  \n",
       "6   0.787984            0.7228  \n",
       "8   0.754897            0.6952  \n",
       "0        NaN               NaN  \n",
       "2        NaN               NaN  \n",
       "3        NaN               NaN  \n",
       "4        NaN               NaN  \n",
       "5        NaN               NaN  \n",
       "7        NaN               NaN  \n",
       "9        NaN               NaN  \n",
       "10       NaN               NaN  \n",
       "11       NaN               NaN  \n",
       "12       NaN               NaN  \n",
       "13       NaN               NaN  \n",
       "14       NaN               NaN  \n",
       "15       NaN               NaN  \n",
       "16       NaN               NaN  \n",
       "17       NaN               NaN  \n",
       "18       NaN               NaN  \n",
       "19       NaN               NaN  \n",
       "20       NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_run_metrics(metric_prefixes=None, run_filter=None, sort_by=None, ascending=False, include_params=True):\n",
    "    \"\"\"\n",
    "    Function to fetch and display a comparison dataframe of metrics across different runs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric_prefixes : list or None\n",
    "        List of metric prefixes to filter (e.g., ['test_', 'val_']). If None, includes all metrics.\n",
    "    run_filter : dict or None\n",
    "        Dictionary of parameter name and values to filter runs (e.g., {'embedding': 'w2v'})\n",
    "    sort_by : str or None\n",
    "        Metric name to sort results by (e.g., 'test_accuracy')\n",
    "    ascending : bool\n",
    "        Sort order for the 'sort_by' column\n",
    "    include_params : bool\n",
    "        Whether to include key parameters (embedding, lstm_units, etc.) in the output\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with run metrics and optionally parameters\n",
    "    \"\"\"\n",
    "    # Get client to query metrics\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Get all runs from our experiment\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "    if len(runs) == 0:\n",
    "        print(\"No runs found in the experiment\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Filter out comparison runs\n",
    "    runs = runs[runs['tags.mlflow.runName'] != 'model_comparison']\n",
    "\n",
    "    # Apply run filter if provided\n",
    "    if run_filter:\n",
    "        for param_name, param_value in run_filter.items():\n",
    "            param_key = f'params.{param_name}'\n",
    "            if param_key in runs.columns:\n",
    "                if isinstance(param_value, list):\n",
    "                # For lists, check if value is in the list\n",
    "                    runs = runs[runs[param_key].isin(param_value)]\n",
    "                else:\n",
    "                    # For single values, use equality\n",
    "                    runs = runs[runs[param_key] == param_value]\n",
    "\n",
    "    # Extract key information\n",
    "    comparison_data = []\n",
    "    key_params = ['embedding', 'lstm_units', 'embedding_dim', 'epochs', 'max_length']\n",
    "\n",
    "    for _, run in runs.iterrows():\n",
    "        # Extract run info\n",
    "        run_id = run['run_id']\n",
    "        run_name = run['tags.mlflow.runName']\n",
    "\n",
    "        # Get metrics based on prefixes\n",
    "        metrics = {}\n",
    "        for col in run.index:\n",
    "            if col.startswith('metrics.'):\n",
    "                metric_name = col.replace('metrics.', '')\n",
    "                include_metric = True\n",
    "\n",
    "                if metric_prefixes:\n",
    "                    include_metric = any(metric_name.startswith(prefix) for prefix in metric_prefixes)\n",
    "\n",
    "                if include_metric:\n",
    "                    metrics[metric_name] = run[col]\n",
    "\n",
    "        # Get parameters if requested\n",
    "        params = {}\n",
    "        if include_params:\n",
    "            for param in key_params:\n",
    "                param_key = f'params.{param}'\n",
    "                if param_key in run.index:\n",
    "                    params[param] = run[param_key]\n",
    "\n",
    "        # Create entry\n",
    "        entry = {\n",
    "            'run_id': run_id,\n",
    "            'run_name': run_name,\n",
    "        }\n",
    "        entry.update(params)\n",
    "        entry.update(metrics)\n",
    "        comparison_data.append(entry)\n",
    "\n",
    "    # Create dataframe\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Sort if requested\n",
    "    if sort_by and sort_by in comparison_df.columns:\n",
    "        comparison_df = comparison_df.sort_values(by=sort_by, ascending=ascending)\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "# Examples of using the function:\n",
    "# Get all metrics for all runs\n",
    "all_metrics_df = compare_run_metrics()\n",
    "display(all_metrics_df)\n",
    "\n",
    "# Get only test metrics, sorted by accuracy\n",
    "test_metrics_df = compare_run_metrics(\n",
    "    metric_prefixes=['test_'],\n",
    "    sort_by='test_accuracy',\n",
    "    ascending=False\n",
    ")\n",
    "display(test_metrics_df)\n",
    "\n",
    "# Compare only w2v and fasttext models\n",
    "embedding_comparison = compare_run_metrics(\n",
    "    metric_prefixes=['test_'],\n",
    "    run_filter={'embedding': ['w2v', 'fasttext']},\n",
    "    sort_by='test_f1_score',\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e8420",
   "metadata": {},
   "source": [
    "# Comparing Model Performance\n",
    "\n",
    "Use the `compare_run_metrics` function to create customized comparison tables of different model runs. This function provides flexible filtering and sorting options to help you analyze model performance.\n",
    "\n",
    "## Examples:\n",
    "\n",
    "1. **Compare all embedding types with test metrics only:**\n",
    "   ```python\n",
    "   test_comparison = compare_run_metrics(\n",
    "       metric_prefixes=['test_'],\n",
    "       sort_by='test_accuracy', \n",
    "       ascending=False\n",
    "   )\n",
    "   display(test_comparison)\n",
    "   ```\n",
    "\n",
    "2. **Compare specific embedding types:**\n",
    "   ```python\n",
    "   # Compare w2v vs glove\n",
    "   w2v_vs_glove = compare_run_metrics(\n",
    "       metric_prefixes=['test_'],\n",
    "       run_filter={'embedding': ['w2v', 'glove']},\n",
    "       sort_by='test_f1_score'\n",
    "   )\n",
    "   display(w2v_vs_glove)\n",
    "   ```\n",
    "\n",
    "3. **Create a heatmap of key metrics:**\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   \n",
    "   # Get test metrics for all models\n",
    "   metrics_df = compare_run_metrics(metric_prefixes=['test_'])\n",
    "   \n",
    "   # Select key metrics to visualize\n",
    "   key_metrics = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1_score', 'test_roc_auc']\n",
    "   heatmap_df = metrics_df.pivot(index='embedding', columns=None, values=key_metrics)\n",
    "   \n",
    "   # Plot heatmap\n",
    "   plt.figure(figsize=(12, 8))\n",
    "   sns.heatmap(heatmap_df, annot=True, cmap='YlGnBu', fmt='.3f')\n",
    "   plt.title('Embedding Performance Comparison')\n",
    "   plt.tight_layout()\n",
    "   plt.show()\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f657af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAGGCAYAAAAAW6PhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOl1JREFUeJzt3XmUl2XdP/DPIIPigogOoBKbLGoi7hq4oOROpYbmUmr8IrVFHyst9ZSg4uP2WCb6lFkarhiFCpprYiJirimk4JIpojCogMo2wPzOdT1nJgZmEoZl7hler3O+Z+bery/8cc/9/n6+n6uksrKyMgAAAAAAKIRmDT0AAAAAAAD+TWgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAKadiwYVFSUpJfU6ZMaejhAADAOiO0BQCgcCorK+PGG2/MgW3ym9/8pqGHBAAA64zQFgCAwnnooYfirbfeilNOOSXat28fv//972PRokUNPSwAAFgnhLYAABROVWXt4MGD46STTopZs2bF6NGja9132rRpceaZZ0b37t2jZcuW0aZNm9hrr73i4osvrve+qcK3X79+tV7v1FNPzdtTqFwl/Z7WpW1Tp06Nr33ta9G2bdto1qxZjBs3Lu/z3HPPxVlnnRW9e/fO191oo43yOH74wx/GRx99VOe/xciRI6N///7Vx3Tu3DlOOOGEePbZZ/P2X//61/naQ4cOrfX4999/P0pLS6NXr151XgMAgGIR2gIAUCgzZsyIe++9N3r06BF9+vTJQWhyww03rLBvCi5TCHrttdfGNttskwPZFPJuttlmMWTIkHrvW19vvPFG7L333jnETef+9re/Ha1ataoOou+8887o2bNnfPOb34wzzjgjtt5667j66qujb9++8fHHH6/QIiK99+OPPz5eeumlOOaYY+Lss8+O/fbbL5544okYO3Zs3i9dJ13jt7/9bSxZsmSFMf3ud7+LxYsXx2mnnbZG3iMAAGtf83VwDQAAWGk33XRTVFRUVIe1O+20U+y+++7x2GOPxeuvvx7dunXL61O7hGOPPTY+/PDDuO222+LEE09coaq2yqrsuzrGjx8f5513Xlx66aUrbEvrr7vuuthggw1qrE9h67e+9a24/vrr48c//nH1+hTyprYQe+65Zzz88MOx+eabV29L4ezMmTPz75tuuml84xvfyOf+85//HAMGDFihN/DGG2+c9wEAoHFQaQsAQGFUhYyprcDJJ59cvT4FuGnbshOSjRkzJle0fvnLX14hhE06dOhQr31XR7t27eLCCy+sdVunTp1WCGyTQYMG5UrZBx98sMb6VBFc1f5g2cA2SedJVbpVUtVu1b7L9wb+5z//mds1LH8OAACKS2gLAEBh/OUvf8ktBg4++ODYdtttq9enoLVFixZx88035yrcZOLEifnn4Ycf/pnnXZV9V0dqv7DhhhvWui2Ne/jw4bHvvvvm/rQpeE29aFNAPXfu3Hj33Xer9/30009j0qRJOQTeddddP/O6n//852P//ffPlbbvvPNO9fqqlhKnn376Gnl/AACsG0JbAAAKoypkrGqNUCWFnF/60pdyS4B77rknr5s9e3b+uWy4W5dV2Xd1tG/fvs5tqdr1+9//frz33nvxla98Jc4999xclZteqQp24cKFqzXe73znO7ltQqpUrpqALPUG3mWXXfJkawAANB562gIAUAjl5eVx9913599POOGE/Kor2B04cGC0bt06Ly9boVqXVdk3SRWwafKu2lQFqnUdV5s0Cdro0aPji1/8Yq6Gbd7833+GL126NK644orVGm+SJipLlbmpR+7PfvYzE5ABADRiQlsAAAohTbqVJgxLk46l6tDapMrRRx55JPdp3WefffK6FIJ+1tf/V2XfZIsttqjRZqBKqmR98cUXY1WlCdSS1FN32cA2+dvf/hbz58+vsW6TTTbJE7ClFgkvvPDCSrVIKC0tzROaDRs2LPfwTRW3aZKyk046aZXHCwBAw9IeAQCAQqiaZOz666/PgWNtr1Q1WjVZWWqX0Llz5xzk3nHHHSucb9q0adW/r8q+SWon8Pbbb+eJvJZ1ySWXxL/+9a9Vfm/p2sm4ceNqrE/tHr773e/WesyZZ56Zf6b3PGfOnBrbUnVuarOwvG9/+9u5V+73vve9HGynXsCbbbbZKo8XAICGVVKZ/uoFAIAGlMLMAw88MHr16hUvvfRSnfu99dZb0bVr19w7NoWqqer1kEMOiY8++igOOOCAXFG7YMGCeOWVV+LRRx+t0eIgtShY2X3TcpoMLU0qlnrRpp66EyZMyEHojjvumMebfq8KY9O4unTpEqecckqeLK22Ct10zSeffDK+8IUv5MnIZsyYkSt/e/bsGW+++WaulE3nqZL+TE/nu+WWW6KsrCz3wU0/p0+fnidsGzRoUAwZMmSFa6X9UjidPPfcc7Hbbrutxv8MAAANQaUtAACFqbJNX+//T1JImvrCpirT1AJgjz32yMHtGWeckStgr7766hxypr6zF110UY1jV2Xf/v375/66n//85+POO+/MrRvStVMrg06dOq3y+0vVrylITddOoesvf/nLGD9+fH6/Dz74YA5sa+uPO2LEiLj11ltjhx12iLvuuiuP+fHHH4/99tsvt1qoTQpzq96vwBYAoHFSaQsAAE1Iqr4dOnRobiHx//7f/2vo4QAAUA9CWwAAaCI+/vjj6N69e1RUVOSJ1DbeeOOGHhIAAPVQc+paAACg0bnvvvvi+eefzy0jUq/cq666SmALANCICW0BAKCR+8Mf/pD77rZr1y7OO++8OPvssxt6SAAANJX2CP/4xz/yBA1pJt40q++PfvSj2Guvvf7jMZMnT84TNKSvf2255Zbx1a9+Nfr167fOxgwAAAAAsCY1iwJZuHBhnpV3ZSdMmDlzZlx22WV5Vt8rrrgijjzyyPjVr36VZwUGAAAAAGiMCtUeYdddd82vlfXQQw9F27Zt4+STT87LHTp0iFdffTX39Npll13W4kgBAAAAANaDSttV9dprr0WvXr1qrOvdu3dMnTq1zmPSTLrz5s2r8UrrAAAAAACKoFCVtqtq9uzZsfnmm9dYl5bnz58fixYtihYtWqxwzOjRo2PUqFHVy3379o2zzjprnYwXAAAAAKBJh7b1cfTRR8eAAQOql0tKSvLPNPHZ4sWLG3BkAAAAAEBT1rx589hiiy0+e79oxFq3bh1z5sypsS4tt2zZstYq26S0tDS/lpcCW20SAAAAAICG1qh72nbv3j1efvnlGuteeuml6NGjR4ONCQAAAACgyYS2CxYsiLfeeiu/kpkzZ+bfZ82alZdvv/32GD58ePX+hxxySN7n1ltvjXfffTcefPDBeOqpp+LII49ssPcAAAAAALA6CtUe4Y033oihQ4dWL48YMSL/POCAA+K73/1u7jtbFeAmbdu2jZ/85Cfx+9//Pu6///7Ycsst4/TTT49ddtmlQcYPAAAAALC6SiorKytX+yxNQHl5uZ62AAAAAMBak+baKisra1ztEQAAAAAA1ndCWwAAAACAAhHaAgAAAAAUiNAWAAAAAKBAhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgQhtAQAAAAAKRGgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCAAAAABSI0BYAAAAAoECEtgAAAAAABSK0BQAAAAAoEKEtAAAAAECBCG0BAAAAAApEaAsAAAAAUCBCWwAAAACAAhHaAgAAAAAUiNAWAAAAAKBAhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgQhtAQAAAAAKRGgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCAAAAABSI0BYAAAAAoECEtgAAAAAABSK0BQAAAAAoEKEtAAAAAECBCG0BAAAAAApEaAsAAAAAUCDNo2AeeOCBGDNmTMyePTs6deoUgwYNim7dutW5/3333RcPPfRQzJo1K1q1ahV77713nHjiidGiRYt1Om4AAAAAgCZXaTthwoQYMWJEDBw4MC6//PIc2g4bNizmzJlT6/7jx4+P22+/PY499tj4+c9/Hqeffno89dRTcccdd6zzsQMAAAAANLnQduzYsdG/f/848MADo0OHDjF48OBcMfvYY4/Vuv+UKVOiZ8+ese+++0bbtm2jd+/e0bdv33j99dfX+dgBAAAAAJpUaLt48eJ48803o1evXtXrmjVrlpenTp1a6zEpsE3HVIW0M2bMiBdeeCF23XXXOq9TUVER8+bNq37Nnz9/LbwbAAAAAIBG3tN27ty5sXTp0mjdunWN9Wl5+vTptR6TKmzTcT/96U/z8pIlS+Lggw+OY445ps7rjB49OkaNGlW93KVLl9yKAQAAAACgCAoT2tbH5MmTcwj7rW99K7p37x7vv/9+3HTTTTmUTX1xa3P00UfHgAEDqpdLSkrW4YgBAAAAABpJaNuqVavcDmH27Nk11qfl5atvq4wcOTL233//3Ac36dixYyxYsCBuuOGGXG2bzre80tLS/AIAAAAAKKLC9LRt3rx5dO3aNSZNmlS9LrVLSMs9evSo9ZiFCxeuUClbW1ALAAAAANBYFKbSNkltC6677roc3nbr1i3uv//+HMz269cvbx8+fHi0adMmTjzxxLy8++67x3333Zf70la1R0jVt2m98BYAAAAAaIwKFdr26dMnTyx211135bYInTt3jvPPP7+6PcKsWbNqVNZ+9atfzct33nlnfPjhh7nFQgpsTzjhhAZ8FwAAAAAA9VdSWVlZuRrHNxnl5eVRUVHR0MMAAAAAAJqoNNdWWVnZZ+6nhwAAAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCAAAAABSI0BYAAAAAoECEtgAAAAAABSK0BQAAAAAoEKEtAAAAAECBCG0BAAAAAApEaAsAAAAAUCBCWwAAAACAAhHaAgAAAAAUiNAWAAAAAKBAhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgQhtAQAAAAAKRGgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAICmENr+5je/iSlTpqzZ0QAAAAAArOea1/fA8ePHxyOPPBJt27aN/fbbL7+23nrrNTs6AAAAAID1TEllZWVlfQ6sqKiIZ599Np544ol48cUXY8mSJbHddtvF/vvvH3369IlWrVpFY1JeXp7fEwAAAADA2lBaWhplZWVrL7Rd1ieffBJPPfVUrr599dVXY4MNNoidd945B7h77LFHtGjRIopOaAsAAAAANJnQdlmzZs2KW265JSZOnJiXW7ZsGfvss08cfvjh0alTpygqoS0AAAAAUITQtt49bWsLa1OlbWqXMG3atNh0001zm4TmzZvndePGjYtBgwbFIYccsqYuCQAAAADQ5KxWpe2nn36a2yKkUHbKlCm5LcKuu+6a2yLstttuObBNUgXrNddcE1OnTo0bbrghikilLQAAAADQqCttr7zyyjwB2eLFi6Nbt265ijZV1qYK29oGk1okPPPMM/W9HAAAAADAeqHeoe1bb70VX/rSl+KAAw6Irbfe+jP3TxOTXXjhhfW9HAAAAADAemGNT0TWWGmPAAAAAAAUoT1Cs/peYObMmfHss8/WuT1tS/sAAAAAALDy6h3ajhgxIv785z/Xuf3BBx+M22+/vb6nBwAAAABYL9U7tH3ttddyn9q69OrVK1555ZX6nh4AAAAAYL1U79D2k08+iZYtW9a5faONNsr7AAAAAACwDkLbrbbaKl599dU6t6cq2zZt2tT39AAAAAAA66V6h7Z9+/aNJ598Mu6///5YunRp9fr0e1o3YcKE2HfffdfUOAEAAAAA1gsllZWVlfU5sKKiIi677LKYNGlStGrVKrbZZpu8fvr06TF37tzYcccd4/zzz4/S0tJoDMrLy/N7AgAAAABYG1JWWlZWtvZC26qq2scffzyefvrpmDFjRl7Xrl272GeffWL//fePZs3qXci7zgltAQAAAIBGH9o2JUJbAAAAAKAIoW3jKYUFAAAAAFgPNF+dg2fPnh1/+ctf4s0334z58+fXmJAsKSkpiZ/97GerO0YAAAAAgPVGvUPbf/3rXzFkyJBYtGhRnoTs7bffjg4dOsS8efPiww8/zL1tt9xyy1U+7wMPPBBjxozJgXCnTp1i0KBB0a1btzr3//TTT+OOO+6Iv/3tb/HJJ5/k8uJTTjkldtttt/q+NQAAAACAxhfa3n777bHRRhvFlVdeGS1atIjBgwfHN7/5zdhpp53iqaeeihtvvDHOPPPMVTrnhAkTYsSIEflc3bt3j/vuuy+GDRsWv/jFL2LzzTdfYf/FixfHJZdcEq1atYof/OAH0aZNm5g1a1ZsvPHG9X1bAAAAAAANqt49bV999dU4+OCDY6uttopmzf7vNFXtEb7whS/EvvvuG7fccssqnXPs2LHRv3//OPDAA3PVbgpvUyD82GOP1bp/as2QqmvPOeec2H777aNt27ax4447RufOnev7tgAAAAAAGmelbWVlZXX1a6psTcFtClCrdOzYMYeqKytVzabeuEcddVT1unTOXr16xdSpU2s95rnnnssVub/97W/j2WefzRW3ffv2zeeoCpKXV1FRkV/L9t1t2bLlSo8TAAAAAKCQoW2qap05c2b+PQWkafnll1+OPn365HVTpkyJTTbZZKXPN3fu3Fyp27p16xrr0/L06dNrPWbGjBlRXl6eq3rPO++8eP/993NbhiVLlsSxxx5b6zGjR4+OUaNGVS936dIlLr/88pUeJwAAAABAIUPbnXfeOSZOnBgnnHBCXk6tElI7hBTkpircyZMnx5e+9KVYm9J1UnXtaaedloPjrl275knQ7r333jpD26OPPjoGDBhQo9IWAAAAAKDRh7bHHHNMrnBNbQ2aN28eRx55ZCxcuDCefvrpHKB+9atfzfusrBS+puNmz55dY31aXr76tkpan669bCuEbbfdNh9TNa7llZaW5hcAAAAAQJMJbVOFawpK02RhVcFoqlhNQW161WsgzZvnStlJkybFXnvtldeldglp+bDDDqv1mJ49e8aTTz6Z96sKbt97773YYostag1sAQAAAACKrvbZuj5DqmIdNGhQ/PnPf16jg0ltCx599NEYN25cTJs2LfenTdW7/fr1y9uHDx8et99+e/X+hxxySJ787Oabb859b59//vncs/bQQw9do+MCAAAAAFhX6lWOmtoLpNYEa7rNQJrELE1Idtddd+UWB507d47zzz+/uj3CrFmzavSg3WqrreKCCy6I3//+93HOOedEmzZt4vDDD4+jjjpqjY4LAAAAAGBdKalMvQ7q4c4774wXXnghhg0b1iRaEZSXl0dFRUVDDwMAAAAAaKJSEWxZWdln7lfvtLVjx47xzDPPxA9+8IPcviBdrEWLFivst/fee9f3EgAAAAAA6516V9p+7WtfW6n9Ro4cGY2BSlsAAAAAoFFX2l544YX1PRQAAAAAgDUd2u644471PRQAAAAAgDo0q2sDAAAAAACNqNJ26NChn7lPSUlJ/OxnP6vvJQAAAAAA1jv1Dm3T/GUplF3W0qVL84ReH3zwQbRv3z7atGmzJsYIAAAAALDeKKlM6esa9txzz8UNN9wQP/nJT6JLly7RGKSwuaKioqGHAQAAAAA0UaWlpVFWVtYwPW1333332G+//eLmm29eG6cHAAAAAGiy1tpEZO3atYs33nhjbZ0eAAAAAKBJWiuh7ZIlS+Kpp56KzTbbbG2cHgAAAACgyar3RGTXX399revnzZsXr732WsyePTtOPvnk1RkbAAAAAMB6p96h7eTJk1dYV1JSEptsskn07Nkz+vfvH717917d8QEAAAAArFdKKisrKxt6EEVQXl4eFRUVDT0MAAAAAKCJKi0tjbKysoabiAwAAAAAgFVX79B2/Pjxcd111/3HnrcTJkyo7+kBAAAAANZL9Q5t77vvvlzOW5cWLVrkfQAAAAAAWAeh7fTp06Nz5851bu/UqVPeBwAAAACAlbdaPW3nzZtX57ZPP/00Fi9evDqnBwAAAABY79Q7tE1Vtk8++WStwWxFRUXuedulS5fVHR8AAAAAwHql3qHtUUcdFW+//XYMHTo0nn322ZgxY0Z+pd+HDBkS77zzTt4HAAAAAICVV1JZWVkZ9TRu3Li46aabYsGCBTXWb7TRRnHKKafEQQcdFI1FeXl5rhAGAAAAAFgbSktLo6ysbO2GtlV9bV966aVcZZu0a9cuevfuHS1btozGRGgLAAAAADSJ0LapENoCAAAAAEUIbevd0zZV195+++11br/jjjti0qRJ9T09AAAAAMB6qd6h7R//+Mf44IMP6tz+4Ycf5n0AAAAAAFgHoe3bb78d3bt3r3P7dtttl/cBAAAAAGAdhLaLFy/Or/+0feHChfU9PQAAAADAeqneoe3nPve5+Nvf/lbrtjS32dNPPx0dOnRYnbEBAAAAAKx36h3aHnbYYTFlypS4+uqrcxuEJUuW5Ne//vWvvG7q1Kl5HwAAAAAAVl7zqKf9998/ZsyYkScbS1W1zZr9X/67dOnSKCkpia9+9avRr1+/+p4eAAAAAGC9VFKZehmshvfffz+3SZg5c2ZebteuXey5557Rvn37aEzKy8ujoqKioYcBAAAAADRRpaWlUVZWtvZD26ZCaAsAAAAAFCG0rXdPWwAAAAAACtTTNnnhhRdi7Nix8c9//jPmzZsXtRXtjhw5cnUuAQAAAACwXql3pe3EiRPjsssuizlz5kSfPn1yYNu3b9/8atGiRXTq1CkGDhy4ZkcLAAAAANDE1bvS9u67745u3brFxRdfHJ988kk8/PDDcdBBB8VOO+2UJyW74IILom3btmt2tAAAAAAATVy9K22nTZuWq2qbNWsWG2ywQV63ePHi/DOFtYceemjcc889a26kAAAAAADrgXqHthtuuGE0b/5/hbqbbLJJ/n327NnV2zfffPNccQsAAAAAwDoIbbfZZptcbVulc+fO8de//jWWLFkSixYtivHjx8dWW21V39MDAAAAAKyX6h3a7rnnnvHMM89ERUVFXj7mmGNi8uTJceqpp8a3vvWtePXVV+Ooo45ak2MFAAAAAGjySiorKyvX1MleeeWVePrpp3Of29122y1PStZYlJeXVwfQAAAAAABrWmlpaZSVla3b0PY/WbBgQYwdOzb233//PFFZ0QhtAQAAAIAihLb1bo9Qn9D2D3/4g8nJAAAAAACKENoCAAAAAPDZhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgTSPAnrggQdizJgxMXv27OjUqVMMGjQounXr9pnHPfnkk3HNNdfEHnvsEeeee+46GSsAAAAAQJOutJ0wYUKMGDEiBg4cGJdffnkObYcNGxZz5sz5j8fNnDkzbrnllthhhx3W2VgBAAAAAJp8aDt27Njo379/HHjggdGhQ4cYPHhwtGjRIh577LE6j1m6dGlce+21cdxxx0Xbtm3X6XgBAAAAAAoR2l5//fXx2muv1bn99ddfz/tUadWqVQwfPjx69uxZ5zGLFy+ON998M3r16vXvATZrlpenTp1a53GjRo3K5z/ooIPq9V4AAAAAABp9aPv444/HjBkz/mO7grRP9YWaNYuysrIoLS2t85i5c+fmqtnWrVvXWJ+WU3/b2rz66qvxl7/8JU477bSVGndFRUXMmzev+jV//vyVOg4AAAAAoFFPRPbhhx/mtgZrUwpcU1uEFNimStuVMXr06FyZW6VLly65dy4AAAAAQKMLbZ955pn8qvLII4/ESy+9tMJ+qYL15Zdfjm7duq3SYFLwmipyl6+qTcvLV98mqdK3vLy8RuhaWVmZfx5//PHxi1/8Itq3b1/jmKOPPjoGDBhQvVxSUrJKYwQAAAAAKExoO23atJg4cWL1cuppm3rQLiuFoBtuuGHssMMOcfLJJ6/aYJo3j65du8akSZNir732yutSu4S0fNhhh62w/zbbbBNXXXVVjXV33nlnLFiwIE499dTYaqutVjgmtWf4Ty0aAAAAAAAaTWibqlTTK/na174WZ5xxRuy7775rdECpCva6667L4W2q1L3//vtj4cKF0a9fv7w9TWbWpk2bOPHEE3P7hY4dO9Y4fpNNNsk/l18PAAAAANCke9qOHDky1oY+ffrkCcnuuuuu3Bahc+fOcf7551e3R5g1a5aWBgAAAABAk1VSWdUEth6TgH366ac1WhCkyccefvjhqKioiH322WeVe9o2pNQbN40bAAAAAGBtSG1by8rK1l5omyb5SkHnsGHDqicf++EPf5iD21QJu8EGG+QK2c9//vPRGAhtAQAAAIAihLbN6nuBKVOmxG677Va9/MQTT8RHH30UF198cdx00025p+yf/vSn+p4eAAAAAGC9VO/QNvWdTROCVXn22Wdj++23jx49ekTLli3jgAMOiLfeemtNjRMAAAAAYL1Q79B2k002yROFJYsWLYpXX301dt5553+fuFmzvB4AAAAAgJXXPOopVdQ+9NBDse2228aLL76YA9o999yzevt7771XoxIXAAAAAIC1WGn79a9/PU829j//8z/x6KOPxoABA+Jzn/tc3rZ06dKYOHFi7LDDDvU9PQAAAADAeqmksrKysr4HL168OKZNmxYbb7xxtG3btnr9/PnzY9KkSdGpU6ca64usvLw8KioqGnoYAAAAAEATVVpaGmVlZWs3tG1KhLYAAAAAQBFC23r3tE3mzZuX+9pOnjw55syZE9/+9rejW7du8cknn8S4ceNijz32iPbt26/OJQAAAAAA1iv1Dm0/+OCDGDJkSMyaNSu23nrrePfdd2PBggV526abbhoPP/xwrl795je/uSbHCwAAAADQpNU7tL3lllty79orr7wyWrVqFYMHD66xfc8994znn39+TYwRAAAAAGC90ay+B7700ktx+OGHR4cOHaKkpGSF7e3atcvVuAAAAAAArIPQdtGiRbnCti6pChcAAAAAgHUU2qYK21deeaXO7c8880x07ty5vqcHAAAAAFgv1Tu0PeKII+LJJ5+Mu+++O+bNm5fXLV26NN5///249tprY+rUqXHkkUeuybECAAAAADR5JZWVlZX1PfhPf/pT/OEPf4h0ivRKvW3Tz2bNmsXXvva1OOqoo6KxKC8vj4qKioYeBgAAAADQRJWWlkZZWdnaC21nzZqVe9rOnTs3Jk6cmCts06nSBGR77713tG7dOj7++OPYaqutojEQ2gIAAAAAjTq0TZW03//+92PfffetdfuECRPimmuuiZEjR0ZjILQFAAAAAIoQ2ta7p+1nWbx4cW6TAAAAAADAymu+CvvmCceqJh1LUvuD1CZheZ9++mmutE0tEgAAAAAAWHmr1B4hTTo2atSoVWqhcMwxx0RjoD0CAAAAAFCE9girVGnbu3fv2GijjfKEY7fddlv07ds3unTpUmOfkpKS2HDDDaNr166x3XbbrfrIAQAAAADWY6sU2vbo0SO/koULF8bee+8dHTt2XFtjAwAAAABY76xSe4SmTHsEAAAAAKAI7RGardVRAAAAAACwSoS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCAAAAABSI0BYAAAAAoECEtgAAAAAABSK0BQAAAAAoEKEtAAAAAECBCG0BAAAAAApEaAsAAAAAUCBCWwAAAACAAhHaAgAAAAAUiNAWAAAAAKBAhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgQhtAQAAAAAKRGgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQJpHAT3wwAMxZsyYmD17dnTq1CkGDRoU3bp1q3XfRx55JP7617/GO++8k5e7du0aJ5xwQp37AwAAAAAUWeEqbSdMmBAjRoyIgQMHxuWXX55D22HDhsWcOXNq3f8f//hH9O3bNy688MK45JJLYsstt8w/P/zww3U+dgAAAACAJhfajh07Nvr37x8HHnhgdOjQIQYPHhwtWrSIxx57rNb9zzzzzDj00EOjc+fOse2228bpp58elZWV8fLLL6/zsQMAAAAANKnQdvHixfHmm29Gr169qtc1a9YsL0+dOnWlzrFw4cJ8nk033XQtjhQAAAAAYD3oaTt37txYunRptG7dusb6tDx9+vSVOsdtt90Wbdq0qRH8LquioiK/qpSUlETLli1Xc+QAAAAAAE0wtF1dd999dzz55JMxZMiQ3FKhNqNHj45Ro0ZVL3fp0iX3zgUAAAAAKIJChbatWrXK7RBmz55dY31aXr76dnn33ntvDm1/+tOf5snL6nL00UfHgAEDalTaAgAAAAAURaF62jZv3jy6du0akyZNql6X2iWk5R49etR53D333BN//OMf4/zzz4/tttvuP16jtLQ0Nt544+qX1ggAAAAAQJEUKrRNUhXso48+GuPGjYtp06bFjTfemCcX69evX94+fPjwuP3226v3T9W1I0eOjDPOOCPatm2bq3LTa8GCBQ34LgAAAAAAmkB7hKRPnz55QrK77rorh6+dO3fOFbRV7RFmzZpVo6XBww8/HIsXL46rr766xnkGDhwYxx133DofPwAAAADA6iiprKysXK0zNBHl5eVRUVHR0MMAAAAAAJqo1Lq1rKys8bVHAAAAAABYnwltAQAAAAAKRGgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCAAAAABSI0BYAAAAAoECEtgAAAAAABSK0BQAAAAAoEKEtAAAAAECBCG0BAAAAAApEaAsAAAAAUCBCWwAAAACAAhHaAgAAAAAUiNAWAAAAAKBAhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgQhtAQAAAAAKRGgLAAAAAFAgQlsAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCAAAAABSI0BYAAAAAoECEtgAAAAAABSK0BQAAAAAoEKEtAAAAAECBCG0BAAAAAApEaAsAAAAAUCBCWwAAAACAAhHaAgAAAAAUiNAWAAAAAKBAhLYAAAAAAAUitAUAAAAAKBChLQAAAABAgTSPAnrggQdizJgxMXv27OjUqVMMGjQounXrVuf+Tz31VIwcOTLKy8ujffv2cdJJJ8Vuu+22TscMAAAAANAkK20nTJgQI0aMiIEDB8bll1+eQ9thw4bFnDlzat1/ypQpcc0118RBBx2U999zzz3jyiuvjLfffnudjx0AAAAAoMmFtmPHjo3+/fvHgQceGB06dIjBgwdHixYt4rHHHqt1//vvvz922WWX+PKXv5z3P/7446Nr1665WhcAAAAAoLEpVGi7ePHiePPNN6NXr17V65o1a5aXp06dWusxaf2y+ye9e/eO1157ba2PFwAAAACgSfe0nTt3bixdujRat25dY31anj59eq3HpL63m2++eY11aTmtr01FRUV+VSkpKYmWLVtG8+aF+qcAAAAAAJqYlc0g17ukcvTo0TFq1Kjq5b59+8ZZZ50VW2yxRYOOCwAAAACgcO0RWrVqldshLF8lm5aXr76tktYvP0lZWq5r/6OPPjpuvvnm6lfqmbts5S2wdsyfPz9+/OMf558A0BS4twHQlLivQbE0K1p5cJpEbNKkSdXrUruEtNyjR49aj0nrX3755RrrXnrppejevXut+5eWlsbGG29c45XWAWtXZWVl/POf/8w/AaApcG8DoClxX4NiKVRomwwYMCAeffTRGDduXEybNi1uvPHGWLhwYfTr1y9vHz58eNx+++3V+x9xxBHx97//PcaMGRPvvvtu3HXXXfHGG2/EYYcd1oDvAgAAAACgfgrX07ZPnz55QrIUvqa2CJ07d47zzz+/ut3BrFmz8uRhVXr27Blnnnlm3HnnnXHHHXfE1ltvHeecc0507NixAd8FAAAAAED9lFSqewfWgdQ7Ok0EmPpKa0kCQFPg3gZAU+K+BsUitAUAAAAAKJDC9bQFAAAAAFifCW0BAAAAAApEaAusEd/97nfjvvvua+hhAECWOoD9+te/jm9+85tx3HHHxVtvvdXQQwIAgJXWfOV3BQCAxuHFF1+McePGxZAhQ6Jdu3ax2Wabrdb5UvD7ox/9KPbaa6/qdXfddVc888wzceWVV8aatLbOCwC1mTx5ci7Aef3112P+/PnRvn37+PKXvxz77bdfQw8N1mtCWwAAmpwZM2bEFltsET179mzooQBAoU2ZMiU6duwYX/nKV2LzzTeP559/PoYPHx4bb7xx7L777g09PFhvlVSm744BfIb0ietvfvObXPnTsmXL/Mnrs88+G507d45TTz01t0c44ogj4sgjj8z7z5o1K373u9/Fyy+/HM2aNYvevXvHoEGDonXr1jF9+vT4r//6r/j5z38e2267bfU1xo4dGw8++GBce+21efntt9+OW2+9NV555ZXYaKONYuedd45TTjklWrVq1WD/DgAU33XXXRePP/549XJZWVkMHjw4/vjHP8Y777yT70s9evTI969UTZQsXrw4fv/738fTTz8dn376aX5oPfjgg+Poo4/O97jy8vIa5zv22GPj+uuvr3Hd73znO9GvX798/C233JLvmem8Xbt2zfevdM+cO3du/PCHP4zDDz88jjnmmOqH5VQRfP7558cHH3xQ53kBYGU999xz+bkqPZOl+15qE3TuuefmYPakk07K+/zqV7+KRYsWxZlnnrnC8f/93/+d74XpHvT3v/89rrjiirjhhhtik002qd7npptuys9sF1544Tp9b7C+UGkLrJT0IJseKtONPt2801c3//nPf+YH0OUtXbo039RT0Dp06NBYsmRJ/Pa3v41f/OIX+aF0m222ie222y6eeOKJOP7446uPGz9+fPTt2zf/nh54L7roojjooIPyg276Y+K2227LQa8/CgD4T1If29QS4dFHH80Pnelh9R//+EcMGDAgOnXqFAsWLIiRI0fGVVddle9Xafv999+fP4w8++yzY6uttsrhafoAMknn+Na3vpUfXHfZZZe8f7rHpQfV9CD705/+NO+XKpKSq6++Olq0aJFD2LTu4Ycfjosvvjiuueaa/MHjGWeckVsfpA800z0xVTMddthh0atXr3y/q+u8ALCydthhh1x4k57Z0rNXug+mVkHpZ5X0ewpxazNv3rzqApt0f0r3ovTBZno+q3rmmzBhQpxwwgnr6B3B+sdEZMBnSjf7VLH0jW98I9+w01dn0oNrulHXZtKkSfmBM31im6qLunfvHt/73vfyHwWpT1Ky7777xpNPPll9TKq+ffPNN6v7Jj3wwAPRpUuXOPHEE/MfC+n39JCb+i2lfQGgLunBMn0rJIWr6RseKSjdZ599Yu+9986VtekDx3RPSfeqadOm5WNSQLv11lvH9ttvnytp0890r0qqvuGRzlt1vhTKpuC26hrplda9+uqr+V73gx/8ID8kp3OefPLJ+diJEyfm8+y2227Rv3//+OUvf5m/xbLhhhvm+11S13kBYFWk+06636XnpyT9TN+KTCFu+vDyww8/jPfffz923HHHFY5NYewbb7wRBx54YF5O96RUXJOKbKqkb1SmYDfdW4G1Q6UtsFJ9AVO1bLdu3Wr8EZCqg2qTHoC33HLLXKlUpUOHDvmrNO+++24+T7rpp6+OTp06NX9FNf0BkILZqk9z//Wvf+XwNwXFtY2nrmsDQG3ee++9XF2bAtWPP/64+oPHFNamDyNT+4FLLrkkt+9JFbCph1/6uarS10/Tw3BqCbSsVEGbHo6rpCA3tUl46qmn4vLLL4/S0tI18C4B4N9SIJsKZ770pS/lDxXTB4TpvpN+/+STT3Lv9/Th4rLSM9j//u//xmmnnRaf+9znqtenDzIvuOCCHPa2adMmf2ty1113rdEuAVizhLZAg0iVQzvttFMOa6tC20MOOaR6e3rgTQ/MX//612s9FgBWRQpGUwVteghND6lpWocUmqaes0n6ZkhqU/Diiy/GSy+9lNvxpG+XpH1WRbp/pfOndkDLW7bNQQpw04NvGsfMmTNzcAwAa9LnP//5eOyxx3JBzAYbbJALZNK6VHWb2tEtX2WbAt50v0zt6Q444IAa21LhTfq2SqrCTc9tqW97+vYlsPYIbYHPlPoCppt8qk6qqp5NX4VJbQpSr6Tlparaql6AVfun6tv0h0HatuyntalPbfqZqmf79OlTvS1V3aaeSekBO10bAOorVdame1YKbKvuW6nKqLZQNd2L0iu1U7j00ktzJdKmm26a70XLtwVq3rz5CutS+Dt79uz8VdK2bdvWOp4UFKfJYdJ10jdHfv3rX+dWQqlnfF3nBYBVlVr9pFZ3acLnqoA2/bznnnvy/S1V4FZJQe5ll12WJyn74he/WOv50nNbqrBNlbYlJSW53Q+w9uhpC3ym1BcwfdJ666235q/LpJm301dm0gNpbar63qYH0tSnNoW9qXop/YGQ+vtVSf2P0h8RqZ9fqrpNN/8qhx56aP5DIk3ako5PFUmp+inNqO1BFoBVkb66mSZfeeSRR/L9JN3L0gSby0oPtOlbH6mNTwp4U//Z9M2OqurYFMCm41Igm+5PVetSlWxqiTB37tyoqKjI98D0DZI00ViaTCxtTxN53nHHHbk/YJJ+Tx9+pgnT0gQw6aup6b5apbbzAsCqSh86pgk40/1t2dA2PaOltkFV69L9LQW2hx9+eP7QMt3rlr3fVUnzj6SeuKNHj877ae0Da5dKW2ClpK/IpHA1fV0mhbhf/vKXczVtbZOjpE9dzz333Pjd734XF154YQ53U1/A5fv7pfOkFgipr1KaEGZZKcBNM22nStxhw4blB9ZUdZvOk84PACsr3YfOOuusuOmmm3K7g1TdmgLTZVsYpMm/7r333vwQm/ZPXwM977zzqj+gTD3WR4wYEY8++mi+R1133XX5w8f0rZChQ4fmb5Okr4mm3rjpuBTMpg8aU+iawt9U4ZsqaVMl0/3335/vj1WBcJqs85xzzomHHnoof+W0rvMCwKpKwWz6EDC1RagKctO3H+fMmVM9T0iadHrhwoVx991359eyxy57r0ztEdL9MRXVpOdDYO0qqUyNtABWUerZd/rpp+eJVA466KCGHg4AAABAk6HSFlgp6Wsw6Suj6ZPV9JXOUaNG5fV77LFHQw8NAAAAoEkR2gIrbcyYMbnPX5ogJU20ctFFF0WrVq0aelgAAAAATYr2CAAAAAAABVL71O8AAAAAADQIoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIACEdoCALBeOe644+K3v/3tWr/O5MmT87XSz88yZMiQ/Koyc+bMfOy4cePW8igBACgioS0AAAAAQIE0b+gBAAAANZWVlcWtt94azZv7cx0AYH3kr0AAACiYkpKSaNGiRUMPAwCABiK0BQCgMD788MO4884744UXXohPP/002rdvHwMGDIiDDjoob0/9YYcOHRr/9V//Fe+++2488sgjMX/+/Ojdu3ecccYZUVpaGrfddluMHz8+Fi5cGF/4whdi8ODBef3ynnjiiRg1alTMmjUrOnToEKecckrsuOOOqzSeKh988EHuk/vyyy/HhhtuGPvuu2/ssssutb7HNOZ77rknn7tjx45x8sknr7BP6mn7ve99L77zne9Ev3798rrrrrsuJk6cGNdcc03ceOON+Vop2D3ggAPi61//ejRr9u/OZx9//HHcfPPN8eyzz+YAeI899sjjPvfcc2ucEwCAYhLaAgBQCLNnz44LLrgg/37ooYdGq1at4sUXX4xf/epXOZg98sgjq/e9++67c2B51FFHxfvvvx8PPPBAbLDBBjm4TOHqscceG6+99lqeyKtt27YxcODAGtf6xz/+ERMmTIjDDz88B7oPPfRQXHrppfmVgtRVGc+iRYvioosuyuFvOl+bNm3ir3/9a60TkP3lL3+JG264IXr27BlHHHFEzJgxI6644orYdNNNY8stt/zMf6OlS5fGsGHDolu3bvGNb3wjB7djx47NYfIhhxxSvc/ll18er7/+el63zTbb5PA2hb4AADQOQlsAAAohVbSmwPGqq66KzTbbLK9LoeMvfvGL+MMf/hAHH3xw9b5LliyJIUOGVPd8nTt3bg5hU3XreeedVx20pkD3scceWyG0feedd+Kyyy6Lrl275uW+ffvGWWedFXfddVf86Ec/WunxpOA4Vc6+9957cfbZZ+fK3qR///5xzjnn1Ljm4sWL44477ojOnTvHhRdeWD32VOWbgtyVCW0rKiryNareTxrPj3/84xwGV4W2zzzzTEydOjVOPfXUHAxX7XfJJZfU6/8FAIB179/foQIAgAZSWVkZTz/9dOy+++759xTCVr1SEDtv3rx48803q/dPLQGWnaSre/fu+bgDDzywxnlTRWqqgE0h77J69OhRHdgmW221Vey5557x97//PQe1qzKe1Dphiy22iH322af6fKlFwhe/+MUa10z7z5kzJ4e9y449tSrYeOONV/rfqiqcrbL99tvnit0qqRo4VR2n4LhKqkBOITYAAI2DSlsAABpcCkNTW4NUtZpede2zySabVIesy6oKPZevVk3rU+iaQtaqatkktRNY3tZbb5374KbrpD6wKzOepLy8PJ8vHbOs1JZgWWm/qussKwW47dq1i5WRWjmkNg3LSv8maaxVUkidQuQUHC+rtvcMAEAxCW0BAGhwKVhN9ttvv1xFW5tOnTrFtGnT8u/LTrq1rLrWV51/TY9nXavr/QEA0LQIbQEAaHCperRly5a5NcHOO+9c535Voe3qSr1ul5f60qbq1KpK1pUZT1JWVhZvv/12DnqXrbadPn36CvtVXWennXaq0et25syZaywETlXIkyZNylXDy1bb1vaeAQAoJh/VAwDQ4FIF6d577537yKYAtK5WBGtKmqhr2R65qaVAmsArBbRpLKsynl133TU++uijmDhxYvW6FJgu31Yh9dBNgfDDDz+cg9oq48aNq9HeYHX17t079/B99NFHq9el8PnBBx9cY9cAAGDtUmkLAEAhnHjiiTF58uS44IIL8iRaHTp0iE8++SSHqy+//HLcdNNNa+xan/vc52LYsGFx+OGH5z6xDz30UF5/3HHHrfJ40rYHHngghg8fnrelfrJ//etfV+gpm3rXHn/88XHDDTfE0KFDo0+fPrnCNoW2K9vTdmXstddeeQK2ESNG5Ora1Fv3ueeey2MHAKBxENoCAFAIrVu3jksvvTRGjRqVK1xTZWiaPCwFrCeddNIavdaOO+4YPXr0yNdKVbYpkP3Od75To0XByo4nhbM/+9nP4ne/+10Ob1u0aJF74e6yyy75+GV98YtfzFWv9957b9x6663RsWPHOPfcc2PkyJFr7L2lKuGf/OQncfPNN8fjjz+eWzakIHfgwIHx05/+NI8PAIBiK6lc1VkZAACARudvf/tbXHXVVXHRRRfF9ttv39DDAQDgP9DTFgAAmphFixbVWE7VvakKOE2ulnrrAgBQbNojAABAE5NaNaTgNrWAqKioyFW2U6ZMiRNOOEF7BACARkB7BAAAaGLGjx8fY8aMyRORpdC2ffv2ccghh8Rhhx3W0EMDAGAlCG0BAAAAAApET1sAAAAAgAIR2gIAAAAAFIjQFgAAAACgQIS2AAAAAAAFIrQFAAAAACgQoS0AAAAAQIEIbQEAAAAACkRoCwAAAABQIEJbAAAAAIAojv8PwrR99eHzpMwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 130\u001b[39m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics_df\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m metrics_comparison = \u001b[43mvisualize_model_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mvisualize_model_comparison\u001b[39m\u001b[34m(metric_names, run_filter)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pivot_data:\n\u001b[32m    114\u001b[39m     pivot_df = pd.DataFrame(pivot_data)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     heatmap_df = \u001b[43mpivot_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmetric\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# Plot heatmap\u001b[39;00m\n\u001b[32m    118\u001b[39m     sns.heatmap(heatmap_df, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m'\u001b[39m\u001b[33mYlGnBu\u001b[39m\u001b[33m'\u001b[39m, fmt=\u001b[33m'\u001b[39m\u001b[33m.3f\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/oc-projects/python/aiengineer/P7-Sentiments_analysis/.venv/lib/python3.12/site-packages/pandas/core/frame.py:9346\u001b[39m, in \u001b[36mDataFrame.pivot\u001b[39m\u001b[34m(self, columns, index, values)\u001b[39m\n\u001b[32m   9339\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   9340\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mpivot\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   9341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpivot\u001b[39m(\n\u001b[32m   9342\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, columns, index=lib.no_default, values=lib.no_default\n\u001b[32m   9343\u001b[39m ) -> DataFrame:\n\u001b[32m   9344\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpivot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[32m-> \u001b[39m\u001b[32m9346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/oc-projects/python/aiengineer/P7-Sentiments_analysis/.venv/lib/python3.12/site-packages/pandas/core/reshape/pivot.py:570\u001b[39m, in \u001b[36mpivot\u001b[39m\u001b[34m(data, columns, index, values)\u001b[39m\n\u001b[32m    566\u001b[39m         indexed = data._constructor_sliced(data[values]._values, index=multiindex)\n\u001b[32m    567\u001b[39m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m result = \u001b[43mindexed\u001b[49m\u001b[43m.\u001b[49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_listlike\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    571\u001b[39m result.index.names = [\n\u001b[32m    572\u001b[39m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result.index.names\n\u001b[32m    573\u001b[39m ]\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/oc-projects/python/aiengineer/P7-Sentiments_analysis/.venv/lib/python3.12/site-packages/pandas/core/series.py:4626\u001b[39m, in \u001b[36mSeries.unstack\u001b[39m\u001b[34m(self, level, fill_value, sort)\u001b[39m\n\u001b[32m   4581\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4582\u001b[39m \u001b[33;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[32m   4583\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4622\u001b[39m \u001b[33;03mb    2    4\u001b[39;00m\n\u001b[32m   4623\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4624\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[32m-> \u001b[39m\u001b[32m4626\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/oc-projects/python/aiengineer/P7-Sentiments_analysis/.venv/lib/python3.12/site-packages/pandas/core/reshape/reshape.py:517\u001b[39m, in \u001b[36munstack\u001b[39m\u001b[34m(obj, level, fill_value, sort)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj.dtype):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value, sort=sort)\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m unstacker = \u001b[43m_Unstacker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_constructor_expanddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker.get_result(\n\u001b[32m    521\u001b[39m     obj._values, value_columns=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=fill_value\n\u001b[32m    522\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/oc-projects/python/aiengineer/P7-Sentiments_analysis/.venv/lib/python3.12/site-packages/pandas/core/reshape/reshape.py:154\u001b[39m, in \u001b[36m_Unstacker.__init__\u001b[39m\u001b[34m(self, index, level, constructor, sort)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_cells > np.iinfo(np.int32).max:\n\u001b[32m    147\u001b[39m     warnings.warn(\n\u001b[32m    148\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cells \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    149\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min the resulting pandas object.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    150\u001b[39m         PerformanceWarning,\n\u001b[32m    151\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    152\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/oc-projects/python/aiengineer/P7-Sentiments_analysis/.venv/lib/python3.12/site-packages/pandas/core/reshape/reshape.py:210\u001b[39m, in \u001b[36m_Unstacker._make_selectors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m mask.put(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.sum() < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.index):\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m.group_index = comp_index\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m.mask = mask\n",
      "\u001b[31mValueError\u001b[39m: Index contains duplicate entries, cannot reshape"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_model_comparison(metric_names=None, run_filter=None):\n",
    "    \"\"\"\n",
    "    Create advanced visualizations to compare models based on selected metrics.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric_names : list or None\n",
    "        List of specific metric names to compare (e.g., ['test_accuracy', 'test_f1_score']).\n",
    "        If None, uses default metrics: accuracy, precision, recall, f1_score, and roc_auc.\n",
    "    run_filter : dict or None\n",
    "        Dictionary of parameter name and values to filter runs (e.g., {'embedding': 'w2v'})\n",
    "    \"\"\"\n",
    "    # Default metrics to visualize if none provided\n",
    "    if not metric_names:\n",
    "        metric_names = ['test_accuracy', 'test_precision', 'test_recall',\n",
    "                        'test_f1_score', 'test_roc_auc']\n",
    "\n",
    "    # Get metrics dataframe\n",
    "    metrics_df = compare_run_metrics(run_filter=run_filter)\n",
    "\n",
    "    # Filter for metrics we want to visualize\n",
    "    available_metrics = [m for m in metric_names if m in metrics_df.columns]\n",
    "    if not available_metrics:\n",
    "        print(\"None of the requested metrics are available in the runs.\")\n",
    "        return\n",
    "\n",
    "    # 1. Radar Chart / Spider Plot\n",
    "    if len(available_metrics) >= 3 and len(metrics_df) >= 2:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "\n",
    "        # Set up the radar chart\n",
    "        categories = [m.replace('test_', '').replace('_', ' ').title() for m in available_metrics]\n",
    "        N = len(categories)\n",
    "\n",
    "        # Create angles for each metric\n",
    "        angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "        angles += angles[:1]  # Close the loop\n",
    "\n",
    "        # Set up subplot in polar projection\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "\n",
    "        # Add lines for each embedding type\n",
    "        embedding_types = metrics_df['embedding'].unique()\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(embedding_types)))\n",
    "\n",
    "        for i, embedding in enumerate(embedding_types):\n",
    "            model_data = metrics_df[metrics_df['embedding'] == embedding]\n",
    "\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "\n",
    "            # Get values for this model\n",
    "            values = [model_data[metric].values[0] for metric in available_metrics]\n",
    "            values += values[:1]  # Close the loop\n",
    "\n",
    "            # Plot values\n",
    "            ax.plot(angles, values, 'o-', linewidth=2, color=colors[i], label=embedding)\n",
    "            ax.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "\n",
    "        # Set chart properties\n",
    "        plt.xticks(angles[:-1], categories)\n",
    "        ax.set_rlabel_position(0)\n",
    "        plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], ['0.2', '0.4', '0.6', '0.8', '1.0'],\n",
    "                   color=\"grey\", size=8)\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.title('Model Comparison Across Metrics', size=15)\n",
    "\n",
    "        # Save the radar chart\n",
    "        radar_chart_path = \"radar_chart_model_comparison.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(radar_chart_path)\n",
    "        mlflow.log_artifact(radar_chart_path)\n",
    "        plt.show()\n",
    "\n",
    "    # 2. Bar chart comparison for each metric\n",
    "    plt.figure(figsize=(14, 4 * len(available_metrics)))\n",
    "\n",
    "    for i, metric in enumerate(available_metrics):\n",
    "        plt.subplot(len(available_metrics), 1, i+1)\n",
    "\n",
    "        # Sort for this specific metric\n",
    "        sorted_df = metrics_df.sort_values(by=metric, ascending=False)\n",
    "\n",
    "        # Create bar chart\n",
    "        sns.barplot(x='embedding', y=metric, data=sorted_df)\n",
    "        plt.title(f\"{metric.replace('test_', '').replace('_', ' ').title()}\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    bar_chart_path = \"bar_chart_model_comparison.png\"\n",
    "    plt.savefig(bar_chart_path)\n",
    "    mlflow.log_artifact(bar_chart_path)\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Heatmap for all metrics\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Prepare data for heatmap - pivot table with embeddings as rows and metrics as columns\n",
    "    pivot_data = []\n",
    "    for _, row in metrics_df.iterrows():\n",
    "        embedding = row['embedding']\n",
    "        for metric in available_metrics:\n",
    "            if metric in row:\n",
    "                pivot_data.append({\n",
    "                    'embedding': embedding,\n",
    "                    'metric': metric.replace('test_', '').replace('_', ' ').title(),\n",
    "                    'value': row[metric]\n",
    "                })\n",
    "\n",
    "    if pivot_data:\n",
    "        pivot_df = pd.DataFrame(pivot_data)\n",
    "        heatmap_df = pivot_df.pivot(index='embedding', columns='metric', values='value')\n",
    "\n",
    "        # Plot heatmap\n",
    "        sns.heatmap(heatmap_df, annot=True, cmap='YlGnBu', fmt='.3f')\n",
    "        plt.title('Performance Metrics by Embedding Type')\n",
    "\n",
    "        heatmap_path = \"heatmap_model_comparison.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(heatmap_path)\n",
    "        mlflow.log_artifact(heatmap_path)\n",
    "        plt.show()\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Example usage\n",
    "metrics_comparison = visualize_model_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb6f67",
   "metadata": {},
   "source": [
    "# Example Usage for Model Comparison\n",
    "\n",
    "Below are some examples of how to use the functions we've created to compare model performance across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1da6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Get a basic comparison of all models\n",
    "all_models_df = compare_run_metrics(\n",
    "    metric_prefixes=['test_'],\n",
    "    sort_by='test_accuracy',\n",
    "    ascending=False\n",
    ")\n",
    "display(all_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f95780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Create visualizations comparing different embedding types\n",
    "visualize_model_comparison(['test_accuracy', 'test_precision', 'test_recall', 'test_f1_score', 'test_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8344907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ba5ab_row2_col7, #T_ba5ab_row2_col8, #T_ba5ab_row2_col9, #T_ba5ab_row7_col7, #T_ba5ab_row7_col8, #T_ba5ab_row7_col9, #T_ba5ab_row9_col7, #T_ba5ab_row9_col8, #T_ba5ab_row9_col9 {\n",
       "  background-color: rgb(0,255,0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ba5ab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ba5ab_level0_col0\" class=\"col_heading level0 col0\" >run_id</th>\n",
       "      <th id=\"T_ba5ab_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_ba5ab_level0_col2\" class=\"col_heading level0 col2\" >embedding</th>\n",
       "      <th id=\"T_ba5ab_level0_col3\" class=\"col_heading level0 col3\" >lstm_units</th>\n",
       "      <th id=\"T_ba5ab_level0_col4\" class=\"col_heading level0 col4\" >embedding_dim</th>\n",
       "      <th id=\"T_ba5ab_level0_col5\" class=\"col_heading level0 col5\" >epochs</th>\n",
       "      <th id=\"T_ba5ab_level0_col6\" class=\"col_heading level0 col6\" >max_length</th>\n",
       "      <th id=\"T_ba5ab_level0_col7\" class=\"col_heading level0 col7\" >test_accuracy</th>\n",
       "      <th id=\"T_ba5ab_level0_col8\" class=\"col_heading level0 col8\" >test_auc</th>\n",
       "      <th id=\"T_ba5ab_level0_col9\" class=\"col_heading level0 col9\" >test_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ba5ab_row0_col0\" class=\"data row0 col0\" >2bc9842159d2492eaf5f8673a07beecc</td>\n",
       "      <td id=\"T_ba5ab_row0_col1\" class=\"data row0 col1\" >bemused-moose-553</td>\n",
       "      <td id=\"T_ba5ab_row0_col2\" class=\"data row0 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row0_col4\" class=\"data row0 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row0_col5\" class=\"data row0 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row0_col6\" class=\"data row0 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ba5ab_row1_col0\" class=\"data row1 col0\" >29f1463d30e34065a4b6064fb5fc59e9</td>\n",
       "      <td id=\"T_ba5ab_row1_col1\" class=\"data row1 col1\" >LSTM_glove_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row1_col2\" class=\"data row1 col2\" >glove</td>\n",
       "      <td id=\"T_ba5ab_row1_col3\" class=\"data row1 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row1_col4\" class=\"data row1 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row1_col5\" class=\"data row1 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row1_col6\" class=\"data row1 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ba5ab_row2_col0\" class=\"data row2 col0\" >d876ae30831a417abeb61a77e6d4f695</td>\n",
       "      <td id=\"T_ba5ab_row2_col1\" class=\"data row2 col1\" >LSTM_glove_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row2_col2\" class=\"data row2 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row2_col4\" class=\"data row2 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row2_col5\" class=\"data row2 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row2_col6\" class=\"data row2 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row2_col7\" class=\"data row2 col7\" >0.7568</td>\n",
       "      <td id=\"T_ba5ab_row2_col8\" class=\"data row2 col8\" >0.8414</td>\n",
       "      <td id=\"T_ba5ab_row2_col9\" class=\"data row2 col9\" >0.7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ba5ab_row3_col0\" class=\"data row3 col0\" >52e306e2772448c1849c419c74b25c16</td>\n",
       "      <td id=\"T_ba5ab_row3_col1\" class=\"data row3 col1\" >LSTM_glove_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row3_col2\" class=\"data row3 col2\" >glove</td>\n",
       "      <td id=\"T_ba5ab_row3_col3\" class=\"data row3 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row3_col4\" class=\"data row3 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row3_col5\" class=\"data row3 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row3_col6\" class=\"data row3 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ba5ab_row4_col0\" class=\"data row4 col0\" >d693a63906af4a5f978ff76b5ff7c195</td>\n",
       "      <td id=\"T_ba5ab_row4_col1\" class=\"data row4 col1\" >LSTM_glove_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row4_col2\" class=\"data row4 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row4_col3\" class=\"data row4 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row4_col4\" class=\"data row4 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row4_col5\" class=\"data row4 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row4_col6\" class=\"data row4 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ba5ab_row5_col0\" class=\"data row5 col0\" >aa4696301cc74bd59a0316eac345e667</td>\n",
       "      <td id=\"T_ba5ab_row5_col1\" class=\"data row5 col1\" >LSTM_glove_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row5_col2\" class=\"data row5 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row5_col3\" class=\"data row5 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row5_col4\" class=\"data row5 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row5_col5\" class=\"data row5 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row5_col6\" class=\"data row5 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row5_col7\" class=\"data row5 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row5_col8\" class=\"data row5 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row5_col9\" class=\"data row5 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ba5ab_row6_col0\" class=\"data row6 col0\" >74a884d7c23243688652947286030c54</td>\n",
       "      <td id=\"T_ba5ab_row6_col1\" class=\"data row6 col1\" >LSTM_fasttext_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row6_col2\" class=\"data row6 col2\" >fasttext</td>\n",
       "      <td id=\"T_ba5ab_row6_col3\" class=\"data row6 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row6_col4\" class=\"data row6 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row6_col5\" class=\"data row6 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row6_col6\" class=\"data row6 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row6_col7\" class=\"data row6 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row6_col8\" class=\"data row6 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row6_col9\" class=\"data row6 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ba5ab_row7_col0\" class=\"data row7 col0\" >3205b86fe0a946399d577bd4cb0c89ce</td>\n",
       "      <td id=\"T_ba5ab_row7_col1\" class=\"data row7 col1\" >LSTM_fasttext_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row7_col2\" class=\"data row7 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row7_col3\" class=\"data row7 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row7_col4\" class=\"data row7 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row7_col5\" class=\"data row7 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row7_col6\" class=\"data row7 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row7_col7\" class=\"data row7 col7\" >0.7181</td>\n",
       "      <td id=\"T_ba5ab_row7_col8\" class=\"data row7 col8\" >0.7880</td>\n",
       "      <td id=\"T_ba5ab_row7_col9\" class=\"data row7 col9\" >0.7228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ba5ab_row8_col0\" class=\"data row8 col0\" >2010b366dbbd4bbba3edf2c1d55d0342</td>\n",
       "      <td id=\"T_ba5ab_row8_col1\" class=\"data row8 col1\" >LSTM_w2v_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row8_col2\" class=\"data row8 col2\" >w2v</td>\n",
       "      <td id=\"T_ba5ab_row8_col3\" class=\"data row8 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row8_col4\" class=\"data row8 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row8_col5\" class=\"data row8 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row8_col6\" class=\"data row8 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row8_col7\" class=\"data row8 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row8_col8\" class=\"data row8 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row8_col9\" class=\"data row8 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ba5ab_row9_col0\" class=\"data row9 col0\" >c2dd5010f80c4740ad7899a449aff2a5</td>\n",
       "      <td id=\"T_ba5ab_row9_col1\" class=\"data row9 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row9_col2\" class=\"data row9 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row9_col3\" class=\"data row9 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row9_col4\" class=\"data row9 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row9_col5\" class=\"data row9 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row9_col6\" class=\"data row9 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row9_col7\" class=\"data row9 col7\" >0.6891</td>\n",
       "      <td id=\"T_ba5ab_row9_col8\" class=\"data row9 col8\" >0.7549</td>\n",
       "      <td id=\"T_ba5ab_row9_col9\" class=\"data row9 col9\" >0.6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ba5ab_row10_col0\" class=\"data row10 col0\" >94ebec2f9bef412c8f38777f9d592e0a</td>\n",
       "      <td id=\"T_ba5ab_row10_col1\" class=\"data row10 col1\" >LSTM_w2v_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row10_col2\" class=\"data row10 col2\" >w2v</td>\n",
       "      <td id=\"T_ba5ab_row10_col3\" class=\"data row10 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row10_col4\" class=\"data row10 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row10_col5\" class=\"data row10 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row10_col6\" class=\"data row10 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row10_col7\" class=\"data row10 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row10_col8\" class=\"data row10 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row10_col9\" class=\"data row10 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ba5ab_row11_col0\" class=\"data row11 col0\" >4d787195918746468d4fe447ceb289c6</td>\n",
       "      <td id=\"T_ba5ab_row11_col1\" class=\"data row11 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row11_col2\" class=\"data row11 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row11_col3\" class=\"data row11 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row11_col4\" class=\"data row11 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row11_col5\" class=\"data row11 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row11_col6\" class=\"data row11 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row11_col7\" class=\"data row11 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row11_col8\" class=\"data row11 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row11_col9\" class=\"data row11 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ba5ab_row12_col0\" class=\"data row12 col0\" >142521e57609499ba7f2be319e72b928</td>\n",
       "      <td id=\"T_ba5ab_row12_col1\" class=\"data row12 col1\" >LSTM_w2v_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row12_col2\" class=\"data row12 col2\" >w2v</td>\n",
       "      <td id=\"T_ba5ab_row12_col3\" class=\"data row12 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row12_col4\" class=\"data row12 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row12_col5\" class=\"data row12 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row12_col6\" class=\"data row12 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row12_col7\" class=\"data row12 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row12_col8\" class=\"data row12 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row12_col9\" class=\"data row12 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ba5ab_row13_col0\" class=\"data row13 col0\" >84a4e871a87e489db612124ad0169154</td>\n",
       "      <td id=\"T_ba5ab_row13_col1\" class=\"data row13 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row13_col2\" class=\"data row13 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row13_col3\" class=\"data row13 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row13_col4\" class=\"data row13 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row13_col5\" class=\"data row13 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row13_col6\" class=\"data row13 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row13_col7\" class=\"data row13 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row13_col8\" class=\"data row13 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row13_col9\" class=\"data row13 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ba5ab_row14_col0\" class=\"data row14 col0\" >14f07c4330374f26bb38e5aa075aef69</td>\n",
       "      <td id=\"T_ba5ab_row14_col1\" class=\"data row14 col1\" >LSTM_w2v_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row14_col2\" class=\"data row14 col2\" >w2v</td>\n",
       "      <td id=\"T_ba5ab_row14_col3\" class=\"data row14 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row14_col4\" class=\"data row14 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row14_col5\" class=\"data row14 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row14_col6\" class=\"data row14 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row14_col7\" class=\"data row14 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row14_col8\" class=\"data row14 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row14_col9\" class=\"data row14 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ba5ab_row15_col0\" class=\"data row15 col0\" >1b94f6ed96c746f0854220e272f1fdc1</td>\n",
       "      <td id=\"T_ba5ab_row15_col1\" class=\"data row15 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row15_col2\" class=\"data row15 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row15_col3\" class=\"data row15 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row15_col4\" class=\"data row15 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row15_col5\" class=\"data row15 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row15_col6\" class=\"data row15 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row15_col7\" class=\"data row15 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row15_col8\" class=\"data row15 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row15_col9\" class=\"data row15 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ba5ab_row16_col0\" class=\"data row16 col0\" >66678ca23d0f4bf79369eb05574209ee</td>\n",
       "      <td id=\"T_ba5ab_row16_col1\" class=\"data row16 col1\" >LSTM_w2v_5epochs_128units</td>\n",
       "      <td id=\"T_ba5ab_row16_col2\" class=\"data row16 col2\" >w2v</td>\n",
       "      <td id=\"T_ba5ab_row16_col3\" class=\"data row16 col3\" >128</td>\n",
       "      <td id=\"T_ba5ab_row16_col4\" class=\"data row16 col4\" >100</td>\n",
       "      <td id=\"T_ba5ab_row16_col5\" class=\"data row16 col5\" >5</td>\n",
       "      <td id=\"T_ba5ab_row16_col6\" class=\"data row16 col6\" >100</td>\n",
       "      <td id=\"T_ba5ab_row16_col7\" class=\"data row16 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row16_col8\" class=\"data row16 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row16_col9\" class=\"data row16 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ba5ab_row17_col0\" class=\"data row17 col0\" >bdc916b56d1143b5a1ca7bda8031f828</td>\n",
       "      <td id=\"T_ba5ab_row17_col1\" class=\"data row17 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row17_col2\" class=\"data row17 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row17_col3\" class=\"data row17 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row17_col4\" class=\"data row17 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row17_col5\" class=\"data row17 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row17_col6\" class=\"data row17 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row17_col7\" class=\"data row17 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row17_col8\" class=\"data row17 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row17_col9\" class=\"data row17 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ba5ab_row18_col0\" class=\"data row18 col0\" >2c1fb330a10840cdbd74917a0cb370fb</td>\n",
       "      <td id=\"T_ba5ab_row18_col1\" class=\"data row18 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row18_col2\" class=\"data row18 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row18_col3\" class=\"data row18 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row18_col4\" class=\"data row18 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row18_col5\" class=\"data row18 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row18_col6\" class=\"data row18 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row18_col7\" class=\"data row18 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row18_col8\" class=\"data row18 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row18_col9\" class=\"data row18 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ba5ab_row19_col0\" class=\"data row19 col0\" >e614b4dcd5f04fb78bb3c95e0071fd8f</td>\n",
       "      <td id=\"T_ba5ab_row19_col1\" class=\"data row19 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row19_col2\" class=\"data row19 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row19_col3\" class=\"data row19 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row19_col4\" class=\"data row19 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row19_col5\" class=\"data row19 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row19_col6\" class=\"data row19 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row19_col7\" class=\"data row19 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row19_col8\" class=\"data row19 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row19_col9\" class=\"data row19 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ba5ab_row20_col0\" class=\"data row20 col0\" >5fbefa2aa28747c8bb6b658e952bec8b</td>\n",
       "      <td id=\"T_ba5ab_row20_col1\" class=\"data row20 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row20_col2\" class=\"data row20 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row20_col3\" class=\"data row20 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row20_col4\" class=\"data row20 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row20_col5\" class=\"data row20 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row20_col6\" class=\"data row20 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row20_col7\" class=\"data row20 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row20_col8\" class=\"data row20 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row20_col9\" class=\"data row20 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba5ab_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ba5ab_row21_col0\" class=\"data row21 col0\" >1a8ade3d04ef4ccb9fa72d754bb884ea</td>\n",
       "      <td id=\"T_ba5ab_row21_col1\" class=\"data row21 col1\" >LSTM_w2v_5epochs_128units_model</td>\n",
       "      <td id=\"T_ba5ab_row21_col2\" class=\"data row21 col2\" >None</td>\n",
       "      <td id=\"T_ba5ab_row21_col3\" class=\"data row21 col3\" >None</td>\n",
       "      <td id=\"T_ba5ab_row21_col4\" class=\"data row21 col4\" >None</td>\n",
       "      <td id=\"T_ba5ab_row21_col5\" class=\"data row21 col5\" >None</td>\n",
       "      <td id=\"T_ba5ab_row21_col6\" class=\"data row21 col6\" >None</td>\n",
       "      <td id=\"T_ba5ab_row21_col7\" class=\"data row21 col7\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row21_col8\" class=\"data row21 col8\" >nan</td>\n",
       "      <td id=\"T_ba5ab_row21_col9\" class=\"data row21 col9\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x459348f20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 4: Create a styled DataFrame with colored metrics based on performance\n",
    "def style_dataframe(df, columns_to_style):\n",
    "    \"\"\"\n",
    "    Apply conditional formatting to specific columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame to style\n",
    "    columns_to_style : list\n",
    "        List of column names to apply styling to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.io.formats.style.Styler\n",
    "        Styled DataFrame\n",
    "    \"\"\"\n",
    "    # Create a subset of the DataFrame with just the columns to style\n",
    "    subset_df = df[columns_to_style].copy()\n",
    "\n",
    "    # Define a function to color cells based on their values (higher is better)\n",
    "    def color_scale(val):\n",
    "        # For metrics where higher is better\n",
    "        if pd.notnull(val):\n",
    "            # Color from light yellow to dark green\n",
    "            color_val = min(val * 2, 1.0)  # Scale value for better color spread\n",
    "            r = int(255 * (1 - color_val))\n",
    "            g = int(200 + 55 * color_val)\n",
    "            b = int(100 * (1 - color_val))\n",
    "            return f'background-color: rgb({r},{g},{b})'\n",
    "        return ''\n",
    "\n",
    "    # Apply the styling\n",
    "    styled_df = df.style.apply(lambda x: [color_scale(val) if col in columns_to_style else ''\n",
    "                                         for col, val in x.items()], axis=1)\n",
    "\n",
    "    # Format metric columns to 4 decimal places\n",
    "    format_dict = {col: '{:.4f}' for col in columns_to_style}\n",
    "    styled_df = styled_df.format(format_dict)\n",
    "\n",
    "    return styled_df\n",
    "\n",
    "# Get metrics dataframe\n",
    "metrics_df = compare_run_metrics(\n",
    "    metric_prefixes=['test_'],\n",
    "    sort_by='test_f1_score',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# Define columns to style\n",
    "metrics_to_style = [col for col in metrics_df.columns if col.startswith('test_')]\n",
    "\n",
    "# Create styled dataframe\n",
    "styled_metrics = style_dataframe(metrics_df, metrics_to_style)\n",
    "display(styled_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae132b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Find the best model for each metric\n",
    "def summarize_best_models(metric_prefixes=['test_']):\n",
    "    \"\"\"\n",
    "    Create a summary of the best model for each metric.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric_prefixes : list\n",
    "        List of metric prefixes to filter (e.g., ['test_', 'val_'])\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with best model for each metric\n",
    "    \"\"\"\n",
    "    # Get metrics dataframe\n",
    "    metrics_df = compare_run_metrics(metric_prefixes=metric_prefixes)\n",
    "\n",
    "    if metrics_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Find best model for each metric\n",
    "    best_models = []\n",
    "\n",
    "    # Get all metric columns\n",
    "    metric_cols = [col for col in metrics_df.columns if any(col.startswith(prefix) for prefix in metric_prefixes)]\n",
    "\n",
    "    for metric in metric_cols:\n",
    "        # Skip non-numeric columns\n",
    "        if not pd.api.types.is_numeric_dtype(metrics_df[metric]):\n",
    "            continue\n",
    "\n",
    "        # Find the row with the maximum value for this metric\n",
    "        best_idx = metrics_df[metric].idxmax()\n",
    "        best_row = metrics_df.loc[best_idx]\n",
    "\n",
    "        best_models.append({\n",
    "            'metric': metric,\n",
    "            'best_value': best_row[metric],\n",
    "            'embedding': best_row.get('embedding', 'unknown'),\n",
    "            'run_name': best_row.get('run_name', 'unknown'),\n",
    "            'run_id': best_row.get('run_id', 'unknown')\n",
    "        })\n",
    "\n",
    "    # Create summary dataframe\n",
    "    summary_df = pd.DataFrame(best_models)\n",
    "    summary_df = summary_df.sort_values(by='metric')\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "# Get and display best model summary\n",
    "best_models_summary = summarize_best_models()\n",
    "display(best_models_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d74e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison of all model results\n",
    "def create_model_comparison_summary():\n",
    "    # Get client to query metrics\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Get all runs from our experiment\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "    if len(runs) == 0:\n",
    "        print(\"No runs found in the experiment\")\n",
    "        return\n",
    "\n",
    "    # Extract key information for comparison\n",
    "    comparison_data = []\n",
    "    for _, run in runs.iterrows():\n",
    "        run_id = run.run_id\n",
    "\n",
    "        # Skip the run if it's just a comparison run\n",
    "        if run.tags.run_name == \"model_comparison\":\n",
    "            continue\n",
    "\n",
    "        # Extract embedding type from run name\n",
    "        run_name = run.tags.run_name\n",
    "        embedding_type = run_name.split('_')[1] if '_' in run_name else \"unknown\"\n",
    "\n",
    "        # Get metrics\n",
    "        metrics = run.metrics\n",
    "        test_metrics = {k: v for k, v in metrics.items() if k.startswith('test_')}\n",
    "\n",
    "        # Add to comparison data\n",
    "        run_info = {\n",
    "            'run_id': run_id,\n",
    "            'embedding': embedding_type,\n",
    "            'run_name': run_name\n",
    "        }\n",
    "        run_info.update(test_metrics)\n",
    "        comparison_data.append(run_info)\n",
    "\n",
    "    # Create dataframe\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Create comparison visualizations\n",
    "    if len(comparison_data) > 0 and len(comparison_data) > 1:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "        # Plot key metrics\n",
    "        metrics_to_plot = ['test_accuracy', 'test_roc_auc', 'test_f1_score']\n",
    "        metrics_to_plot = [m for m in metrics_to_plot if m in comparison_df.columns]\n",
    "\n",
    "        for i, metric in enumerate(metrics_to_plot):\n",
    "            plt.subplot(1, len(metrics_to_plot), i+1)\n",
    "            sns.barplot(x='embedding', y=metric, data=comparison_df)\n",
    "            plt.title(f'{metric.replace(\"test_\", \"\").capitalize()}')\n",
    "            plt.ylim(0, 1.0)  # Set y-axis from 0 to 1\n",
    "            plt.grid(True, axis='y')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"model_comparison_chart.png\")\n",
    "\n",
    "        # Save the comparison data\n",
    "        comparison_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "\n",
    "        # Log to MLflow in a new run\n",
    "        with mlflow.start_run(run_name=\"model_comparison\"):\n",
    "            mlflow.log_artifact(\"model_comparison_chart.png\")\n",
    "            mlflow.log_artifact(\"model_comparison_results.csv\")\n",
    "\n",
    "        print(\"Model comparison completed and artifacts logged to MLflow\")\n",
    "    else:\n",
    "        print(\"Not enough models to create comparison\")\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "# Run the comparison after all models are trained\n",
    "model_comparison = create_model_comparison_summary()\n",
    "display(model_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5af73",
   "metadata": {},
   "source": [
    "# Finding Best Epoch for Each Run\n",
    "\n",
    "The function below helps identify the optimal epoch for each model run based on specified metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da698c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No val_accuracy data found for run: bemused-moose-553\n",
      "No val_accuracy data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_fasttext_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>embedding</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_val_accuracy</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94ebec2f9bef412c8f38777f9d592e0a</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.427517</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>0.768960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14f07c4330374f26bb38e5aa075aef69</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.431794</td>\n",
       "      <td>0.472045</td>\n",
       "      <td>0.774120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142521e57609499ba7f2be319e72b928</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.430828</td>\n",
       "      <td>0.482841</td>\n",
       "      <td>0.768580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66678ca23d0f4bf79369eb05574209ee</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.445012</td>\n",
       "      <td>0.492224</td>\n",
       "      <td>0.759640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52e306e2772448c1849c419c74b25c16</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>5</td>\n",
       "      <td>0.489022</td>\n",
       "      <td>0.407412</td>\n",
       "      <td>0.814313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29f1463d30e34065a4b6064fb5fc59e9</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.484394</td>\n",
       "      <td>0.450160</td>\n",
       "      <td>0.787719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74a884d7c23243688652947286030c54</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>4</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.561974</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.729375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010b366dbbd4bbba3edf2c1d55d0342</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613900</td>\n",
       "      <td>0.480329</td>\n",
       "      <td>0.771563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id                        run_name embedding  \\\n",
       "4  94ebec2f9bef412c8f38777f9d592e0a       LSTM_w2v_5epochs_128units       w2v   \n",
       "6  14f07c4330374f26bb38e5aa075aef69       LSTM_w2v_5epochs_128units       w2v   \n",
       "5  142521e57609499ba7f2be319e72b928       LSTM_w2v_5epochs_128units       w2v   \n",
       "7  66678ca23d0f4bf79369eb05574209ee       LSTM_w2v_5epochs_128units       w2v   \n",
       "1  52e306e2772448c1849c419c74b25c16     LSTM_glove_5epochs_128units     glove   \n",
       "0  29f1463d30e34065a4b6064fb5fc59e9     LSTM_glove_5epochs_128units     glove   \n",
       "2  74a884d7c23243688652947286030c54  LSTM_fasttext_5epochs_128units  fasttext   \n",
       "3  2010b366dbbd4bbba3edf2c1d55d0342       LSTM_w2v_5epochs_128units       w2v   \n",
       "\n",
       "   best_epoch  best_val_accuracy  total_epochs  val_loss  train_loss  \\\n",
       "4           4           0.811500             5  0.427517    0.478890   \n",
       "6           4           0.805000             5  0.431794    0.472045   \n",
       "5           4           0.803250             5  0.430828    0.482841   \n",
       "7           4           0.795250             5  0.445012    0.492224   \n",
       "1           3           0.769375             5  0.489022    0.407412   \n",
       "0           2           0.766500             5  0.484394    0.450160   \n",
       "2           4           0.704000             5  0.561974    0.534061   \n",
       "3           4           0.689375             5  0.613900    0.480329   \n",
       "\n",
       "   train_accuracy  \n",
       "4        0.768960  \n",
       "6        0.774120  \n",
       "5        0.768580  \n",
       "7        0.759640  \n",
       "1        0.814313  \n",
       "0        0.787719  \n",
       "2        0.729375  \n",
       "3        0.771563  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No val_loss data found for run: bemused-moose-553\n",
      "No val_loss data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_fasttext_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_loss data found for run: LSTM_w2v_5epochs_128units_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>embedding</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94ebec2f9bef412c8f38777f9d592e0a</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.427517</td>\n",
       "      <td>5</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>0.768960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142521e57609499ba7f2be319e72b928</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.430828</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803250</td>\n",
       "      <td>0.482841</td>\n",
       "      <td>0.768580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14f07c4330374f26bb38e5aa075aef69</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.431794</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.472045</td>\n",
       "      <td>0.774120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66678ca23d0f4bf79369eb05574209ee</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>4</td>\n",
       "      <td>0.445012</td>\n",
       "      <td>5</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>0.492224</td>\n",
       "      <td>0.759640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52e306e2772448c1849c419c74b25c16</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479830</td>\n",
       "      <td>5</td>\n",
       "      <td>0.765750</td>\n",
       "      <td>0.448893</td>\n",
       "      <td>0.787906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29f1463d30e34065a4b6064fb5fc59e9</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>glove</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484394</td>\n",
       "      <td>5</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>0.450160</td>\n",
       "      <td>0.787719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74a884d7c23243688652947286030c54</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>4</td>\n",
       "      <td>0.561974</td>\n",
       "      <td>5</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.729375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010b366dbbd4bbba3edf2c1d55d0342</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>w2v</td>\n",
       "      <td>3</td>\n",
       "      <td>0.598690</td>\n",
       "      <td>5</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>0.526434</td>\n",
       "      <td>0.735125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id                        run_name embedding  \\\n",
       "4  94ebec2f9bef412c8f38777f9d592e0a       LSTM_w2v_5epochs_128units       w2v   \n",
       "5  142521e57609499ba7f2be319e72b928       LSTM_w2v_5epochs_128units       w2v   \n",
       "6  14f07c4330374f26bb38e5aa075aef69       LSTM_w2v_5epochs_128units       w2v   \n",
       "7  66678ca23d0f4bf79369eb05574209ee       LSTM_w2v_5epochs_128units       w2v   \n",
       "1  52e306e2772448c1849c419c74b25c16     LSTM_glove_5epochs_128units     glove   \n",
       "0  29f1463d30e34065a4b6064fb5fc59e9     LSTM_glove_5epochs_128units     glove   \n",
       "2  74a884d7c23243688652947286030c54  LSTM_fasttext_5epochs_128units  fasttext   \n",
       "3  2010b366dbbd4bbba3edf2c1d55d0342       LSTM_w2v_5epochs_128units       w2v   \n",
       "\n",
       "   best_epoch  best_val_loss  total_epochs  val_accuracy  train_loss  \\\n",
       "4           4       0.427517             5      0.811500    0.478890   \n",
       "5           4       0.430828             5      0.803250    0.482841   \n",
       "6           4       0.431794             5      0.805000    0.472045   \n",
       "7           4       0.445012             5      0.795250    0.492224   \n",
       "1           2       0.479830             5      0.765750    0.448893   \n",
       "0           2       0.484394             5      0.766500    0.450160   \n",
       "2           4       0.561974             5      0.704000    0.534061   \n",
       "3           3       0.598690             5      0.685625    0.526434   \n",
       "\n",
       "   train_accuracy  \n",
       "4        0.768960  \n",
       "5        0.768580  \n",
       "6        0.774120  \n",
       "7        0.759640  \n",
       "1        0.787906  \n",
       "0        0.787719  \n",
       "2        0.729375  \n",
       "3        0.735125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_best_epochs(metric_name='val_accuracy', optimization='max', embedding_types=None):\n",
    "    \"\"\"\n",
    "    Analyzes the training history of each run and identifies the best epoch based on a specified metric.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric_name : str\n",
    "        The name of the metric to optimize (e.g., 'val_accuracy', 'val_loss')\n",
    "    optimization : str\n",
    "        Whether to maximize ('max') or minimize ('min') the metric\n",
    "    embedding_types : list or None\n",
    "        Filter runs by embedding types (e.g., ['w2v', 'fasttext', 'glove'])\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the best epoch and corresponding metric value for each run\n",
    "    \"\"\"\n",
    "    # Get client to query metrics\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Check if experiment exists\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if experiment is None:\n",
    "        print(f\"Error: Experiment '{experiment_name}' not found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get all runs from our experiment\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "    if len(runs) == 0:\n",
    "        print(\"No runs found in the experiment\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Filter out comparison runs\n",
    "    runs = runs[runs['tags.mlflow.runName'] != 'model_comparison']\n",
    "\n",
    "    # Filter by embedding type if specified\n",
    "    if embedding_types:\n",
    "        filtered_runs = []\n",
    "        for _, run in runs.iterrows():\n",
    "            run_name = run['tags.mlflow.runName']\n",
    "            for embedding in embedding_types:\n",
    "                if embedding in run_name:\n",
    "                    filtered_runs.append(run)\n",
    "                    break\n",
    "        runs = pd.DataFrame(filtered_runs) if filtered_runs else runs\n",
    "\n",
    "    # Get best epoch for each run\n",
    "    best_epochs = []\n",
    "\n",
    "    for _, run in runs.iterrows():\n",
    "        run_id = run['run_id']\n",
    "        run_name = run['tags.mlflow.runName']\n",
    "\n",
    "        # Extract embedding type from run name\n",
    "        embedding_parts = run_name.split('_')\n",
    "        embedding_type = embedding_parts[1] if len(embedding_parts) > 1 else \"unknown\"\n",
    "\n",
    "        try:\n",
    "            # Get metric history\n",
    "            metric_history = client.get_metric_history(run_id, metric_name)\n",
    "\n",
    "            if not metric_history:\n",
    "                print(f\"No {metric_name} data found for run: {run_name}\")\n",
    "                continue\n",
    "\n",
    "            # Convert to DataFrame for easier analysis\n",
    "            epochs = []\n",
    "            values = []\n",
    "\n",
    "            for item in metric_history:\n",
    "                epochs.append(item.step)\n",
    "                values.append(item.value)\n",
    "\n",
    "            history_df = pd.DataFrame({\n",
    "                'epoch': epochs,\n",
    "                'value': values\n",
    "            })\n",
    "\n",
    "            # Find the best epoch based on optimization direction\n",
    "            if optimization.lower() == 'max':\n",
    "                best_idx = history_df['value'].idxmax()\n",
    "            else:  # min\n",
    "                best_idx = history_df['value'].idxmin()\n",
    "\n",
    "            best_epoch = history_df.loc[best_idx, 'epoch']\n",
    "            best_value = history_df.loc[best_idx, 'value']\n",
    "\n",
    "            # Get other metrics at this epoch if available\n",
    "            other_metrics = {}\n",
    "            potential_metrics = ['val_loss', 'val_accuracy', 'train_loss', 'train_accuracy']\n",
    "\n",
    "            for other_metric in potential_metrics:\n",
    "                if other_metric != metric_name:\n",
    "                    try:\n",
    "                        other_history = client.get_metric_history(run_id, other_metric)\n",
    "                        for item in other_history:\n",
    "                            if item.step == best_epoch:\n",
    "                                other_metrics[other_metric] = item.value\n",
    "                                break\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            # Create entry\n",
    "            entry = {\n",
    "                'run_id': run_id,\n",
    "                'run_name': run_name,\n",
    "                'embedding': embedding_type,\n",
    "                'best_epoch': best_epoch,\n",
    "                f'best_{metric_name}': best_value,\n",
    "                'total_epochs': max(epochs) + 1  # +1 because epochs are 0-indexed\n",
    "            }\n",
    "            entry.update(other_metrics)\n",
    "\n",
    "            best_epochs.append(entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run_name}: {e}\")\n",
    "\n",
    "    # Create dataframe\n",
    "    if best_epochs:\n",
    "        best_epochs_df = pd.DataFrame(best_epochs)\n",
    "\n",
    "        # Sort by the optimized metric\n",
    "        sort_col = f'best_{metric_name}'\n",
    "        if sort_col in best_epochs_df.columns:\n",
    "            if optimization.lower() == 'max':\n",
    "                best_epochs_df = best_epochs_df.sort_values(by=sort_col, ascending=False)\n",
    "            else:\n",
    "                best_epochs_df = best_epochs_df.sort_values(by=sort_col)\n",
    "\n",
    "        return best_epochs_df\n",
    "    else:\n",
    "        print(\"No valid runs found with the specified criteria\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example: Find best epochs based on validation accuracy\n",
    "best_epochs_by_accuracy = get_best_epochs(metric_name='val_accuracy', optimization='max')\n",
    "display(best_epochs_by_accuracy)\n",
    "\n",
    "# Example: Find best epochs based on minimizing validation loss\n",
    "best_epochs_by_loss = get_best_epochs(metric_name='val_loss', optimization='min')\n",
    "display(best_epochs_by_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3ca3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No val_accuracy data found for run: bemused-moose-553\n",
      "No val_accuracy data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_glove_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_fasttext_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "No val_accuracy data found for run: LSTM_w2v_5epochs_128units_model\n",
      "Warning: Could not log artifact to MLflow: Run with UUID 2bc9842159d2492eaf5f8673a07beecc is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison at Best Epochs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>run_name</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_val_accuracy</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w2v</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.427517</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>0.768960</td>\n",
       "      <td>94ebec2f9bef412c8f38777f9d592e0a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>4</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.431794</td>\n",
       "      <td>0.472045</td>\n",
       "      <td>0.774120</td>\n",
       "      <td>14f07c4330374f26bb38e5aa075aef69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w2v</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.430828</td>\n",
       "      <td>0.482841</td>\n",
       "      <td>0.768580</td>\n",
       "      <td>142521e57609499ba7f2be319e72b928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>4</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.445012</td>\n",
       "      <td>0.492224</td>\n",
       "      <td>0.759640</td>\n",
       "      <td>66678ca23d0f4bf79369eb05574209ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glove</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>5</td>\n",
       "      <td>0.489022</td>\n",
       "      <td>0.407412</td>\n",
       "      <td>0.814313</td>\n",
       "      <td>52e306e2772448c1849c419c74b25c16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glove</td>\n",
       "      <td>LSTM_glove_5epochs_128units</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.484394</td>\n",
       "      <td>0.450160</td>\n",
       "      <td>0.787719</td>\n",
       "      <td>29f1463d30e34065a4b6064fb5fc59e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>LSTM_fasttext_5epochs_128units</td>\n",
       "      <td>4</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.561974</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.729375</td>\n",
       "      <td>74a884d7c23243688652947286030c54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w2v</td>\n",
       "      <td>LSTM_w2v_5epochs_128units</td>\n",
       "      <td>4</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613900</td>\n",
       "      <td>0.480329</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>2010b366dbbd4bbba3edf2c1d55d0342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding                        run_name  best_epoch  best_val_accuracy  \\\n",
       "4       w2v       LSTM_w2v_5epochs_128units           4           0.811500   \n",
       "6       w2v       LSTM_w2v_5epochs_128units           4           0.805000   \n",
       "5       w2v       LSTM_w2v_5epochs_128units           4           0.803250   \n",
       "7       w2v       LSTM_w2v_5epochs_128units           4           0.795250   \n",
       "1     glove     LSTM_glove_5epochs_128units           3           0.769375   \n",
       "0     glove     LSTM_glove_5epochs_128units           2           0.766500   \n",
       "2  fasttext  LSTM_fasttext_5epochs_128units           4           0.704000   \n",
       "3       w2v       LSTM_w2v_5epochs_128units           4           0.689375   \n",
       "\n",
       "   total_epochs  val_loss  train_loss  train_accuracy  \\\n",
       "4             5  0.427517    0.478890        0.768960   \n",
       "6             5  0.431794    0.472045        0.774120   \n",
       "5             5  0.430828    0.482841        0.768580   \n",
       "7             5  0.445012    0.492224        0.759640   \n",
       "1             5  0.489022    0.407412        0.814313   \n",
       "0             5  0.484394    0.450160        0.787719   \n",
       "2             5  0.561974    0.534061        0.729375   \n",
       "3             5  0.613900    0.480329        0.771563   \n",
       "\n",
       "                             run_id  \n",
       "4  94ebec2f9bef412c8f38777f9d592e0a  \n",
       "6  14f07c4330374f26bb38e5aa075aef69  \n",
       "5  142521e57609499ba7f2be319e72b928  \n",
       "7  66678ca23d0f4bf79369eb05574209ee  \n",
       "1  52e306e2772448c1849c419c74b25c16  \n",
       "0  29f1463d30e34065a4b6064fb5fc59e9  \n",
       "2  74a884d7c23243688652947286030c54  \n",
       "3  2010b366dbbd4bbba3edf2c1d55d0342  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model for Each Metric:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>best_model</th>\n",
       "      <th>best_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_accuracy</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_precision</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_recall</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_f1_score</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_specificity</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric best_model  best_value\n",
       "0     test_accuracy                      0\n",
       "1    test_precision                      0\n",
       "2       test_recall                      0\n",
       "3     test_f1_score                      0\n",
       "4      test_roc_auc                      0\n",
       "5  test_specificity                      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_models_at_best_epochs(metric_name='val_accuracy', optimization='max'):\n",
    "    \"\"\"\n",
    "    Creates a comparison of model performance at their respective best epochs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric_name : str\n",
    "        The name of the metric to optimize (e.g., 'val_accuracy', 'val_loss')\n",
    "    optimization : str\n",
    "        Whether to maximize ('max') or minimize ('min') the metric\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with model performance metrics at their best epochs\n",
    "    \"\"\"\n",
    "    # Get best epochs\n",
    "    best_epochs_df = get_best_epochs(metric_name, optimization)\n",
    "\n",
    "    if best_epochs_df.empty:\n",
    "        print(\"No data available for comparison\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get client to query metrics\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Metrics to compare\n",
    "    comparison_metrics = [\n",
    "        'test_accuracy', 'test_precision', 'test_recall', 'test_f1_score',\n",
    "        'test_roc_auc', 'test_specificity'\n",
    "    ]\n",
    "\n",
    "    # Get metrics for each run at its best epoch\n",
    "    for _, row in best_epochs_df.iterrows():\n",
    "        run_id = row['run_id']\n",
    "\n",
    "        # Get test metrics for this run\n",
    "        run_data = mlflow.get_run(run_id).data\n",
    "        for metric in comparison_metrics:\n",
    "            if metric in run_data.metrics:\n",
    "                best_epochs_df.loc[_, metric] = run_data.metrics[metric]\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    cols_order = ['embedding', 'run_name', 'best_epoch', f'best_{metric_name}', 'total_epochs'] + \\\n",
    "                 [c for c in best_epochs_df.columns if c.startswith('train_') or c.startswith('val_')] + \\\n",
    "                 comparison_metrics + \\\n",
    "                 [c for c in best_epochs_df.columns if c not in ['embedding', 'run_name', 'best_epoch',\n",
    "                                                               f'best_{metric_name}', 'total_epochs'] and\n",
    "                                                     not c.startswith('train_') and\n",
    "                                                     not c.startswith('val_') and\n",
    "                                                     c not in comparison_metrics]\n",
    "\n",
    "    # Keep only columns that exist\n",
    "    cols_order = [c for c in cols_order if c in best_epochs_df.columns]\n",
    "\n",
    "    # Create a styled dataframe\n",
    "    comparison_df = best_epochs_df[cols_order].copy()\n",
    "\n",
    "    # Find the best model for each metric\n",
    "    best_model_summary = pd.DataFrame({\n",
    "        'metric': comparison_metrics,\n",
    "        'best_model': [''] * len(comparison_metrics),\n",
    "        'best_value': [0] * len(comparison_metrics)\n",
    "    })\n",
    "\n",
    "    for i, metric in enumerate(comparison_metrics):\n",
    "        if metric in comparison_df.columns:\n",
    "            idx_best = comparison_df[metric].idxmax()\n",
    "            if pd.notnull(idx_best):\n",
    "                best_model = comparison_df.loc[idx_best, 'embedding']\n",
    "                best_value = comparison_df.loc[idx_best, metric]\n",
    "                best_model_summary.loc[i, 'best_model'] = best_model\n",
    "                best_model_summary.loc[i, 'best_value'] = best_value\n",
    "\n",
    "    # Create visualization of best model performance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, embedding in enumerate(comparison_df['embedding'].unique()):\n",
    "        model_data = []\n",
    "        available_metrics = []\n",
    "        for metric in comparison_metrics:\n",
    "            if metric in comparison_df.columns:\n",
    "                value = comparison_df[comparison_df['embedding'] == embedding][metric].values\n",
    "                if len(value) > 0:\n",
    "                    model_data.append(value[0])\n",
    "                    available_metrics.append(metric)\n",
    "                else:\n",
    "                    model_data.append(0)\n",
    "                    available_metrics.append(metric)\n",
    "\n",
    "        #  Only plot if we have data\n",
    "        if len(model_data) > 0:\n",
    "            plt.plot(available_metrics, model_data, marker='o', label=embedding)\n",
    "\n",
    "    if len(plt.gca().get_lines()) == 0:\n",
    "        plt.text(0.5, 0.5, \"No data available to plot\",\n",
    "                horizontalalignment='center', verticalalignment='center',\n",
    "                transform=plt.gca().transAxes)\n",
    "    plt.title('Model Performance at Best Epochs')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = \"model_performance_at_best_epochs.png\"\n",
    "    plt.savefig(plot_path)\n",
    "\n",
    "    # Log to MLflow\n",
    "    try:\n",
    "        with mlflow.start_run(run_name=\"best_epochs_comparison\"):\n",
    "            mlflow.log_artifact(plot_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not log artifact to MLflow: {e}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return comparison_df, best_model_summary\n",
    "\n",
    "# Example: Compare models at their best epochs\n",
    "comparison_df, best_model_summary = compare_models_at_best_epochs()\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Comparison at Best Epochs:\")\n",
    "display(comparison_df)\n",
    "\n",
    "print(\"\\nBest Model for Each Metric:\")\n",
    "display(best_model_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
